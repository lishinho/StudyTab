2.3
一，什么是GFW

Great FireWall, 防火长城，特指中国国家防火墙。网友常说的网站被墙，指的就是网站内容被防火长城所屏蔽或者指服务器的通讯被封阻，“翻墙”也被引申为突破网络审查浏览大陆境外被屏蔽的网站或使用服务的行为。

防火墙是由分散部门的各服务器和路由器等设备加上相关公司的应用程序组成，用于信息审查和管制。GFW一直没有官方承认，不过可以称得上是互联网时代最优秀的系统之一，系统神秘而深奥 据悉还没有人通过黑盒了解GFW的全貌，再加上大陆内部蓬勃的互联网发展使民众并不在意GFW的存在，造成人们对它的现在印象。

二，主要技术

从最开始说，其实做到信息防护，我们可以把所有信息记录在磁盘上，然后一点点查过滤敏感信息，不过这么做一是信息量太大，二是无法实时防护，更不要说分布式一系列问题。所以我们把过滤权限写在ACL表中，通过技术进行封锁敏感网站信息，当海外网站信息进入国家入口网关时，既可以选择性过滤，当然黑名单白名单就要自己设计，如果技术隔离做得好，甚至技术人员可以不知道过滤信息就能达到作用（即开发者没有读写改敏感词权限），即使海外网站信息使用代理，只要信息不加密 一样会倒在GFW面前。

技术不断发展，就有人为创造的可能，刚刚我们说入口网关会根据敏感信息实现过滤屏蔽网站，如果实现多级代理信息加密技术，让网关识别不到或蒙蔽逃过审核，就可以实现翻过GFW的目的，而这一概念实际上早就存在了，只不过技术一直在演化。07年阮一峰老师写的绕过GFW方法中（https代理，tor，ssh隧道，vpn等）就有介绍。

魔高一尺，道高一丈。什么动态SSL Freenet VPN SSH TOR GNUnet JAP I2P Psiphon 什么Feed Over Email 。所有的翻墙方法，只要有人想得到，GFW都有研究并且有反制措施的实验室方案储备。GFW对每一项翻墙技术都有做相应的对策，包括资料中常见的是DNS缓存污染，IP地址封锁，TCP连接重置等，具体细节要参考论文，有很多都算作机密，而采取方法的过程中有一些方法甚至会阶段性影响境外网站的正常使用，这也是一些国家一直恐惧而敌视中国互联网发展的原因之一。只是GFW面对一些标志难题也是无能为力，比如P2P的隐匿性，比如DDoS攻击等。技术就是这样，只有相互借鉴相互促进，只不过使用用途可能不尽相同。

那既然GFW如此强大，为什么还会有各种可用的翻墙软件呢？

我猜想是各个时期的要求不同，相关政策和敏感权限也不是一曾不变。

三，方法汇总

绕过GFW的方法：

1. 修改hosts文件
修改电脑内部的host文件，通过自主指定相关网站的IP地址的方式实现，即避开DNS，简单粗暴，这种方式现在依然存在；
我们访问网站的时候，输入的是域名，实际上DNS会进行IP解析，把域名对应IP进行访问，GFW 会干扰DNS 的解析过程，并且返回一个错误的 IP 地址给你，使你无法正确连接到你要的服务器上读取正确的信息。Host的级别比DNS要高，修改Host文件实际上相当于是直接访问IP.在有些时候，即使修改了Host文件，有些网站还是打不开。这就是这个网站的IP被封锁了.就是说你即使改了Host，可以打开Google但是打不开FB，Twitter 也是正常现象，这个时候就必须要翻墙了.
2. 强制指定DNS
GFW主要攻击手段之一是DNS污染，于是便有了强制指定DNS的方式以避免IP被污染的方法，这种方法经常会结合1使用；
3. VPN
原本用来作为一种匿名，安全，保密的VPN服务也被发掘出翻墙的潜力，其原理比较简单，选择一个没有被GFW封杀的服务器，通过该服务器将相关网站的流量转发到自己的设备，而设备与VPN服务器之间的通信并不在GFW的屏蔽范围之内，于是便达成了翻墙的目的。VPN最初的目的是用于企业服务，方便员工远程登录企业内网进行操作，主要协议有PPTP、L2TP，IPsec、IKEv2、openVPN等等；
4.网络服务
GoAgent，自由门，fqrouter等一系列网络服务；

5. Shadowsocks（搭建ss/ssr服务器集群->客户端工具翻墙）
Shadowsocks类：主要包括各类Shadowsocks衍生版本，ShadowsocksR，Shadowsocks-libev等，特点是加密了通信过程中的数据以及流量分流；由于种种原因，ss，ssr等版本原创者不再更新，现在流行的小火箭shadowRocket，surge等
6. 内网穿透
内网穿透：比较典型的是ZeroTier，简单解释就是假装自己在国外上网，这么说的主要原因是因为当两台设备同时加入到ZeroTier的服务器之后，两台设备会拥有同一IP段内的IP地址，此时两台电脑相当于处于一个虚拟局域网之中，可以用iPad连接电脑远程运行MATLAB；
7. V2Ray
V2Ray 是 Project V 下的一个工具。Project V 是一个包含一系列构建特定网络环境工具的项目，而 V2Ray 属于最核心的一个。官方介绍 Project V 提供了单一的内核和多种界面操作方式。内核（V2Ray）用于实际的网络交互、路由等针对网络数据的处理，而外围的用户界面程序提供了方便直接的操作流程。不过从时间上来说，先有 V2Ray才有Project V；

GFW相应对策：

1.VPN及其软件系列
防火长城现已有能力早就可以对基于PPTP和L2TP协议的VPN连接进行监控和封锁，一方面对各大应用软件市场进行vpn封锁，致使开发者只能使用testflights，一旦开发者在试用期后不再开发，服务也不再继续。


2.对破网软件流量检测
GFW可以提取加密流量数据包分析特征，基于神经网络算法对shadowsocks等软件流量进行检测，定位打击。即使v2ray等软件基于websocket和tls加密，能够将加密流量和https协议流量进行混淆，也有方法进行定量识别。


3.基于tls的连接进行tor刺探，建立破坏连接


4.其他防护方法
数据包探测加速嗅出可疑流量，IPV6审查，间歇性封锁等

因此为了稳定的达到翻GFW的目的，最好推荐用搬瓦工自建ss/V2Ray服务器，搭梯子进行翻墙，这样由于量小GFW不会细致进行流量识别。不过这么做有一定技术要求。



以上内容只涉及技术分享，无关政治人文

参考文献粗糙，如有出入请留言。


if(c<32) 控制字符
else if(c>'0'&&c<'9') 数字
else if(c>'a'&&c<'z') 小写字母
else if(c>'A'&&c<'Z') 大写字母
else 其它字母

guardian-3.2发布模块
manager上架 迁移代码要合进去
tdc上架


kunDB限制登陆ip地址
openldap有 apacheds没有
userugi
拿到用户的ip
ldap带到用户的ip vpget
限制ip数据从哪里读-
mysql用户ip创建一张表

inceptor-plugin修改
kunDB代码 
限制策略怎么存储 怎么vpget曾 资源动态加载在哪边实现


1. 要kundb的项目权限，了解ip的封禁情况
2. 修改圣哥的comment

byte型为什么要&0xff

2.4
kundb -> vitess
vitess是什么 sharded mysql on kubernetes to optimize huge DB
How to move hundreds of MySQL databases into kubernates
vitess是一个用于部署 扩展和管理大型mysql实例集群的数据库解决方案。
1.支持对Mysql数据库进行分片扩展，无需应用程序做太多更改
2.从物理机迁移到云
3.部署和管理mysql实例

vitess基本概念
sharing middleware for Mysql
Massively scalable
HA
Cloud-native
vitess怎么运行
spot
Architecture.jpg
kundb权限部分实现

写博客：maven和pom文件/vitess基本含义


sharing key
cell
keyspace
shard
vtclt
vtctld
vtgate

设置名字和邮箱https://blog.csdn.net/diu_brother/article/details/51982993
// 设置全局
git config --global user.name "Author Name"
git config --global user.email "Author Email"

// 或者设置本地项目库配置
git config user.name "Author Name"
git config user.email "Author Email"

git commit --amend --author="NewAuthor <NewEmail@address.com>"

pwdHistLiveAge -> pwdInHistoryDuration
PWD_IN_HISTORY_DURATION
OLPW_IN_HISTORY_DURATION

Topology

拓扑服务 一个元数据存储，包含有关正在运行的服务器、分片方案和复制图的信息。拓扑由一致的数据存储支持。您可以使用vtctl (命令行) 和 vtctld (web)查看拓扑.

在Kubernetes中，数据存储是etcd。 Vitess源代码还附带Apache ZooKeeper支持。

vtgate

vtgate 是一个轻型代理服务器，它将流量路由到正确的vttablet，并将合并的结果返回给客户端。应用程序向vtgate发起查询。客户端使用起来非常简单，它只需要能够找到vtgate实例就能使vitess。

为了路由查询，vtgate综合考虑了分片方案、数据延迟以及vttablet及其对应底层MySQL实例的可用性。

vttablet

vttablet 是一个位于MySQL数据库前面的代理服务器。vitess实现中每个MySQL实例都有一个vttablet。

执行的任务试图最大化吞吐量，同时保护mysql不受有害查询的影响。它的特性包括连接池、查询重写和重用重复数据。此外，vtTablet执行vtcl启动的管理任务，并提供用于过滤复制和数据导出的流式服务。

通过在MySQL数据库前运行vttablet并更改您的应用程序以使用Vitess客户端而不是MySQL驱动程序，您的应用程序将受益于vttablet的连接池，查询重写和重用数据集等功能。

vtctl

vtctl vtctl是一个用于管理Vitess集群的命令行工具。它允许用户或应用程序轻松地与Vitess实现交互。使用vtctl，您可以识别主数据库和副本数据库，创建表，启动故障转移，执行分片（和重新分片）操作等。

当vtctl执行操作时，它会根据需要更lockserver。其他Vitess服务器会观察这些变化并做出相应的反应。例如，如果使用vtctl故障转移到新的主数据库，则vtgate会查看更改并将将写入流量切到新主服务器。

vtctld

vtctld vtctld是一个HTTP服务器，允许您浏览存储在lockserver中的信息。它对于故障排除或获取服务器及其当前状态的高层概观非常有用。

vtworker

vtworker 托管长时间运行的进程。它支持插件架构并提供代码库，以便您可以轻松选择要使用的vttablet。插件可用于以下类型的作业：

水平拆分或合并过程中检查数据的完整性
垂直拆分或合并过程中检查数据的完整性
vtworker还可以让您轻松添加其他验证程序。例如，如果一个keyspace中的索引表引用到另一keyspace中的数据，则可以执行片内完整性检查以验证类似外键的关系或跨分片完整性检查。

609-682
 @Override
  public List<NodeVo> getAuthorizedDataNodes(PrincipalVo principalVo, PermFilterParams filterParams, boolean includeInherited) throws GuardianException {
    Assert.assertLegal(principalVo);
    ResourceVo parentResourceVo = filterParams.getResourceVo();
    Assert.assertLegal(parentResourceVo);
    try (SqlSession session = sqlSessionFactory.openSession()) {
      PermMapper permMapper = session.getMapper(PermMapper.class);
      String princ = principalVo.getPrincipal();
      PrincipalType princType = principalVo.getPrincipalType();

      ResourceServiceMapper resourceServiceMapper = session.getMapper(ResourceServiceMapper.class);
      ResourceMapper resourceMapper = session.getMapper(ResourceMapper.class);
      // keyword matching can only be done in memory
      Map<Long, ResourceVo> resources = getRequestedResourcesMap(resourceServiceMapper, resourceMapper, filterParams).entrySet()
          .stream().filter(e -> StringUtils.containsKeyword(e.getValue().getDataSource(), filterParams.getSearchValue()))
          .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
      if (MapUtils.isEmpty(resources)) {
        return Collections.emptyList();
      }
      List<Long> resourceIds = new ArrayList<>(resources.keySet());
      String action = filterParams.getAction();

      switch (princType) {
        case USER:
          UserMapper userMapper = session.getMapper(UserMapper.class);
          User user = userMapper.selectUserWithCategory(princ);
          if (user == null || !UserUtil.userPresentable(user)) {
            return Collections.emptyList();
          }
          List<Resource> userResources = new ArrayList<>();
          List<Resource> userSelfResources = permMapper.selectUserAuthorizedDatanodes(princ, resourceIds, action);
          if (userSelfResources != null) {
            userResources.addAll(userSelfResources);
          }
          if (includeInherited) {
            List<Resource> userInheritedResourcesFromRole = permMapper.selectRoleAuthorizedDatanodesByUser(princ, resourceIds, action);
            if (userInheritedResourcesFromRole != null) {
              userResources.addAll(userInheritedResourcesFromRole);
            }

            List<String> groupNames = getPrincParentGroups(session, principalVo);
            userResources.addAll(getInheritDatanodes(session, resourceIds, groupNames, action));
          }
          Set<NodeVo> userAuthorizedDatanodes = new HashSet<>();
          userResources.forEach(resource -> userAuthorizedDatanodes.add((NodeVo) resource.getDataSource());
          return rearrangeResources(userAuthorizedDatanodes);
        case ROLE:
          List<ResourceVo> roleAuthorizedDatanodes = new ArrayList<>();
          List<Resource> roleSelfDatanodes = permMapper.selectRoleAuthorizedDatanodes(princ, resourceIds, action);
          if (CollectionUtils.isNotEmpty(roleSelfDatanodes)) {
            roleSelfDatanodes.forEach(resource -> roleAuthorizedDatanodes.add(new ResourceVo.Builder().dataSource(resource.getDataSource()).build()));
          }
          return roleAuthorizedDatanodes;
        case GROUP:
          List<ResourceVo> groupAuthorizedDatanodes = new ArrayList<>();
          if (includeInherited) {
            List<String> groupNames = getPrincParentGroups(session, principalVo);
            List<Resource> groupDatanodes = new ArrayList<>(getInheritDatanodes(session, resourceIds, groupNames, action));

            groupDatanodes.forEach(resource -> groupAuthorizedDatanodes.add(new ResourceVo.Builder().dataSource(resource.getDataSource()).build()));
            return rearrangeResources(groupAuthorizedDatanodes);
          } else {

            List<Resource> groupDatanodes = permMapper.selectGroupAuthorizedDatanodes(princ, resourceIds, action);
            groupDatanodes.forEach(resource -> groupAuthorizedDatanodes.add(new 
ResourceVo.Builder().dataSource(resource.getDataSource()).build()));
            return groupAuthorizedDatanodes;
          }
      }
      return Collections.emptyList();
    } catch (PersistenceException pe) {
      LOG.error(String.format("Failed to get authorized datanodes of principal [%s] of dataSource [%s] due to persistence exception", principalVo, filterParams.getResourceVo().toString()), pe);
      throw new GuardianException(ErrorCodes.GUARDIAN_SERVER_PERSISTENCE_EXCEPTION, "failed to get authorized datanodes");
    }
  }

A database clustering system for horizontal scaling of MySQL
分片管理
MySQL本身并不提供拆分分片功能，但是您的业务数据量增大到一定程度是您是需要增加集群的。Vitess提供在线拆分功能，只需要很少的时间就完成新集群的切换，无需您在应用程序中添加任何拆分逻辑。
连接池
Vitess避免了MySQL连接的高内存开销。 Vitess服务器轻松地一次处理数千个连接。
工作流
Vitess会跟踪有关集群配置的所有元数据，以便集群拓扑始终是最新的，对不同的客户端保持一致。
性能
Vitess自动重写对数据库性能有损害的查询。它还使用缓存机制来调解查询，并防止重复查询同时到达您的数据库
扩展性
Vitess集Mysql数据库的很多重要特性和NoSQL数据库的可扩展性于一体。其内建拆分分片功能使您能够对您的MySQL数据库集群无限水平扩展，同时无需为应用添加分片逻辑

2.5
什么是rpc

 Modification buildPwdHistory( ModifyOperationContext modifyContext, Attribute pwdHistoryAt,
        int histSize, int pwdHistLiveAge, byte[] newPassword, boolean isPPolicyReqCtrlPresent ) throws LdapOperationException
    {
        List<PasswordHistory> pwdHistLst = new ArrayList<>();
        List<PasswordHistory> pwdHistSortedLst = new ArrayList<>();

        for ( Value<?> value : pwdHistoryAt )
        {
            pwdHistSortedLst.add( new PasswordHistory( Strings.utf8ToString( value.getBytes() ) ) );
        }

        // see the javadoc of PasswordHistory
        Collections.sort( pwdHistSortedLst );

        for ( PasswordHistory pwdh : pwdHistSortedLst )
        {
            // Admin user is exempt from history check
            // https://issues.apache.org/jira/browse/DIRSERVER-2084 
            if ( !modifyContext.getSession().isAnAdministrator() )
            {
                boolean matched = Arrays.equals( newPassword, pwdh.getPassword() );

                if ( matched )
                {
                    if ( pwdHistLiveAge > 0 )
                    {
                        long currentTime = DateUtils.getDate( DateUtils.getGeneralizedTime() ).getTime();
                        long pwdModifiedTime = DateUtils.getDate( pwdh.getTime() ).getTime();
                        if ( ( int ) ( currentTime - pwdModifiedTime ) / 1000 >= pwdHistLiveAge && pwdHistLst.size() >= histSize )
                        {
                            continue;
                        }
                        else
                        {
                            LOG.error( "invalid reuse of password which has {} seconds left to resume", pwdHistLiveAge - ( currentTime - pwdModifiedTime ) / 1000 );
                        }
                    }

                    if ( isPPolicyReqCtrlPresent )
                    {
                        PasswordPolicyDecorator responseControl =
                            new PasswordPolicyDecorator( directoryService.getLdapCodecService(), true );
                        responseControl.getResponse().setPasswordPolicyError(
                            PasswordPolicyErrorEnum.PASSWORD_IN_HISTORY );
                        modifyContext.addResponseControl( responseControl );
                    }

                    throw new LdapOperationException( ResultCodeEnum.CONSTRAINT_VIOLATION,
                        "invalid reuse of password present in password history" );
                }
            }

            pwdHistLst.add( pwdh );
        }
 
        Modification pwdRemHistMod = null;

        if ( pwdHistLst.size() >= histSize && pwdHistLst.size() > 0 )
        {
            if ( pwdHistLiveAge == 0 )
            {
                // remove the oldest value
                PasswordHistory remPwdHist = ( PasswordHistory ) pwdHistLst.toArray()[histSize - 1];
                Attribute tempAt = new DefaultAttribute( pwdHistoryAT );
                tempAt.add( remPwdHist.getHistoryValue() );
                pwdRemHistMod = new DefaultModification( REMOVE_ATTRIBUTE, tempAt );
            }

        }

        return pwdRemHistMod;
    }


 /**
     * Build the list of passwordHistory
     */
    Modification buildPwdHistory( ModifyOperationContext modifyContext, Attribute pwdHistoryAt, 
        int histSize, byte[] newPassword, boolean isPPolicyReqCtrlPresent ) throws LdapOperationException
    {
        List<PasswordHistory> pwdHistLst = new ArrayList<PasswordHistory>();

        for ( Value<?> value : pwdHistoryAt )
        {
            PasswordHistory pwdh = new PasswordHistory( Strings.utf8ToString( value.getBytes() ) );

            // Admin user is exempt from history check
            // https://issues.apache.org/jira/browse/DIRSERVER-2084 
            if ( !modifyContext.getSession().isAnAdministrator() )
            {
                boolean matched = Arrays.equals( newPassword, pwdh.getPassword() );

                if ( matched )
                {
                    if ( isPPolicyReqCtrlPresent )
                    {
                        PasswordPolicyDecorator responseControl =
                            new PasswordPolicyDecorator( directoryService.getLdapCodecService(), true );
                        responseControl.getResponse().setPasswordPolicyError(
                            PasswordPolicyErrorEnum.PASSWORD_IN_HISTORY );
                        modifyContext.addResponseControl( responseControl );
                    }

                    throw new LdapOperationException( ResultCodeEnum.CONSTRAINT_VIOLATION,
                        "invalid reuse of password present in password history" );
                }
            }

            pwdHistLst.add( pwdh );
        }
 
        Modification pwdRemHistMod = null;
        
        if ( pwdHistLst.size() >= histSize )
        {
            // see the javadoc of PasswordHistory
            Collections.sort( pwdHistLst );

            // remove the oldest value
            PasswordHistory remPwdHist = ( PasswordHistory ) pwdHistLst.toArray()[histSize - 1];
            Attribute tempAt = new DefaultAttribute( pwdHistoryAT );
            tempAt.add( remPwdHist.getHistoryValue() );
            pwdRemHistMod = new DefaultModification( REMOVE_ATTRIBUTE, tempAt );
        }

        return pwdRemHistMod;
    }

shift+f6

2.6

golang
语言变量
初始化数组 var balance = [5]float32{1000.0 , 2.0 , 3.4 , 7.0 , 50.0}

guardian->AWS 
hyperbase->base
inceptor->hive+mysql
kundb->vitess
 
go语言结构体
结构体定义需要使用 type 和 struct 语句。struct 语句定义一个新的数据类型，结构体中有一个或多个成员。type 语句设定了结构体的名称。结构体的格式如下：
type Books struct {
title string
author string
subject string
book_id int
}

Go 语言的 For 循环有 3 种形式，只有其中的一种使用分号。
和 C 语言的 for 一样：
for init; condition; post { }
和 C 的 while 一样：
for condition { }
和 C 的 for(;;) 一样：
for { }

go语言切片 slice
Go 语言切片是对数组的抽象。
Go 数组的长度不可改变，在特定场景中这样的集合就不太适用，Go中提供了一种灵活，功能强悍的内置类型切片("动态数组"),与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大。
var identifier []type
var nums []int
s := []
package main

import "fmt"

func main() {
   var numbers = make([]int,3,5)

   printSlice(numbers)
}

func printSlice(x []int){
   fmt.Printf("len=%d cap=%d slice=%v\n",len(x),cap(x),x)
}

Go 语言中 range 关键字用于 for 循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。在数组和切片中它返回元素的索引和索引对应的值，在集合中返回 key-value 对。
package main
import "fmt"
func main(){
   nums := []int{1,2,3,4}
   for i,num := range nums {
      fmt.Printf("索引是%d,长度是%d\n",i, num)
   }
}
输出结果为：
索引是0,长度是1
索引是1,长度是2
索引是2,长度是3
索引是3,长度是4

type Phone interface {
    call()
}

type NokiaPhone struct {
}

func (nokiaPhone NokiaPhone) call() {
    fmt.Println("I am Nokia, I can call you!")
}

2.7
摩尔定律（英语：Moore's law）是由英特尔（Intel）创始人之一戈登·摩尔提出的。其内容为：集成电路上可容纳的晶体管数目，约每隔两年便会增加一倍；经常被引用的“18个月”，是由英特尔首席执行官大卫·豪斯（David House）提出：预计18个月会将芯片的性能提高一倍（即更多的晶体管使其更快），是一种以倍数增长的观测。

摩尔定律的定义归纳起来，主要有以下三种版本：
集成电路上可容纳的晶体管数目，约每隔18个月便增加一倍。
微处理器的性能每隔18个月提高一倍，或价格下降一半。
相同价格所买的电脑，性能每隔18个月增加一倍。

因为在较小规模上一些量子特性开始出现导致漏电等一系列问题，并且精细晶体管成本增加，制造商开始着手从其他方面提高处理器的性能：
1. 向处理器添加越来越多的内核
2. 超线程技术
3. 为处理器加入缓存

Go语言的并发是基于 goroutine 的，goroutine 类似于线程，但并非线程。可以将 goroutine 理解为一种虚拟线程。Go 语言运行时会参与调度 goroutine，并将 goroutine 合理地分配到每个 CPU 中，最大限度地使用CPU性能。开启一个goroutine的消耗非常小（大约2KB的内存），你可以轻松创建数百万个goroutine。

goroutine的特点：

goroutine具有可增长的分段堆栈。这意味着它们只在需要时才会使用更多内存。
goroutine的启动时间比线程快。
goroutine原生支持利用channel安全地进行通信。
goroutine共享数据结构时无需使用互斥锁。

从性能上看，go的性能更接近于java（单核运行某些还是没有java强，但特点是多核处理），而又同C一样是编译型语言执行效率更高


List<String> filterDatabaseByPrivileges(String username, List<String> dbs) throws HiveAuthzPluginException {
    //prepare for filter
    if (!guardianConf.getBoolean(GuardianVars.GUARDIAN_INCEPTOR_FILTER_SHOW_DESCS.varname, GuardianVars.GUARDIAN_INCEPTOR_FILTER_SHOW_DESCS.defaultBoolVal) || CollectionUtils.isEmpty(dbs)) {
      return dbs;
    }

    try {
      //check global privileges
      List<String> dataSource = InceptorPermUtil.global();
      List<PermissionVo> permVos = new ArrayList<>();
      permVos.add(new PermissionVo(component, dataSource, ADMIN_PERM));
      for (GuardianSQLPrivilegeType privilegeType : GuardianSQLPrivilegeType.ALL_ON_TABLE) {
        permVos.add(new PermissionVo(component, dataSource, privilegeType.name()));
      }
      if (guardianClient.checkAnyAccess(username, permVos)) {
        return dbs;
      }

      //filter database
      List<String> dbPerms = guardianClient.userAuthorizedDataNodes(username, component, Collections.singletonList("TABLE_OR_VIEW"), null, null);
      Set<String> dbsWithPrivsSet = new HashSet<>();
      List<String> userOwnedDbs = metastoreClientFactory.getHiveMetastoreClient().getDatabasesWithUser(".*", username, true);
      if (!CollectionUtils.isEmpty(userOwnedDbs)) {
        dbsWithPrivsSet.addAll(userOwnedDbs);
      }
      if (dbPerms != null) {
        for (String db : dbPerms) {
          dbsWithPrivsSet.add(db.toLowerCase());
        }
      }
      List<String> dbsWithPrivs = new ArrayList<>(dbsWithPrivsSet);
      dbsWithPrivs.retainAll(dbs);
      return dbsWithPrivs;
    } catch (GuardianClientException | TException e) {
      LOG.error("Fail to filter DBs by privileges. username: [{}]", username, e);
      throw new HiveAuthzPluginException(e);
    } catch (HiveAuthzPluginException ex) {
      LOG.error("Fail to check if user [{}] is the owner of some database ", username, ex);
      throw ex;
    }
  }










//////////


package io.transwarp.guardian.plugins.inceptor;

import io.transwarp.guardian.abac.core.engine.IPolicyEngine;
import io.transwarp.guardian.abac.core.engine.PolicyEngineFactory;
import io.transwarp.guardian.abac.core.expr.CurrentTimeExpr;
import io.transwarp.guardian.abac.core.expr.ResourceExpr;
import io.transwarp.guardian.abac.core.expr.SourceIpExpr;
import io.transwarp.guardian.client.GuardianClient;
import io.transwarp.guardian.client.GuardianClientFactory;
import io.transwarp.guardian.common.conf.GuardianConfiguration;
import io.transwarp.guardian.common.conf.GuardianConstants;
import io.transwarp.guardian.common.conf.GuardianVars;
import io.transwarp.guardian.common.exception.GuardianClientException;
import io.transwarp.guardian.common.model.*;
import io.transwarp.guardian.common.model.v2.EnvContextVo;
import io.transwarp.guardian.common.model.v2.PolicyResult;
import io.transwarp.guardian.common.model.v2.ResourceVo;
import io.transwarp.guardian.common.util.StringUtils;
import io.transwarp.guardian.plugins.common.constants.PluginConstants;
import io.transwarp.guardian.plugins.common.utils.PermUtil;
import org.apache.commons.collections.CollectionUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.permission.FsAction;
import org.apache.hadoop.hive.conf.HiveConf;
import org.apache.hadoop.hive.ql.ErrorMsg;
import org.apache.hadoop.hive.ql.security.authorization.plugin.*;
import org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.RequiredPrivileges;
import org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLAuthorizationUtils;
import org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLPrivTypeGrant;
import org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLPrivilegeType;
import org.apache.hadoop.hive.ql.session.SessionState;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.*;

import static io.transwarp.guardian.plugins.inceptor.InceptorConstants.*;

/**
 * Created by zhaoliu on 16-8-15.
 */
public class GuardianAuthorizer {
  private static final Logger LOG = LoggerFactory.getLogger(GuardianAuthorizer.class);

  private static final String ADMIN_PERM = "ADMIN";
  private static final String OWNER_PERM = "OWNER";

  private GuardianConfiguration guardianConf;
  private GuardianClient guardianClient;
  private String component;
  private Configuration hiveConf;
  private IPolicyEngine policyEngine;
  private boolean guardianAbacEnabled;

  GuardianAuthorizer(HiveConf hiveConf, GuardianConfiguration guardianConf) throws HiveAuthzPluginException {
    this.hiveConf = hiveConf;
    this.guardianConf = new GuardianConfiguration(guardianConf);
    // get dependent metastore id
    String _component = hiveConf.get(PluginConstants.HIVE_METASTORE_SERVICE_ID);
    if (StringUtils.isEmpty(_component)) {
      _component = hiveConf.get(PluginConstants.HIVE_SERVICE_ID);
      if (StringUtils.isEmpty(_component)) {
        _component = this.guardianConf.get(GuardianVars.GUARDIAN_PERMISSION_COMPONENT.varname, GuardianVars.GUARDIAN_PERMISSION_COMPONENT.defaultVal);
        if (StringUtils.isEmpty(_component)) {
          LOG.error("Configuration {} or {} must be set when initializing GuardianAuthorizer",
                  PluginConstants.HIVE_SERVICE_ID, GuardianVars.GUARDIAN_PERMISSION_COMPONENT.varname);
          // TODO: deal with ErrorMsg
          throw new HiveAuthzPluginException("Configuration guardian.permission.component must be set when initialize GuardianAuthorizer", ErrorMsg.GENERIC_ERROR);
        }
      }
    }

    this.component = _component;
    try {
      this.guardianConf.set(GuardianVars.GUARDIAN_PERMISSION_COMPONENT.varname, component);
      this.guardianClient = GuardianClientFactory.getInstance(this.guardianConf);
    } catch (GuardianClientException e) {
      LOG.error("Fail to initialize Guardian Client when initializing Guardian Authorizer", e);
      // TODO: deal with ErrorMsg
      throw new HiveAuthzPluginException(e,
              "Fail to initialize Guardian Client when initializing Guardian Authorizer", ErrorMsg.GENERIC_ERROR);
    }

    guardianAbacEnabled = this.guardianConf.getBoolean(GuardianVars.GUARDIAN_ABAC_AUTHORIZATION_ENABLED.varname,
            GuardianVars.GUARDIAN_ABAC_AUTHORIZATION_ENABLED.defaultBoolVal);

    if (guardianAbacEnabled) {
      try {
        policyEngine = PolicyEngineFactory.getInstance(this.guardianConf);
        policyEngine.start();
      } catch (GuardianClientException e) {
        LOG.error("Fail to initialize Guardian policy engine when initializing Guardian AccessController", e);
        // TODO: deal with ErrorMsg
        throw new HiveAuthzPluginException(e,
                "Fail to initialize Guardian policy engine when initializing Guardian AccessController", ErrorMsg.GENERIC_ERROR);
      }
    }
  }

  boolean checkAccessPermission(String username) {
    if (guardianAbacEnabled) {
      LOG.debug("Check guardian ABAC policies");
      PolicyResult result = checkPolicy(username, ResourceVo.global(), GuardianConstants.GLOBAL, GuardianConstants.ACCESS_PERM);
      // If the policy result is ALLOW or DENY, return directly. Otherwise check the RBAC
      // TODO: Optimize check several actions for on resource
      if (result == PolicyResult.ALLOW) {
        LOG.debug("Check guardian ABAC policies result is ALLOW, return true");
        return true;
      } else if (result == PolicyResult.DENY) {
        LOG.debug("Check guardian ABAC policies result is DENY, return false");
        return false;
      }
      LOG.debug("Check guardian ABAC policies not applied check the following RBAC");
    }
    return PermUtil.checkGlobalAccess(guardianClient, username);
  }

  boolean checkGlobalPermission(String username, SQLPrivTypeGrant priv) {
    if (guardianAbacEnabled) {
      LOG.debug("Check guardian ABAC policies");
      String action;
      if (priv == SQLPrivTypeGrant.ADMIN_PRIV || priv == SQLPrivTypeGrant.OWNER_PRIV || priv.isWithGrant()) {
        action = ADMIN_PERM;
      } else {
        action = priv.getPrivType().name();
      }

      PolicyResult result = checkPolicy(username, ResourceVo.global(), GuardianConstants.GLOBAL, action);
      // If the policy result is ALLOW or DENY, return directly. Otherwise check the RBAC
      // TODO: Optimize check several actions for on resource
      if (result == PolicyResult.ALLOW) {
        LOG.debug("Check guardian ABAC policies result is ALLOW, return true");
        return true;
      } else if (result == PolicyResult.DENY) {
        LOG.debug("Check guardian ABAC policies result is DENY, return true");
        return false;
      }
      LOG.debug("Check guardian ABAC policies not applied check the following RBAC");
    }

    List<String> global = InceptorPermUtil.global();
    List<PermissionVo> permVos = SQLPrivTypeGrant2Perm(global, priv);
    boolean hasAccess = false;
    try {
      hasAccess = guardianClient.checkAnyAccess(username, permVos);
    } catch (GuardianClientException e) {
      LOG.error("Fail to check permission {} of {} for user {}", permVos, global.toString(), username, e);
    }
    return hasAccess;
  }

  boolean checkPermission(String username, HivePrivilegeObject hiveObj, SQLPrivTypeGrant priv) {
    if (guardianAbacEnabled) {
      LOG.debug("Check guardian ABAC policies");
      PolicyResult result = checkPolicy(username, hiveObj, priv);
      // If the policy result is ALLOW or DENY, return directly. Otherwise check the RBAC
      // TODO: Optimize check several actions for on resource
      if (result == PolicyResult.ALLOW) {
        LOG.debug("Check guardian ABAC policies result is ALLOW, return true");
        return true;
      } else if (result == PolicyResult.DENY) {
        LOG.debug("Check guardian ABAC policies result is DENY, return true");
        return false;
      }
      LOG.debug("Check guardian ABAC policies not applied check the following RBAC");
    }

    //type is of {GLOBAL, DATABASE, TABLE_OR_VIEW, APPLICATION, STREAMJOB}
    HivePrivilegeObject.HivePrivilegeObjectType type = hiveObj.getType();
    List<List<String>> dataSources = new ArrayList<>();
    dataSources.add(InceptorPermUtil.global());
    if (type != null) {
      switch (type) {
        case DATABASE:
          dataSources.add(InceptorPermUtil.convertDatabase(hiveObj.getDbname()));
          break;
        case TABLE_OR_VIEW:
          dataSources.add(InceptorPermUtil.convertDatabase(hiveObj.getDbname()));
          dataSources.add(InceptorPermUtil.convertTable(hiveObj.getDbname(), hiveObj.getObjectName()));
          break;
        case APPLICATION:
          dataSources.add(InceptorPermUtil.convertApplication(hiveObj.getDbname()));
          break;
        case STREAMJOB:
          dataSources.add(InceptorPermUtil.convertApplication(hiveObj.getDbname()));
          dataSources.add(InceptorPermUtil.convertStreamjob(hiveObj.getDbname(), hiveObj.getObjectName()));
          break;
        default:
          break;
      }
    }
    List<PermissionVo> permVos = new ArrayList<>();
    for (List<String> dataSource : dataSources) {
      permVos.addAll(SQLPrivTypeGrant2Perm(dataSource, priv));
    }
    boolean hasAccess = false;
    try {
      hasAccess = guardianClient.checkAnyAccess(username, permVos);
    } catch (GuardianClientException e) {
      LOG.error("Fail to check permission {} on {} for user {}", priv.toString(), hiveObj.toString(), username, e);
    }
    return hasAccess;
  }

  private PolicyResult checkPolicy(String username, HivePrivilegeObject hiveObj, SQLPrivTypeGrant priv) {
    //type is of {GLOBAL, DATABASE, TABLE_OR_VIEW, APPLICATION, STREAMJOB}
    HivePrivilegeObject.HivePrivilegeObjectType type = hiveObj.getType();

    // 1. Get resourceVo
    ResourceVo resourceVo = null;
    String strResource = null;
    if (type != null) {
      switch (type) {
        case DATABASE:
          resourceVo = new ResourceVo.Builder().addNode(DATABASE, hiveObj.getDbname()).build();
          strResource = hiveObj.getDbname();
          break;
        case TABLE_OR_VIEW:
          resourceVo = new ResourceVo.Builder()
                  .addNode(DATABASE, hiveObj.getDbname())
                  .addNode(TABLE, hiveObj.getObjectName())
                  .build();
          strResource = hiveObj.getDbname() + "." + hiveObj.getObjectName();
          break;
        case APPLICATION:
          resourceVo = new ResourceVo.Builder().addNode(APPLICATION, hiveObj.getDbname()).build();
          strResource = hiveObj.getDbname();
          break;
        case STREAMJOB:
          resourceVo = new ResourceVo.Builder()
                  .addNode(APPLICATION, hiveObj.getDbname())
                  .addNode(JOB, hiveObj.getObjectName())
                  .build();
          strResource = hiveObj.getDbname() + "." + hiveObj.getObjectName();
          break;
        default:
          break;
      }
    }

    // 2. Get the action
    String action;
    if (priv == SQLPrivTypeGrant.ADMIN_PRIV || priv == SQLPrivTypeGrant.OWNER_PRIV || priv.isWithGrant()) {
      action = ADMIN_PERM;
    } else {
      action = priv.getPrivType().name();
    }

    if (resourceVo == null) {
      resourceVo = ResourceVo.global();
    }

    // 3. check policy
    return checkPolicy(username, resourceVo, strResource, action);

  }

  private PolicyResult checkPolicy(String username, ResourceVo resourceVo, String strResource, String action) {
    // construct the context
    SessionState sessionState = SessionState.get();
    EnvContextVo contextVo = new EnvContextVo();
    if (sessionState != null) {
      contextVo.put(SourceIpExpr.CONTEXT_KEY, sessionState.getUserIpAddress());
    }
    contextVo.put(ResourceExpr.CONTEXT_KEY, strResource != null ? strResource : GuardianConstants.GLOBAL);
    contextVo.put(CurrentTimeExpr.CONTEXT_KEY, new Date());

    return policyEngine.checkPolicy(username, resourceVo, action, contextVo);
  }

  Collection<SQLPrivTypeGrant> findMissingPrivs(String username, HivePrivilegeObject hiveObj, RequiredPrivileges requiredPrivs, EnumSet<SQLPrivTypeGrant> ownerGrants)
          throws HiveAuthzPluginException {
    List<SQLPrivTypeGrant> missingPrivs = new ArrayList<>();

    boolean isAdmin = ownerGrants.contains(SQLPrivTypeGrant.ADMIN_PRIV) || checkPermission(username, hiveObj, SQLPrivTypeGrant.ADMIN_PRIV);
    if (isAdmin) {
      return missingPrivs;
    }

    for (SQLPrivTypeGrant priv : requiredPrivs.getRequiredPrivilegeSet()) {
      if (ownerGrants.contains(priv)) {
        continue;
      }
      if (!checkPermission(username, hiveObj, priv)) {
        missingPrivs.add(priv);
      }
    }
    return missingPrivs;
  }

  RequiredPrivileges getPrivilegesFromFS(Path filePath, HiveConf conf, String userName)
          throws HiveAuthzPluginException {
    RequiredPrivileges fsPrivs = new RequiredPrivileges();

    // HDFS posix acls
    RequiredPrivileges posixAclPrivs = SQLAuthorizationUtils.getPrivilegesFromFS(filePath, conf, userName);
    Set<SQLPrivTypeGrant> privsSet = posixAclPrivs.getRequiredPrivilegeSet();
    fsPrivs.addAll(privsSet.toArray(new SQLPrivTypeGrant[0]));

    // HDFS acls from guardian
    RequiredPrivileges guardianPrivs = getHdfsPreviledgeFromGuardian(filePath, userName);
    privsSet = guardianPrivs.getRequiredPrivilegeSet();
    fsPrivs.addAll(privsSet.toArray(new SQLPrivTypeGrant[0]));
    return fsPrivs;
  }

  private List<PermissionVo> SQLPrivTypeGrant2Perm(List<String> dataSource, SQLPrivTypeGrant priv) {
    return SQLPrivTypeGrant2Perm(dataSource, priv, false);
  }

  private List<PermissionVo> SQLPrivTypeGrant2Perm(List<String> dataSource, SQLPrivTypeGrant priv, boolean heritable) {
    if (priv == SQLPrivTypeGrant.ADMIN_PRIV || priv == SQLPrivTypeGrant.OWNER_PRIV) {
      return Collections.singletonList(new PermissionVo(component, dataSource, ADMIN_PERM));
    } else {
      if (priv.isWithGrant()) {
        return Arrays.asList(new PermissionVo(component, dataSource, priv.getPrivType().name(), heritable, priv.isWithGrant(), false),
                new PermissionVo(component, dataSource, ADMIN_PERM));
      } else {
        return Collections.singletonList(new PermissionVo(component, dataSource, priv.getPrivType().name(), heritable, priv.isWithGrant(), false));
      }
    }
  }

  private SQLPrivTypeGrant[] Perm2SQLPrivTypeGrant(PermissionVo permVo) {
    List<SQLPrivTypeGrant> privs = new ArrayList<>();
    if (permVo.getAction().equalsIgnoreCase(FsAction.READ.name())) {
      privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.SELECT, false));
      if (permVo.isGrantable()) {
        privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.SELECT, true));
      }
    } else if (permVo.getAction().equalsIgnoreCase(FsAction.WRITE.name())) {
      privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.SELECT, false));
      privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.DELETE, false));
      privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.INSERT, false));
      privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.CREATE, false));
      if (permVo.isGrantable()) {
        privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.SELECT, true));
        privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.DELETE, true));
        privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.INSERT, true));
        privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(SQLPrivilegeType.CREATE, true));
      }
    } else if (permVo.getAction().equalsIgnoreCase(ADMIN_PERM)) {
      privs.add(SQLPrivTypeGrant.ADMIN_PRIV);
    } else if (permVo.getAction().equalsIgnoreCase(OWNER_PERM)) {
      privs.add(SQLPrivTypeGrant.OWNER_PRIV);
    } else {
      try {
        SQLPrivilegeType priv = Enum.valueOf(SQLPrivilegeType.class, permVo.getAction());
        privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(priv, false));
        if (permVo.isGrantable()) {
          privs.add(SQLPrivTypeGrant.getSQLPrivTypeGrant(priv, true));
        }
      } catch (RuntimeException e) {
        // ignore
      }
    }
    return privs.toArray(new SQLPrivTypeGrant[0]);
  }

  RequiredPrivileges getPrivileges(HivePrivilegeObject obj, String username) throws HiveAuthzPluginException {
    List<String> globalDS = InceptorPermUtil.global();
    List<String> objDS = InceptorPermUtil.convert(obj);
    RequiredPrivileges privs = new RequiredPrivileges();
    List<List<String>> dataSources = new ArrayList<>();
    dataSources.add(globalDS);
    if (obj.getType() == HivePrivilegeObject.HivePrivilegeObjectType.TABLE_OR_VIEW) {
      List<String> database = InceptorPermUtil.convertDatabase(obj.getDbname());
      dataSources.add(database);
    }
    dataSources.add(objDS);
    for (List<String> dataSource : dataSources) {
      try {
        List<PermissionVo> permVos = guardianClient.userPermissions(username, component, dataSource);
        if (permVos != null) {
          for (PermissionVo permVo : permVos) {
            privs.addAll(Perm2SQLPrivTypeGrant(permVo));
          }
        }
      } catch (GuardianClientException e) {
        LOG.error("Fail to obtain permission for component: {}, dataSource: {} for user: {}",
                component, dataSource, username, e);
        throw new HiveAuthzPluginException(e);
      }
    }

    // read owner information from metastore or its cache
    // TODO: take roles into consideration, but current it is a time waste and unusual to use
    long startTime = System.nanoTime();
    if (SQLAuthorizationUtils.isOwner(username, Collections.EMPTY_LIST, obj)) {
      privs.addPrivilege(SQLPrivTypeGrant.OWNER_PRIV);
    }
    long endTime = System.nanoTime();
    LOG.debug("Time to check ownership cost " + (endTime - startTime) + " ns for " + obj.toString());

    return privs;
  }

  /**
   * In the path uri it has been normalized, and replace "//", ".", ".." with corresponding characters
   * Guardian permission
   * @param filePath
   * @param userName
   * @return
   */
  public RequiredPrivileges getHdfsPreviledgeFromGuardian(Path filePath, String userName) {
    List<PermissionVo> permVos = new ArrayList<>();
    String path = filePath.toUri().getPath();
    while (path.length() > 1 && path.endsWith("/")) {
      path = path.substring(0, path.length() - 1);
    }
    boolean atRoot = false;
    while ((!StringUtils.isEmpty(path)) && (!atRoot)) {
      if (path.equals("/")) atRoot = true;
      // Try to get the dependent hdfs component
      String component = hiveConf.get(PluginConstants.HDFS_SERVICE_ID);
      List<String> dataSource = InceptorPermUtil.convertHdfsPath(path);
      try {
        permVos = guardianClient.userPermissions(userName, component, dataSource);
      } catch (GuardianClientException e) {
        LOG.error("Fail to obtain permission for {} in component {} of user {} in Guardian",
               dataSource, component, userName, e);
      }
      if (permVos != null && permVos.size() > 0) break;
      path = path.substring(0, path.lastIndexOf(Path.SEPARATOR_CHAR));
      while (path.length() > 1 && path.endsWith("/")) {
        path = path.substring(0, path.length() - 1);
      }
      if (StringUtils.isEmpty(path)) path = "/";
    }
    RequiredPrivileges privs = new RequiredPrivileges();
    if (permVos != null) {
      for (PermissionVo perm : permVos) {
        privs.addAll(Perm2SQLPrivTypeGrant(perm));
      }
    }
    return privs;
  }

  void authorizeGrant(String userName, List<HivePrivilege> hivePrivileges, HivePrivilegeObject hivePrivObject)
          throws HiveAuthzPluginException, HiveAccessControlException {
    // check whether user has global admin permission
    if (checkGlobalPermission(userName, SQLPrivTypeGrant.ADMIN_PRIV)) {
      return;
    }

    // check whether user has the permissions with grant option
    RequiredPrivileges reqPrivs = new RequiredPrivileges();
    for (HivePrivilege hivePriv : hivePrivileges) {
      reqPrivs.addPrivilege(hivePriv.getName(), true /* grant priv required */);
    }
    RequiredPrivileges availPrivs = getPrivileges(hivePrivObject, userName);
    List<String> deniedMessages = new ArrayList<>();
    Collection<SQLPrivTypeGrant> missingPrivs = reqPrivs.findMissingPrivs(availPrivs, /*ownerAsAdmin*/ false);
    SQLAuthorizationUtils.addMissingPrivMsg(missingPrivs, hivePrivObject, deniedMessages);
    SQLAuthorizationUtils.assertNoDeniedPermissions(new HivePrincipal(userName,
            HivePrincipal.HivePrincipalType.USER), HiveOperationType.GRANT_PRIVILEGE, deniedMessages);
  }

  boolean isUserAdmin(String userName) {
    return checkGlobalPermission(userName, SQLPrivTypeGrant.ADMIN_PRIV);
  }

  List<String> showQuota(List<QuotaVo> quotaVos) throws HiveAuthzPluginException {
    List<String> result = new ArrayList<>();
    for (QuotaVo quotaVo : quotaVos) {
      try {
        quotaVo = guardianClient.readQuota(quotaVo);
        if (quotaVo == null || quotaVo.getProperties().get("spaceQuota") == null) {
          result.add("unlimited");
        } else {
          result.add(spaceQuotaToString(((Number)quotaVo.getProperties().get("spaceQuota")).longValue()));
        }
      } catch (GuardianClientException e) {
        LOG.error("Failed to read quota {}", quotaVo);
        throw new HiveAuthzPluginException(e);
      }
    }
    return result;
  }

  List<String> getAllRoles() throws HiveAuthzPluginException {
    List<String> roles = new ArrayList<>();
    try {
      List<RoleVo> roleVos = guardianClient.getRoles();
      if (roleVos != null) {
        for (RoleVo roleVo : roleVos) {
          roles.add(roleVo.getRoleName());
        }
      }
    } catch (GuardianClientException e) {
      LOG.error("Failed to list all roles", e);
      throw new HiveAuthzPluginException(e);
    }
    return roles;
  }

  // TODO: check hierarchy roles inherited
  List<String> getRoles(String userName) throws HiveAuthzPluginException {
    List<String> roles = new ArrayList<>();
    try {
      UserVo userVo = guardianClient.getUser(userName);
      if (userVo != null) {
        if (userVo.getRoles() != null) {
          roles.addAll(userVo.getRoles());
        }
        if (hasAdminRole(userName)) {
          roles.add("ADMIN");
        }
      }
    } catch (GuardianClientException e) {
      LOG.error("Failed to read user: {}", userName, e);
      throw new HiveAuthzPluginException(e);
    }
    return roles;
  }

  boolean hasAdminRole(String userName) throws HiveAuthzPluginException {
    try {
      return guardianClient.checkAccess(userName, InceptorPermUtil.global(component, "ADMIN"));
    } catch (GuardianClientException e) {
      LOG.error("Failed to check access with Guardian", e);
      throw new HiveAuthzPluginException(e);
    }
  }

  List<HivePrivilegeInfo> listPrivilege(String principalName, HivePrincipal.HivePrincipalType principalType,
                                          HivePrivilegeObject privObj) throws HiveAuthzPluginException {
    List<HivePrivilegeInfo> privInfos = new ArrayList<HivePrivilegeInfo>();
    List<String> dataSource = InceptorPermUtil.convert(privObj);
    try {
      List<EntityPermissionVo> epVos;
      if ((principalName == null && privObj.getType() == null)
        || privObj.getType() == HivePrivilegeObject.HivePrivilegeObjectType.GLOBAL) {
        // if neither principal nor object is specified, show all GLOBAL privileges
        epVos = guardianClient.searchPermissions(component, InceptorPermUtil.global());
      } else if (privObj.getType() == null) {
        // if object is not specified, filter all the permissions
        epVos = guardianClient.searchPermissions(principalName, convert(principalType), component,
                null, true);
      } else {
        epVos = guardianClient.searchPermissions(component, dataSource);
      }
      for (EntityPermissionVo epVo : epVos) {
        if (StringUtils.isEmpty(principalName)
                || (principalName.equals(epVo.getName()) && convert(epVo.getPrincipalType()) == principalType )) {
          HivePrincipal principal = new HivePrincipal(epVo.getName(), convert(epVo.getPrincipalType()));
          HivePrivilege priv = new HivePrivilege(epVo.getPermissionVo().getAction(), null);
          HivePrivilegeObject targetObj = InceptorPermUtil.convertFromDataSource(epVo.getPermissionVo().getDataSource());
          boolean grantOption = epVo.getPermissionVo().isGrantable();
          HivePrivilegeInfo privInfo = new HivePrivilegeInfo(principal, priv, targetObj,
                  new HivePrincipal("N/A", HivePrincipal.HivePrincipalType.USER), grantOption, 0);
          privInfos.add(privInfo);
        }
      }
    } catch (GuardianClientException e) {
      LOG.error("Failed to search permissions for {} of {}: {}", dataSource, principalType.name(), principalName);
      throw new HiveAuthzPluginException(e);
    }
    return privInfos;
  }

  List<HiveRoleGrant> getPrincipalGrantInfoForRole(String roleName) throws HiveAuthzPluginException {
    List<HiveRoleGrant> roleGrants = new ArrayList<>();
    try {
      RoleVo roleVo = guardianClient.getRole(roleName);
      if (roleVo.getUsers() != null) {
        for (String user : roleVo.getUsers()) {
          HiveRoleGrant roleGrant = getHiveRoleGrant(roleName, user, PrincipalType.USER.name());
          roleGrants.add(roleGrant);
        }
      }
      if (roleVo.getGroups() != null) {
        for (String group : roleVo.getGroups()) {
          HiveRoleGrant roleGrant = getHiveRoleGrant(roleName, group, PrincipalType.GROUP.name());
          roleGrants.add(roleGrant);
        }
      }
      if (roleVo.getChildren() != null) {
        for (String role : roleVo.getChildren()) {
          HiveRoleGrant roleGrant = getHiveRoleGrant(roleName, role, PrincipalType.ROLE.name());
          roleGrants.add(roleGrant);
        }
      }
    } catch (GuardianClientException e) {
      LOG.error("Failed to get role for role {}", roleName, e);
      throw new HiveAuthzPluginException(e);
    }
    return roleGrants;
  }

  List<HiveRoleGrant> getRoleGrantInfoForPrincipal(HivePrincipal principal) throws HiveAuthzPluginException {
    List<HiveRoleGrant> roleGrants = new ArrayList<>();
    if (principal == null) return roleGrants;
    try {
      switch (principal.getType()) {
        case USER:
          UserVo userVo = guardianClient.getUser(principal.getName());
          if (userVo.getRoles() != null) {
            for (String role : userVo.getRoles()) {
              roleGrants.add(getHiveRoleGrant(role, userVo.getUserName(), PrincipalType.USER.name()));
            }
          }
          break;
        case GROUP:
          GroupVo groupVo = guardianClient.getGroup(principal.getName());
          if (groupVo.getRoles() != null) {
            for (String role : groupVo.getRoles()) {
              roleGrants.add(getHiveRoleGrant(role, groupVo.getGroupName(), PrincipalType.GROUP.name()));
            }
          }
          break;
        case ROLE:
          RoleVo roleVo = guardianClient.getRole(principal.getName());
          if (roleVo.getParents() != null) {
            for (String role : roleVo.getParents()) {
              roleGrants.add(getHiveRoleGrant(role, roleVo.getRoleName(), PrincipalType.ROLE.name()));
            }
          }
      }
    } catch (GuardianClientException e) {
      LOG.error("Failed to get role for {}: {}", principal.getType().name(), principal.getName(), e);
      throw new HiveAuthzPluginException(e);
    }
    return roleGrants;
  }

  List<String> filterDatabaseByPrivileges(String username, List<String> dbs) throws HiveAuthzPluginException {
    try {
      // check global privilege
      // note: do not check GLOBAL ACCESS here since it has already been checked on SQL compiling stage
      List<String> dataSourceOfGlobal = InceptorPermUtil.global();
      List<PermissionVo> permVos = new ArrayList<>();
      permVos.add(new PermissionVo(component, dataSourceOfGlobal, ADMIN_PERM));
      // note: do not check GLOBAL CREATE here
      for (GuardianSQLPrivilegeType privilegeType : GuardianSQLPrivilegeType.ALL_ON_TABLE) {
        permVos.add(new PermissionVo(component, dataSourceOfGlobal, privilegeType.name()));
      }
      if (guardianClient.checkAnyAccess(username, permVos)) {
        return dbs;
      }

      // filter databases
      List<String> authorizedDbs = guardianClient.userAuthorizedDataNodes(username, component, Collections.singletonList("TABLE_OR_VIEW"), null, null);
      Set<String> authorizedDbSet = new HashSet<>();
      if (CollectionUtils.isNotEmpty(authorizedDbs)) {
        for (String db : authorizedDbs) {
          authorizedDbSet.add(db.toLowerCase());
        }
      }
      return new ArrayList<>(authorizedDbSet);
    } catch (GuardianClientException e) {
      LOG.error("Fail to filter databases by privileges from Guardian with user: [{}] ", username, e);
      throw new HiveAuthzPluginException(e);
    }
  }

  List<String> filterTablesByPrivileges(String username, String dbName, List<String> tables) throws HiveAuthzPluginException {
    try {
      // check global and db privileges
      // note: do not check GLOBAL ACCESS here since it has already been checked on SQL compiling stage
      List<String> dataSourceOfGlobal = InceptorPermUtil.global();
      List<String> dataSourceOfDb = InceptorPermUtil.convertDatabase(dbName);
      List<PermissionVo> permVos = new ArrayList<>();
      permVos.add(new PermissionVo(component, dataSourceOfGlobal, ADMIN_PERM));
      permVos.add(new PermissionVo(component, dataSourceOfDb, ADMIN_PERM));
      for (GuardianSQLPrivilegeType privilegeType : GuardianSQLPrivilegeType.ALL_ON_TABLE) {
        permVos.add(new PermissionVo(component, dataSourceOfGlobal, privilegeType.name()));
        permVos.add(new PermissionVo(component, dataSourceOfDb, privilegeType.name()));
      }
      if (guardianClient.checkAnyAccess(username, permVos)) {
        return tables;
      }

      // filter tables
      List<String> authorizedTables = guardianClient.userAuthorizedDataNodes(username, component, InceptorPermUtil.convertDatabase(dbName), null, null);
      Set<String> authorizedTableSet = new HashSet<>();
      if (CollectionUtils.isNotEmpty(authorizedTables)) {
        for (String table : authorizedTables) {
          authorizedTableSet.add(table.toLowerCase());
        }
      }
      return new ArrayList<>(authorizedTableSet);
    } catch (GuardianClientException e) {
      LOG.error("Fail to filter tables by privileges from Guardian with user: [{}], dbName:[{}]", username, dbName, e);
      throw new HiveAuthzPluginException(e);
    }
  }

  private HivePrincipal.HivePrincipalType convert(PrincipalType princType) {
    if (princType == null) return null;
    switch (princType) {
      case USER:
        return HivePrincipal.HivePrincipalType.USER;
      case GROUP:
        return HivePrincipal.HivePrincipalType.GROUP;
      case ROLE:
        return HivePrincipal.HivePrincipalType.ROLE;
      default:
        return HivePrincipal.HivePrincipalType.UNKNOWN;
    }
  }

  private PrincipalType convert(HivePrincipal.HivePrincipalType princType) {
    if (princType == null) return null;
    switch (princType) {
      case USER:
        return PrincipalType.USER;
      case GROUP:
        return PrincipalType.GROUP;
      case ROLE:
        return PrincipalType.ROLE;
      default:
        return null;
    }
  }

当在一个函数执行过程中调用panic()函数时，正常的函数执行流程将立即终止，但函数中 之前使用defer关键字延迟执行的语句将正常展开执行，之后该函数将返回到调用函数，并导致 逐层向上执行panic流程，直至所属的goroutine中所有正在执行的函数被终止。错误信息将被报 告，包括在调用panic()函数时传入的参数，这个过程称为错误处理流程。
////