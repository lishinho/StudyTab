20200316
D00F1BDTGF-eyJsaWNlbnNlSWQiOiJEMDBGMUJEVEdGIiwibGljZW5zZWVOYW1lIjoiaHR0cHM6Ly96aGlsZS5pbyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiJVbmxpbWl0ZWQgbGljZW5zZSB0aWxsIGVuZCBvZiB0aGUgY2VudHVyeS4iLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJNIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRE0iLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUFMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiODkwNzA3MC8wIiwiZ3JhY2VQZXJpb2REYXlzIjowLCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-3OPFIX9/KSL76ctAKOwpBPCCAfUhUbucdNbtqMaTqRryvKEvrFqCKncE0eMHA2YkrcP2CtV9LKjlIXhJMqp0N821Qv1AhuIJrDMBubqiEtiqnGkcGV35DF0GzyUQaUdN6fTbZna05riHzR6yzgEzo9R3RIzCTDMQdB/0EojWM0nCBkPsLdncZeDv3+Y+VA8ZH3/BBvzwR1e0gWsT3mfT9tIvwxPuEhNrQFNOP1PZOjC8nX9h/J7ag5X3JQL1CQVi4TnEipdy0fxKbDPKTloM3Y/bA23uaW+Q/JQFBRKRR0q3FYJ1DQuSc7YmeJ7Q2IHq7u5QYz8jPZJtP6PKs6g/tQ==-MIIECDCCAfCgAwIBAgIJAI5/xwNtz47cMA0GCSqGSIb3DQEBCwUAMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0EwIBcNMTgwODIzMDcwNDA3WhgPMjExODA3MzAwNzA0MDdaMBExDzANBgNVBAMMBnByb2QzeTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOZ3WopNRg9J8k3apGYFEUGRlvkRsQnQSEz1yMKY4YWg9ElxmuF0mQRAaIj3WOl1eqTn1CXsn4vXV7GODJk9A/rCqEk960sPesWn/RVz7zo5+KazE3Y9yYtwskKxlnkFNp82Kha6dUGDSwG2lYh0Sria2ByOhgr6gmyXtC0PKqlIlTAPcBvz0MEnKTZkxfSqdiHo/meTlMRd9885vr4P52Fd9Ryxe3yVAKZSP9ZzPmRvCvgF1oGCgobZJ5d7FvTwkGt2t4pjy/RlU6FDcXNMHLk4pfJqr3lnEkAh2MbCGlGo1i6Rc6DtgISuJn2AUkrQKhI6F0U7o9e5qPEOjNkhznMCAwEAAaNaMFgwCQYDVR0TBAIwADALBgNVHQ8EBAMCBaAwHQYDVR0OBBYEFJDgSMx4XrLktYOG827wP7VULTnJMB8GA1UdIwQYMBaAFDAS51akWaJlzxC2x4yP3iAYbqtxMA0GCSqGSIb3DQEBCwUAA4ICAQBxRyfCpL7q2VurGfh9XqaC4GsGp6ut3l/rOEyc6DP148A69DRmZ7saqfZW87DcLkmcynPhyBOxdcGwtwKlR9E/+X923JeL6VPQCTY5WyJKib36vQCnoC4ELTnw1yc51v2j+MaZXjrlzBIcCUocWK14WS4iBycUwLuMszz6rJ8xluuYDKDeNcS/AjQf+yTUfDXjktHLgcE27sSEQUQ+7bpbKHkJ5xBvaupJEPX+ndj7V2eD+/sO03jgnsWVa2nky7yDXX/5KCqzL5kAA1n2t2dWSJXxpac8O2bPyRhk6dUSwzNr+IjCjHqUKIouB0nosi85Q5MaIE0pwOOSggnawpnjmL3qDnsS/n7NUcX/mF4eiNQ8cMJmKIgfS6rntKuQY2zSod+4+G0AFbiihVTnKsRf7CiJa/VniZdaGdbclT8KzRnNKJ1TrPO8rVPjg+SpvqTq75xynS08/OXCpoJ3aVeBWZJYJmheHhvJw2RiNW2P2GSIw+m6HIIsthUtvvHqdKpIaThFHAOKmw0LpPO7uGs/z/Q3un7+lqSlW7akUoSCHdiAJ4wWv+qFEgE4mq8bKtHoa9yy6FZBoORbbRTj8WkS+UvCLN5p7kZenmKYnWCzBf02O1ULpMsR5WvKCGCekSwWf3lAF9lYTL12JaFTw9iH1nSkyvcu7AoXlWI50hOhmA==

DEADLINE_EXCEEDED
clientDeadline := time.Now().Add(time.Duration(*deadlineMs) * time.Millisecond)
ctx, cancel := context.WithDeadline(ctx, clientDeadline)

工作周报 - 李镇邦 20200309 ~ 20200313

完成：
1. WARP-41394/WARP-41542:复现确定现有状态已解决
2. WARP-41406: mysql语句status显示user不正确，wiki: http://172.16.1.168:8090/pages/viewpage.action?pageId=23486935
3. WARP-41389: 不存在的用户赋权隐式创建，mysql8.0功能，暂时提交review
4. WARP-42372: ip功能修理产品化，merge
5. WARP-41627： guardian在v1和v2创建获取下一层/所有子层的接口

进行中：
1. WARP-42372: grpc idletime部分需要功能确定，ip部分配置文件配到manager-info上
超时时间

本周：
1. 完成WARP-42372的工作，及WARP-41406的方案确定


mysql -h127.0.0.1 -P15307 -uvt_app -p123 --enable-cleartext-plugin
-audit_log_dir $logDir/kungate/public/audit \

-ip_config "$KUNDB_CONF_DIR/ip_config.json" \
-grpc_ip_config "./ip_config.json" \

-mysql_ldap_auth_config_file "$KUNDB_CONF_DIR/guardian.json" \

autoReconnect

重连时用户名，密码在buffer持续多久问题
--skip-reconnect

user() 内置函数在哪里实现 库中的元信息？
vtgate里面已经转化成sql语句了

meta-info:http://172.16.1.41:10080/lishinho/application-metainfo/blob/dev/TDH%205.0%20service%20standard.md
/var/lib/transwarp-manager/master/content/meta/services/KUNDB

scp -r file path

-ip_config "$KUNDB_CONF_DIR/ip_config.json"

service transwarp-manager restart 服务重启


1.关于grpc的idletime，在WARP-42372，和宾哥开会讨论后是因为waterdrop的密码写在配置里，导致重连时用户没有感应，本身goaway报文断开了grpc的channel连接，这部分安全方面应该做在waterdrop的重连密码设置上，已开jira。关于原生mysql的wait-timeout对应这方面功能 不过测过由于tablet分布没法设置全局，所以讨论后目前还是我提交的方案。
2. mysql的idletime本身也有一段缓存重连的时间，这段时间断开用户不需提供密码重连，我会调查下缓存重连持续的时间，到时候提交给你们和宾哥。
3. ip文件已写在metainfo上 jiraWARP-42372提交给你了，本地测过可以生成配置服务表，功能work，你再看一下

0317
1. mysql缓存机制密码存留多久->没有时间限制，只有数据库切换或关闭服务时断开 满足数据库wait-wimeout的时候也会重连 关闭重连开关的是--skip-reconnect 例如mysql -h127.0.0.1 -P15307 -uvt_app -p123 --enable-cleartext-plugin --skip-reconnect
waterdrop--有缓存机制？show可以，grpc执行修改不行 
  -grpc_connection_idle_time 20s \
  -grpc_max_connection_age 10s \
channel置为idle->发送goaway包->等待10s没有重连->关闭channel
2. mysql内置函数改动

【docker安装】
2004  docker images;l
 2005  docker run -it 9b5 bash
 2006  docker run -itd --name mysql-test -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 9b5 
 2007  docker ps
 2008  docker exec -it mysql bash
 2009  docker exec -it mysql-test bash
 2010  docker run -itd --name mysql- -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 9b5
 2011  docker ps
 2012  docker exec -it mysql bash
 2013  cd /opt
 2014  mkdir -p docker_v/mysql/conf
 2015  sudo mkdir -p docker_v/mysql/conf
 2016  cd docker_v/mysql/conf/
 2017  touch my.cnf
 2018  sudo touch my.cnf
 2019  docker run -p 3306:3306 --name mysql -v /opt/docker_v/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 -d 9b5
 2020  docker ps
 2021  mysql -hlocalhost -uroot -p
 2022  docker exec -it mysql bash
 2023  history 20

【kundb 证书】
mysql -h127.0.0.1 -P15307 -uvt_app -p123 --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA

 mysql -h127.0.0.1 -P15307 -uvt_app -p123 --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA --enable-cleartext-plugin
mysql采用host来区分用户，所以有user()和currentuser()的概念，而kunDB由于架构上的不同，不需要再重复认证user，并且没有host在mysql中的区分（比如172.%.%.%)导致user()在kundb没用，成为bug

ComStatistics:
【COM_STATISTICS】

E0317 13:37:32.776510   26649 vtgate.go:1470] Execute: target: _mfed.0.master, used tablet: test-800 (transwarp-Latitude-5480), vttablet: rpc error: code = Unknown desc = Unknown system variable 'user' (errno 1193) (sqlstate HY000) during query: select @@user from dual where 1 != 1, CallerID: vt_app, request: map[Session:autocommit:true options:<included_fields:ALL > session_id:"\242x\202\250vfI\364\220\332\374\302]\263\241\222"  Sql:select @@user BindVariables:map[]]
E0317 13:37:32.776816   26649 vtgate.go:448] SQLLog: Session Info: a27882a8-7666-49f4-90da-fcc25db3a192 , Executed sql: select @@user, BindVariables: map[], Cost: 8.668729ms, Error: vtgate: http://transwarp-Latitude-5480:15001/: target: _mfed.0.master, used tablet: test-800 (transwarp-Latitude-5480), vttablet: rpc error: code = Unknown desc = Unknown system variable 'user' (errno 1193) (sqlstate HY000) during query: select @@user from dual where 1 != 1, CallerID: vt_app
W0317 13:38:02.768334   26649 server.go:411] killing connection (exceeded idleTimeout: 30s)
I0317 17:41:22.070091   26649 plugin_mysql_server.go:98] rollback because of ongoing transaction
I0317 17:41:22.071409   26649 vtgate.go:445] SQLLog: Session Info: a27882a8-7666-49f4-90da-fcc25db3a192 , Executed sql: rollback, BindVariables: map[], Cost: 963.81µs
I0317 17:41:24.171028   26649 vtgate.go:445] SQLLog: Session Info: 3e2a024f-5641-43c8-a78b-1fc44a527281 , Executed sql: show databases, BindVariables: map[], Cost: 4.56031ms
W0317 17:41:54.166648   26649 server.go:411] killing connection (exceeded idleTimeout: 30s)


I0318 10:01:34.741908   15178 conn.go:323] zk conn: session for addr localhost:21811,localhost:21812,localhost:21813 event: {EventNodeDataChanged Unknown /kundb/test/SrvVSchema <nil> }
I0318 10:01:34.763192   15178 conn.go:323] zk conn: session for addr localhost:21811,localhost:21812,localhost:21813 event: {EventNodeDataChanged Unknown /kundb/test/SrvVSchema <nil> }
I0318 10:01:34.764279   15178 auth_server_ldap.go:62] Not configuring AuthServerLdap because mysql_ldap_auth_config_file and mysql_ldap_auth_config_string are empty
I0318 10:01:34.765174   15178 service_map.go:65] Registering vtgateservice for grpc, disable it with -grpc-vtgateservice service_map parameter
I0318 10:01:34.782715   15178 grpc_server.go:164] Listening for gRPC calls on port 15991
I0318 10:01:34.782936   15178 unix_socket.go:36] Not listening on socket file
I0318 10:03:33.652183   15178 vtgate.go:465] here2 is select @@version_comment limit 1
I0318 10:03:33.653172   15178 executor.go:377] It is select @@version_comment limit 1
I0318 10:03:33.661826   15178 vtgate.go:448] SQLLog: Session Info: 67b6dc77-a7cf-4205-8411-e55c9b2c81cc , Executed sql: select @@version_comment limit 1, BindVariables: map[vtg1:type:INT64 value:"1" ], Cost: 9.465047ms
I0318 10:03:40.552823   15178 vtgate.go:465] here2 is show databases
I0318 10:03:40.555739   15178 vtgate.go:448] SQLLog: Session Info: 67b6dc77-a7cf-4205-8411-e55c9b2c81cc , Executed sql: show databases, BindVariables: map[], Cost: 2.874968ms

mysql/server->plugin_mysql_server->vtgate.go->executor.go

分支WARP-41406-a：jdbc加计时器+comstatistics报文处理+mysql端idletime日志修改+status user()替换

select DATABASE(), USER()

select DATABASE(), USER() limit 1


mysql> select @@session.wait_timeout;
+------------------------+
| @@session.wait_timeout |
+------------------------+
|                  28800 |
+------------------------+
1 row in set (0.01 sec)

mysql> set @@session.interactive_timeout = 20;
ERROR 1105 (HY000): vtgate: http://transwarp-Latitude-5480:15001/: unsupported construct: set @@session.interactive_timeout = 20
mysql> set @@session.wait_timeout = 20;
ERROR 1105 (HY000): vtgate: http://transwarp-Latitude-5480:15001/: unsupported construct: set @@session.wait_timeout = 20

1. waterdrop有鬼。连接上执行不了命令
2. 本身mysql支持这一功能 kungate语法不支持，idletime是vtgate之前的一段，mysql是连接数据库之后的一段
3. grpc的功能是work的，无法验证复现

【登镜像mysql】：
transwarp@transwarp-Latitude-5480:~$ mysql -h127.0.0.1 -P3306 -uroot -p123456
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 11
Server version: 8.0.19 MySQL Community Server - GPL

Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
4 rows in set (0.01 sec)

mysql/server->plugin_mysql_server->vtgate.go->executor.go->mysql


[postgreSQL]

    <property>
        <name>guardian.txsql.connection.username</name>
        <value>pguser</value>
    </property>
    <property>
        <name>guardian.txsql.connection.password</name>
        <value>Warp1234</value>
    </property>


//第一步
            Statement stat = conn.createStatement();
            String command = "select * from orders";
            ResultSet result =  stat.executeQuery(command);

            //按行读取查询结果当中的数据
            while(result.next()) {
                //使用访问器方法获取信息
                System.out.println(result.getString(1) + " " +  result.getString(2) + " " + result.getString(3) );
            }
            result.close();
            return conn;
        }
        catch(Exception e) {
            e.printStackTrace();//异常处理
            return null;
        }


transwarp@transwarp-Latitude-5480:~/workHub$ mysql -h172.26.5.94 -P15307 -ulzb -p --enable-cleartext-plugin
Enter password: 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 4
Server version: KunDB-1.3.0 MariaDB Server

Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+-----------+
| Databases |
+-----------+
| _mfed     |
| kundb1    |
+-----------+
2 rows in set (0.01 sec)

mysql> use kundb1;
Database changed
mysql> show databases;
+-----------+
| Databases |
+-----------+
| _mfed     |
| kundb1    |
+-----------+
2 rows in set (0.00 sec)

mysql> show tables;
ERROR 1044 (42000): vtgate: http://tw-node594:15001/: target: _mfed.0.master, used tablet: transwarp-800 (tw-node595), vttablet: rpc error: code = Unknown desc = Access denied for user 'lzb'@'%' to database 'kundb1' (errno 1044) (sqlstate 42000) during query: USE kundb1, CallerID: lzb

【grpc keepalive无效】
1. goaway包只通知对方不要在已有连接上新建流，client端不作处理就无效
2. goaway包本身不限制对方重连


	
	// InitUser is for creating user
	InitUser(user string) error

create user/role是dcl语句

1.空闲时间部分grpc的参数不生效 大概是因为client部分没有接受goaway包的设置 / 为了适配功能在jdbc写了定时器，jdbc连接和waterdrop连接都work，可配置
2.新jira WARP-41378未经授权查看database：
这个问题其实已经解决了的，现在kundb初始时看不到数据库，就不需要授权了；
关于ldap认证后可进入mysql客户端没什么问题，所有用户都有public的usage权限，初始化没可见库就没有权限需要做的事了；
关于连接认证后要重新create user才能使用，觉得这个是产品使用方式的问题，也不需要改，我在本地写了个demo，以后如果需要的话可以提交


HDFS 透明加密算法支持SM4商密算法
现在很多涉密客户需要用国产加密算法
SM4算法本身应该是实现好的

hdfs kms
kms key management server
guardian-utils provides common utilities for guardian projects

/usr/lib/guardian/lib/guardian-utils-guardian-3.1.2.jar

<dependency>
        <groupId>jdk.tools</groupId>
        <artifactId>jdk.tools</artifactId>
        <version>1.8</version>
        <scope>system</scope>
        <systemPath>${JAVA_HOME}/lib/tools.jar</systemPath>
    </dependency>

/usr/lib/jvm/jdk1.7.0_71
jdk1.7.0_71

export JAVA_HOME_7=/usr/lib/jvm/jdk1.7.0_71

export JAVA_HOME_8=/usr/lib/jvm/default-java

alias jdk1.7="export JAVA_HOME=$JAVA_HOME_7 && JAVA_HOME = /usr/lib/jvm/jdk1.7.0_71 && source /etc/profile"

alias jdk1.8="export JAVA_HOME=$JAVA_HOME_8 && JAVA_HOME = /usr/lib/jvm/default-java && source /etc/profile"

transwarp@transwarp-Latitude-5480:~/Downloads/work/hadoop-2.7.2-transwarp$ source /etc/profile
transwarp@transwarp-Latitude-5480:~/Downloads/work/hadoop-2.7.2-transwarp$ mvn -version
OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=2048m; support was removed in 8.0
Apache Maven 3.6.2 (40f52333136460af0dc0d7232c0dc0bcf0d9e117; 2019-08-27T23:06:16+08:00)
Maven home: /home/transwarp/Downloads/apache-maven-3.6.2
Java version: 1.8.0_242, vendor: Private Build, runtime: /usr/lib/jvm/java-8-openjdk-amd64/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.15.0-88-generic", arch: "amd64", family: "unix"
transwarp@transwarp-Latitude-5480:~/Downloads/work/hadoop-2.7.2-transwarp$ JAVA_HOME=$JAVA_HOME_
$

hdfs需要jdk7+protobuf
2020-03-19 20:08:17,443 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby
        at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
        at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1785)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1409)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:6196)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1119)
        at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:142)
        at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2225)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2221)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:2197)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2219)

        at org.apache.hadoop.ipc.Client.call(Client.java:1485)
        at org.apache.hadoop.ipc.Client.call(Client.java:1422)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
        at com.sun.proxy.$Proxy20.rollEditLog(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:148)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:273)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:315)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:284)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:301)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:356)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:2177)
        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:436)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:297)
2020-03-19 20:08:33,529 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2020-03-19 20:08:35,736 INFO io.transwarp.guardian.client.cache.PeriodCacheUpdater: Fetch change version: 6
2020-03-19 20:08:45,035 INFO org.apache.hadoop.ipc.Server: Socket Reader #1 for port 8020: readAndProcess from client 172.16.1.238 threw exception [org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, OAUTHBEARER, KERBEROS]]
org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, OAUTHBEARER, KERBEROS]
        at org.apache.hadoop.ipc.Server$Connection.initializeAuthContext(Server.java:1705)
        at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1661)
        at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:897)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:753)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:724)
2020-03-19 20:08:47,875 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for hdfs/tw-node1237@TDH (auth:KERBEROS)
2020-03-19 20:08:47,886 INFO SecurityLogger.org.apache.hadoop.security.authorize.ServiceAuthorizationManager: Authorization successful for hdfs/tw-node1237@TDH (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
2020-03-19 20:08:47,887 INFO org.apache.hadoop.ipc.Server: IPC Server handler 42 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 172.16.1.237:36430 Call#33 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2020-03-19 20:08:50,798 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby

[root@tw-node1238 log]# kubectl logs hadoop-hdfs-namenode-hdfs1-69ff856999-9q6sf -c hadoop-hdfs-namenode-hdfs1


	<dependency>
      <groupId>io.transwarp.guardian.common</groupId>
      <artifactId>gm-crypto</artifactId>
      <version>guardian-3.2.0</version>
    </dependency>


明加密技术是近年来针对企业文件保密需求应运而生的一种文件加密技术。它是指对使用者来说是无感知的。当使用者在打开或编辑指定文件时，系统将自动对未加密的文件进行加密，对已加密的文件自动解密。文件在硬盘上是密文，在内存中是明文。一旦离开使用环境，由于应用程序无法得到自动解密的服务而无法打开，从而起来保护文件内容的效果。

jce-aes
算法/模式/填充         16字节加密后数据长度         不满16字节加密后长度
AES/CBC/NoPadding              16                         不支持
AES/CBC/PKCS5Padding           32                         16
AES/CBC/ISO10126Padding        32                         16

分组密码有五种工作体制：1.电码本模式（Electronic Codebook Book (ECB)）；2.密码分组链接模式（Cipher Block Chaining (CBC)）；3.计算器模式（Counter (CTR)）；4.密码反馈模式（Cipher FeedBack (CFB)）；5.输出反馈模式（Output FeedBack (OFB)）。
hadoop.security.crypto.cipher.suite -> main/resource/core-default
common/crypto/key/keyproviderCryptoExtension
1801
<property>
  <name>hadoop.security.crypto.cipher.suite</name>
  <value>AES/CTR/NoPadding</value>
  <description>
    Cipher suite for crypto codec.
  </description>
</property>

<property>
  <name>hadoop.security.crypto.jce.provider</name>
  <value></value>
  <description>
    The JCE provider name used in CryptoCodec. 
  </description>
</property>


CA/JCE

    概念简单解析
    1） Java密码学架构(Java Cryptography Architecture 简称JCA)
    Java平台重视安全性，包括语言安全性，密码学，公钥基础设施，身份验证，安全通行和访问控制。JCA是JDk平台上非常重要的部分，通过包含一个 “provider”架构，设计了一套API为包括 数字签名、消息摘要、证书和证书验证、加密(对称和非对称，分组和流式密码)、秘钥生成和管理、安全随机码生成等功能服务。

JCA是Java平台安全的基础，其它相关的还有Java密码学拓展(Java Cryptography Extension 简称JCE)、Java Secure Socket Extension (JSSE) 、Java Generic Security Services (JGSS)

JCA在设计之初就遵循一些基本原则，也就是
实现的独立性和互操作性
算法的独立性和可扩展性
应用无需实现具体的安全算法，或者说应用请求来自Java平台的安全服务

    int var3 = this.engineUpdate(var1, var2);
    var3 += this.implDoFinal(var2);
    return var3;


  protected int engineDoFinal(ByteBuffer var1, ByteBuffer var2) throws ShortBufferException, IllegalBlockSizeException, BadPaddingException {
    int var3 = this.engineUpdate(var1, var2);
    var3 += this.implDoFinal(var2);
    return var3;
  }



private int implUpdate(ByteBuffer var1, ByteBuffer var2) throws ShortBufferException {
    int var3 = var1.remaining();
    if (var3 <= 0) {
      return 0;
    } else {
      int var4 = var2.remaining();
      if (var4 < this.updateLength(var3)) {
        throw new ShortBufferException();
      } else {
        int var5 = var1.position();

        try {
          this.ensureInitialized();
          long var6 = 0L;
          int var8 = 0;
          byte[] var9 = null;
          if (var1 instanceof DirectBuffer) {
            var6 = ((DirectBuffer)var1).address();
            var8 = var5;
          } else if (var1.hasArray()) {
            var9 = var1.array();
            var8 = var5 + var1.arrayOffset();
          }

          long var10 = 0L;
          int var12 = 0;
          byte[] var13 = null;
          if (var2 instanceof DirectBuffer) {
            var10 = ((DirectBuffer)var2).address();
            var12 = var2.position();
          } else if (var2.hasArray()) {
            var13 = var2.array();
            var12 = var2.position() + var2.arrayOffset();
          } else {
            var13 = new byte[var4];
          }

          int var14 = 0;
          if (this.encrypt) {
            if (var6 == 0L && var9 == null) {
              var9 = new byte[var3];
              var1.get(var9);
            } else {
              var1.position(var5 + var3);
            }

            var14 = this.token.p11.C_EncryptUpdate(this.session.id(), var6, var9, var8, var3, var10, var13, var12, var4);
          } else {
            int var15 = 0;
            if (this.paddingObj != null) {
              if (this.padBufferLen != 0) {
                if (this.padBufferLen != this.padBuffer.length) {
                  int var16 = this.padBuffer.length - this.padBufferLen;
                  if (var3 <= var16) {
                    this.bufferInputBytes(var1, var3);
                    return 0;
                  }

                  this.bufferInputBytes(var1, var16);
                  var8 += var16;
                  var3 -= var16;
                }

                var14 = this.token.p11.C_DecryptUpdate(this.session.id(), 0L, this.padBuffer, 0, this.padBufferLen, var10, var13, var12, var4);
                this.padBufferLen = 0;
              }

              var15 = var3 & this.blockSize - 1;
              if (var15 == 0) {
                var15 = this.padBuffer.length;
              }

              var3 -= var15;
            }

            if (var3 > 0) {
              if (var6 == 0L && var9 == null) {
                var9 = new byte[var3];
                var1.get(var9);
              } else {
                var1.position(var1.position() + var3);
              }

              var14 += this.token.p11.C_DecryptUpdate(this.session.id(), var6, var9, var8, var3, var10, var13, var12 + var14, var4 - var14);
            }

            if (this.paddingObj != null && var15 != 0) {
              this.bufferInputBytes(var1, var15);
            }
          }

          this.bytesBuffered += var3 - var14;
          if (!(var2 instanceof DirectBuffer) && !var2.hasArray()) {
            var2.put(var13, var12, var14);
          } else {
            var2.position(var2.position() + var14);
          }

          return var14;
        } catch (PKCS11Exception var17) {
          var1.position(var5);
          if (var17.getErrorCode() == 336L) {
            throw (ShortBufferException)((ShortBufferException)(new ShortBufferException()).initCause(var17));
          } else {
            this.reset();
            throw new ProviderException("update() failed", var17);
          }
        }
      }
    }
  }

20200323

工作周报 - 李镇邦 20200316 ~ 20200320

完成：
1. WARP-42372: ip部分配置文件配到manager-info上， idletime功能在JDBC客户端上重写并测试提交
2. WARP-41406: bug修复在KunDB vtgate重写，添加mysql协议com_statistics报文的路径
3. WARP-43034: guardian-util部分 SM4算法补充/学习hdfs透明加密部分确定实现方案
4. 验证KunDB几个jira的重复提交


进行中：
1. WARP-43034: hadoop-common部分透明加密对SM4算法的支持

本周：
1. 继续WARP-43034的工作并完成集群上验证



    ByteBuffer encryptedBuf = ByteBuffer.allocate(160);
    ByteBuffer decryptedBuf = ByteBuffer.allocate(160);
    ByteBuffer tmp = ByteBuffer.allocate(160);

  // byte[]转化成ByteBuffer
  public ByteBuffer encodeValue(byte[] value) {
    ByteBuffer byteBuffer = ByteBuffer.wrap(value);
    return byteBuffer;
  }
 
  // ByteBuffer转化成byte[]
  public byte[] decodeValue(ByteBuffer bytes) {
    int len = bytes.limit() - bytes.position();
    byte[] bytes1 = new byte[len];
    bytes.get(bytes1);
    return bytes1;
  }


      encryptedBuf = ByteBuffer.allocate(64);
      decryptedBuf = ByteBuffer.allocate(64);
      cipher.init(GMCipher.Mode.ENCRYPT, TestConstants.KEY_SPEC, spec);
      cipher.doFinal(ByteBuffer.wrap(TestConstants.PLAIN_32), encryptedBuf);
      encryptedBuf.flip();
      cipher.init(GMCipher.Mode.DECRYPT, TestConstants.KEY_SPEC, spec);
      cipher.doFinal(encryptedBuf, decryptedBuf);
      decryptedBuf.flip();
      Assert.assertArrayEquals(TestConstants.PLAIN_32, decodeValue(decryptedBuf));


将目前目录下的所有档案与子目录的拥有者皆设为 users 群体的使用者 lamport :
chmod -R lamport:users *
-rw------- (600) – 只有属主有读写权限。
-rw-r–r-- (644) – 只有属主有读写权限；而属组用户和其他用户只有读权限。
-rwx------ (700) – 只有属主有读、写、执行权限。
-rwxr-xr-x (755) – 属主有读、写、执行权限；而属组用户和其他用户只有读、执行权限。
-rwx–x--x (711) – 属主有读、写、执行权限；而属组用户和其他用户只有执行权限。
-rw-rw-rw- (666) – 所有用户都有文件读、写权限。这种做法不可取。
-rwxrwxrwx (777) – 所有用户都有读、写、执行权限。更不可取的做法。
以下是对目录的两个普通设定:

drwx------ (700) - 只有属主可在目录中读、写。
drwxr-xr-x (755) - 所有用户可读该目录，但只有属主才能改变目录中的内容。

将目前目录下的所有档案与子目录皆设为任何人可读取 :
chmod -R a+r *

txsql lost connection 在同步配置文件删除重新安装
=====================================================
About to bootstrap Standby ID nn2 from:
           Nameservice ID: nameservice1
        Other Namenode ID: nn1
  Other NN's HTTP address: http://tw-node1237:50070
  Other NN's IPC  address: tw-node1237/172.16.1.237:8020
             Namespace ID: 1901437855
            Block pool ID: BP-1305439193-172.16.1.237-1584964775894
               Cluster ID: hdfs1
           Layout version: -63
       isUpgradeFinalized: true
=====================================================
2020-03-23 19:59:48,606 INFO common.Storage: Storage directory /vdir/hadoop/hadoop_image has been successfully formatted.
2020-03-23 19:59:48,614 INFO common.Storage: Storage directory /vdir/hadoop/namenode_dir has been successfully formatted.
2020-03-23 19:59:48,671 WARN common.Util: Path /vdir/hadoop/hadoop_image should be specified as a URI in configuration files. Please update hdfs configuration.
2020-03-23 19:59:48,672 WARN common.Util: Path /vdir/hadoop/namenode_dir should be specified as a URI in configuration files. Please update hdfs configuration.
2020-03-23 19:59:48,672 WARN common.Util: Path /vdir/hadoop/hadoop_image should be specified as a URI in configuration files. Please update hdfs configuration.
2020-03-23 19:59:48,673 WARN common.Util: Path /vdir/hadoop/namenode_dir should be specified as a URI in configuration files. Please update hdfs configuration.
2020-03-23 19:59:49,111 INFO namenode.TransferFsImage: Opening connection to http://tw-node1237:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1901437855:0:hdfs1
2020-03-23 19:59:49,246 INFO namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-03-23 19:59:49,339 INFO namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-23 19:59:49,340 INFO namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 316 bytes.
2020-03-23 19:59:49,353 INFO util.ExitUtil: Exiting with status 0
2020-03-23 19:59:49,355 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at tw-node1238/172.16.1.238
************************************************************/
++ date
+ echo 'Format Standby Namenode in HA mode on Mon' Mar 23 19:59:49 CST 2020
+ '[' true == false ']'
+ '[' false = true ']'
+ '[' false = true ']'
+ sudo -u hdfs /bin/bash -c 'cd /home/hdfs; /bin/transwarp/namenode.sh'
-Dproc_namenode -Xmx5927m -Dsun.net.inetaddr.ttl=60 -Djava.net.preferIPv4Stack=true -Dhadoop.log.dir=/var/log/hdfs1 -Dhadoop.log.file=hadoop-hdfs-namenode-tw-node1238.log -Dhadoop.home.dir=/usr/lib/hadoop/ -Dhadoop.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.id.str=hdfs -Dhadoop.security.logger=INFO,RFAS -Dcom.sun.management.jmxremote -XX:+UseConcMarkSweepGC -XX:+ExplicitGCInvokesConcurrent -Dhdfs.audit.logger=INFO,NullAppender -Djava.net.preferIPv4Stack=true -Djava.library.path=/lib/native -Dtranswarp.maintenance.only.mode=true
[root@tw-node1236 conf]# ls

transwarp@transwarp-Latitude-5480:~/Downloads/work/hadoop-2.7.2-transwarp/hadoop-common-project$ mvn -version
OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=2048m; support was removed in 8.0
Apache Maven 3.6.2 (40f52333136460af0dc0d7232c0dc0bcf0d9e117; 2019-08-27T23:06:16+08:00)
Maven home: /home/transwarp/Downloads/apache-maven-3.6.2
Java version: 1.8.0_242, vendor: Private Build, runtime: /usr/lib/jvm/java-8-openjdk-amd64/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.15.0-88-generic", arch: "amd64", family: "unix"
transwarp@transwarp-Latitude-5480:~/Downloads/work/hadoop-2.7.2-transwarp/hadoop-common-project$ source /etc/profile
transwarp@transwarp-Latitude-5480:~/Downloads/work/hadoop-2.7.2-transwarp/hadoop-common-project$ JAVA_HOME=$JAVA_HOME_7
transwarp@transwarp-Latitude-5480:~/Downloads/work/hadoop-2.7.2-transwarp/hadoop-common-project$ mvn -version
Apache Maven 3.6.2 (40f52333136460af0dc0d7232c0dc0bcf0d9e117; 2019-08-27T23:06:16+08:00)
Maven home: /home/transwarp/Downloads/apache-maven-3.6.2
Java version: 1.7.0_71, vendor: Oracle Corporation, runtime: /usr/java/jdk1.7.0_71/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.15.0-88-generic", arch: "amd64", family: "unix"

kubectl logs//

我猜可能是hdfs初始化创建znode失败，不过我有个事情要处理下，你可以先看下 boot.sh 中有关 format zk的部分

kinit xxx
klist
gaurdain预制用户密码随机 要自己重置

hdfs的ha模式开安全前zookeeper要先开安全 否则znode就会创建失败

 1008  kubectl cp hadoop-hdfs-datanode-hdfs1-655bf86b76-mc8zh:tmp/hive/hive/dc4726a1-f2ab-425e-88ff-ea27490f9f1e data2
1005  kubectl cp hadoop-hdfs-datanode-hdfs1-655bf86b76-mc8zh:/root/hive/hive/dc4726a1-f2ab-425e-88ff-ea27490f9f1e data1

0000
[root@tw-node1237 usr]# kubectl exec -it hadoop-hdfs-datanode-hdfs1-655bf86b76-mc8zh bash
[root@tw-node1238 ~]# kinit keyadmin
Password for keyadmin@TDH: 
[root@tw-node1238 ~]# hadoop key create inceptor1-key
2020-03-24 16:18:45,385 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
inceptor1-key has not been created. java.io.IOException: Key inceptor1-key already exists
java.io.IOException: Key inceptor1-key already exists
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:157)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:546)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:504)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKeyInternal(KMSClientProvider.java:677)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKey(KMSClientProvider.java:685)
	at org.apache.hadoop.crypto.key.KeyShell$CreateCommand.execute(KeyShell.java:483)
	at org.apache.hadoop.crypto.key.KeyShell.run(KeyShell.java:79)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.crypto.key.KeyShell.main(KeyShell.java:515)
[root@tw-node1238 ~]# kinit hdfs
Password for hdfs@TDH: 
[root@tw-node1238 ~]# klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: hdfs@TDH

Valid starting       Expires              Service principal
03/24/2020 16:18:54  03/25/2020 16:18:54  krbtgt/TDH@TDH
	renew until 03/31/2020 16:18:54
[root@tw-node1238 ~]# hadoop fs -mkdir /inceptor1-encrypt
2020-03-24 16:19:26,315 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
[root@tw-node1238 ~]# ls
anaconda-ks.cfg
[root@tw-node1238 ~]# cd /
[root@tw-node1238 /]# ls
anaconda-post.log  dev   lib         media  proc  sbin  tmp  vdir
bin                etc   lib64       mnt    root  srv   usr
data               home  lost+found  opt    run   sys   var
[root@tw-node1238 /]# hadoop fs -chown hive:hive /inceptor-encrypt
2020-03-24 16:20:21,332 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
chown: `/inceptor-encrypt': No such file or directory
[root@tw-node1238 /]# hadoop fs -chown hive:hive /inceptor1-encrypt
2020-03-24 16:20:36,401 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
ptor1-encrypt
2020-03-24 16:21:32,991 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
Added encryption zone /inceptor1-encrypt
[root@tw-node1238 /]# kinit hive
Password for hive@TDH: 
[root@tw-node1238 /]# ls
anaconda-post.log  dev   lib         media  proc  sbin  tmp  vdir
bin                etc   lib64       mnt    root  srv   usr
data               home  lost+found  opt    run   sys   var
[root@tw-node1238 /]# hdfs dfs -lsr /
lsr: DEPRECATED: Please use 'ls -R' instead.
2020-03-24 16:23:28,999 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
drwx--x--x   - hive hive            0 2020-03-24 15:20 /inceptor1
drwxr-xr-x   - hive hive            0 2020-03-24 15:20 /inceptor1/tmp
drwxrwxrwx   - hive hive            0 2020-03-24 15:20 /inceptor1/tmp/hive
drwxr-xr-x   - hive hive            0 2020-03-24 16:14 /inceptor1/tmp/hive/hive
drwxr-xr-x   - hive hive            0 2020-03-24 16:14 /inceptor1/tmp/hive/hive/dc4726a1-f2ab-425e-88ff-ea27490f9f1e
drwxr-xr-x   - hive hive            0 2020-03-24 16:14 /inceptor1/tmp/hive/hive/dc4726a1-f2ab-425e-88ff-ea27490f9f1e/_tmp_space.db
drwxr-xr-x   - hive hive            0 2020-03-24 15:20 /inceptor1/tmp/hive/hive/e7ce6137-6f65-42ee-8a27-ee3dfffbbd04
drwxr-xr-x   - hive hive            0 2020-03-24 15:20 /inceptor1/tmp/hive/hive/e7ce6137-6f65-42ee-8a27-ee3dfffbbd04/_tmp_space.db
drwxr-xr-x   - hive hive            0 2020-03-24 16:19 /inceptor1-encrypt
drwxrwxrwt   - hdfs hadoop          0 2020-03-24 15:15 /tmp
drwxrwxrwt   - hdfs hadoop          0 2020-03-24 15:15 /user
drwxr-xr-x   - hdfs hbase           0 2020-03-24 15:17 /yarn1
drwxrwxrwt   - yarn hadoop          0 2020-03-24 15:17 /yarn1/user
drwxrwxrwt   - yarn hadoop          0 2020-03-24 15:17 /yarn1/user/history
drwxrwx---   - yarn hadoop          0 2020-03-24 15:17 /yarn1/user/history/done
drwxrwxrwt   - yarn hadoop          0 2020-03-24 15:17 /yarn1/user/history/done_intermediate
drwxr-xr-x   - hdfs hbase           0 2020-03-24 15:17 /yarn1/var
drwxr-xr-x   - hdfs hbase           0 2020-03-24 15:17 /yarn1/var/log
drwxr-xr-x   - hdfs hbase           0 2020-03-24 15:17 /yarn1/var/log/hadoop-yarn
drwxrwxrwt   - yarn hadoop          0 2020-03-24 15:17 /yarn1/var/log/hadoop-yarn/apps
[root@tw-node1238 /]# hdfs dfs -get /inceptor1/tmp/* ~/
2020-03-24 16:24:56,380 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
[root@tw-node1238 /]# cd ~
[root@tw-node1238 ~]# ls
anaconda-ks.cfg  hive
[root@tw-node1238 ~]# hadoop fs -cp /inceptor1/* /inceptor1-encrypt
2020-03-24 16:25:48,564 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
[root@tw-node1238 ~]# hadoop fs -mv /inceptor1 /inceptor1-bak
2020-03-24 16:26:26,080 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
mv: Permission denied: user=hive, access=WRITE, inode="/":hdfs:hbase:drwxr-xr-x in the default POSIX ACLs, nor is granted permission in Guardian service
[root@tw-node1238 ~]# hadoop fs -mv /inceptor1 /inceptor1-bak
2020-03-24 16:28:00,548 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
mv: Permission denied: user=hive, access=WRITE, inode="/":hdfs:hbase:drwxr-xr-x in the default POSIX ACLs, nor is granted permission in Guardian service
[root@tw-node1238 ~]# hadoop fs -mv /inceptor1 /inceptor1-bak
2020-03-24 16:28:54,602 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
[root@tw-node1238 ~]# hadoop fs -mv /inceptor1-encrypt /inceptor1
2020-03-24 16:30:01,481 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
[root@tw-node1238 ~]# hdfs dfs -get /inceptor1/tmp/* /tmp/
2020-03-24 16:30:51,067 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
[root@tw-node1238 ~]# ls
anaconda-ks.cfg  hive
[root@tw-node1238 ~]# cd hive/
[root@tw-node1238 hive]# ls
hive
[root@tw-node1238 hive]# cd hive/
[root@tw-node1238 hive]# ls
dc4726a1-f2ab-425e-88ff-ea27490f9f1e  e7ce6137-6f65-42ee-8a27-ee3dfffbbd04
[root@tw-node1238 hive]# pwd
/root/hive/hive
[root@tw-node1238 hive]# cd ..
[root@tw-node1238 hive]# 
[root@tw-node1238 hive]# pwd
/root/hive
[root@tw-node1238 hive]# cd /tmp
[root@tw-node1238 tmp]# ls
hive  hsperfdata_hdfs  hsperfdata_root  Jetty_localhost_57424_datanode____.v0ko79  krb5cc_0  ks-script-HVSw8G
[root@tw-node1238 tmp]# cd hive
[root@tw-node1238 hive]# ls
hive
[root@tw-node1238 hive]# cd hive/
[root@tw-node1238 hive]# ls
dc4726a1-f2ab-425e-88ff-ea27490f9f1e  e7ce6137-6f65-42ee-8a27-ee3dfffbbd04
[root@tw-node1238 hive]# pwd
/tmp/hive/hive

. 以 keyadmin 身份登录，执行以下命令创建 inceptor 加密秘钥

   hadoop key create inceptor1-key
. 以 hdfs 身份登录，执行以下命令创建加密区

  hadoop fs -mkdir /inceptor1-encrypt

  hadoop fs -chown hive:hive /inceptor1-encrypt

  hdfs crypto -createZone -keyName inceptor1-key -path /inceptor1-encrypt

4. 停止 inceptor 服务或者确保 inceptor 没有新的数据写入

5. 以 hive 身份登录，将 Inceptor 数据拷贝到加密区

  hadoop fs -cp /inceptor1/* /inceptor1-encrypt

[root@tw-node1238 /]# hdfs dfs -get /inceptor1/tmp/* ~/
2020-03-24 16:24:56,380 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST

6. 备份原始数据，并将加密数据目录移动到加密区

  hadoop fs -mv /inceptor1 /inceptor1-bak

  hadoop fs -mv /inceptor1-encrypt /inceptor1

7. 测试 Inceptor 数据是否完整能访问，确认后删除备份的Inceptor数据 (/inceptor1-bak)


[root@tw-node1236 ~]# kinit admin
Password for admin@TDH: 
=hive/tw-node1236@TDH"eeline -u "jdbc:hive2://localhost:10000/default;principal 
Java HotSpot(TM) 64-Bit Server VM warning: Using the ParNew young collector with the Serial old collector is deprecated and will likely be removed in a future release
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/inceptor/lib/graphsearch-hive-2.0.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/inceptor/lib/shiva-client-shade-1.3.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/inceptor/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
scan complete in 5ms
Connecting to jdbc:hive2://localhost:10000/default;principal=hive/tw-node1236@TDH


2020-03-24 17:59:25,677 INFO  [Thread-1] util.KerberosUtil (KerberosUtil.java:getDefaultPrincipalPattern(81)) - Using principal pattern: HTTP/_HOST
Error: java.sql.SQLException: Failed to open new session: java.lang.RuntimeException: java.lang.RuntimeException: The root scratch dir: hdfs://nameservice1/inceptor1/tmp/hive on HDFS should be writable. Current permissions are: rwxr-xr-x (state=,code=0)
2020-03-24 17:59:26,590 INFO  [main] jdbc.Utils (Utils.java:parseURL(304)) - Supplied authorities: tw-node1237:10000
2020-03-24 17:59:26,591 INFO  [main] jdbc.Utils (Utils.java:parseURL(391)) - Resolved authority: tw-node1237:10000
Error: java.sql.SQLException: Failed to open new session: java.lang.RuntimeException: java.lang.RuntimeException: The root scratch dir: hdfs://nameservice1/inceptor1/tmp/hive on HDFS should be writable. Current permissions are: rwxr-xr-x (state=,code=0)
[root@tw-node1236 ~]# 

hadoop fs -chown hive:hive /inceptor1-encrypt

验证文件加密：
1. hdfs fsck / -files -block  
[root@tw-node1237 ~]# hdfs fsck /inceptor1/IamTest -files -blocks -locations

2. find /data/0 -name blk_xxxx
[root@tw-node1236 ~]# cd /hadoop/data
[root@tw-node1236 data]# find ./ -name blk_1073741827_1003*
./current/BP-1730406967-172.16.1.237-1585034092308/current/finalized/subdir0/subdir0/blk_1073741827_1003.meta
[root@tw-node1236 data]# mv ./current/BP-1730406967-172.16.1.237-1585034092308/current/finalized/subdir0/subdir0/blk_1073741827_1003.meta ~/data/
[root@tw-node1236 data]# pwd
/hadoop/data

3. vim 


[root@tw-node1237 ~]# history 5
    2  hadoop fs -mv /inceptor1 /inceptor1-bak
    3  hadoop fs -mv /inceptor1-encrypt /inceptor1
    4  hdfs dfs -rmr /inceptor1-encrypt
    5  hdfs dfs -lsr /
    6  history 5

[root@tw-node1237 lib]# cd ../..
[root@tw-node1237 lib]# find ./ -name hadoop-common-2.7.2-transwarp-6.2.1.jar*
./hadoop/hadoop-common-2.7.2-transwarp-6.2.1.jar
[root@tw-node1237 lib]# find ./ -name hadoop-common-2.7.2-transwarp*
./hadoop/hadoop-common-2.7.2-transwarp-6.2.1.jar
[root@tw-node1237 lib]# cd hadoop
[root@tw-node1237 hadoop]# pwd
/usr/lib/hadoop
[root@tw-node1237 hadoop]# 


    命令格式
    hdfs dfs -rm 目标文件
    hdfs dfs -rmr 目标文件 递归删除（慎用）使用用例
    hdfs dfs -rm /user/test.txt 删除test.txt文件
    hdfs dfs -rmr /user/testdir 递归删除testdir文件夹
    注：rm不可以删除文件夹

^@^A^B^@^@^B^@
\<87>?



    1  cd /usr/lib
    2  ls
    3  cd hadoop
    4  ls
    5  cd ~
    6  ls
    7  kinit hive
    8  hdfs dfs -ls /
    9  hdfs dfs -lsr /
   10  hdfs dfs -rmr /inceptor1-encrypt
   11  hadoop fs -mkdir /inceptor1-encrypt
   12  hdfs dfs -ls /
   13  hdfs dfs -lsr /
   14  hadoop fs -cp /inceptor1/* /inceptor1-encrypt
   15  hdfs dfs -lsr /
   16  hadoop fs -cat /inceptor1-encrypt/user/sm4/sm4Test
   17  hdfs fsck /inceptor1-encrypt/user/sm4/sm4Test -files -blocks -locations
   18  history 30

传统数据管理软件/硬件堆栈中的加密可以在不同的层完成。选择在给定层加密具有不同的优点和缺点。

应用程序级加密。这是最安全和最灵活的方法。应用程序对加密的内容有最终的控制，并且可以精确地反映用户的要求。但是，编写应用程序来做到这一点很困难。对于不支持加密的现有应用程序的客户来说，这也不是一种选择。

数据库级加密。类似于应用程序级加密的属性。大多数数据库供应商提供某种形式的加密 但是，可能会有性能问题。一个例子是索引不能被加密。

文件系统级加密。该选项提供了高性能，应用程序透明性，并且通常易于部署。但是，它无法模拟某些应用程序级别的策略。例如，多租户应用程序可能希望基于最终用户进行加密。数据库可能需要对存储在单个文件中的每个列进行不同的加密设置。

磁盘级加密。易于部署和高性能，但也相当不灵活。只有真正防止物理盗窃。

HDFS级别的加密适用于此堆栈中的数据库级和文件系统级加密。这有很多积极的影响。HDFS加密能够提供良好的性能，现有的Hadoop应用程序能够在加密的数据上透明地运行。在制定策略决策时，HDFS也比传统的文件系统具有更多的上下文。

HDFS级加密还可以防止在文件系统级和以下的攻击（所谓的“OS级攻击”）。操作系统和磁盘只与加密的字节交互，因为数据已经被HDFS加密了。

[root@tw-node1237 ~]# hadoop key create sm4-key
2020-03-25 14:12:34,578 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
sm4-key has not been created. java.io.IOException: HTTP status [500], exception [java.lang.reflect.UndeclaredThrowableException], message [null] 
java.io.IOException: HTTP status [500], exception [java.lang.reflect.UndeclaredThrowableException], message [null] 
	at org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:159)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:546)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:504)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKeyInternal(KMSClientProvider.java:677)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKey(KMSClientProvider.java:685)
	at org.apache.hadoop.crypto.key.KeyShell$CreateCommand.execute(KeyShell.java:483)
	at org.apache.hadoop.crypto.key.KeyShell.run(KeyShell.java:79)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.crypto.key.KeyShell.main(KeyShell.java:515)


[root@tw-node1238 ~]# hadoop key create hdfs1-key
2020-03-25 11:48:57,895 INFO util.KerberosUtil: Using principal pattern: HTTP/_HOST
hdfs1-key has been successfully created with options Options{cipher='AES/CTR/NoPadding', bitLength=128, description='null', attributes=null}.
KMSClientProvider[http://tw-node1238:16000/kms/v1/] has been updated.
[root@tw-node1238 ~]# [root@tw-node1236 data]# 



Setting `dfs.encrypt.data.transfer.cipher.suites` to `AES/CTR/NoPadding` activates AES encryption. By default, this is unspecified, so AES is not used. When AES is used, the algorithm specified in `dfs.encrypt.data.transfer.algorithm` is still used during an initial key exchange. The AES key bit length can be configured by setting `dfs.encrypt.data.transfer.cipher.key.bitlength` to 128, 192 or 256. The default is 128.


// IPConfigList is the struct for ip constraints
type IPConfigList struct {
	BlackListIP []string
	WhiteListIP []string
}

// MatchIPInList is to match ip in IPlist
func MatchIPInList(IPlist []string, remoteAddr string) bool {
	for _, ip := range IPlist {
		reg, err := regexp.Compile(ip)
		if err != nil {
			log.Errorf("Failed to compile to regexp: %v", err)
		}
		if reg.MatchString(remoteAddr) {
			return true
		}
	}
	return false
}

func (c *Conn) handleIPList() error {
	data, err := ioutil.ReadFile(*ipConfig)
	if err != nil {
		log.Errorf("Failed to read ipConfig file: %v", err)
		return err
	}

	// Unmarshal the data here and process remoteAddr
	ipList := IPConfigList{}
	err = json.Unmarshal(data, &ipList)
	if err != nil {
		log.Errorf("Error parsing ipConfig file config: %v", err)
		return err
	}
	remoteAddr := c.conn.RemoteAddr().String()
	i := strings.LastIndex(remoteAddr, ":")
	if i != -1 {
		remoteAddr = remoteAddr[:i]
	}

	// If the whitelist exists, We just allow the whitelist ip to connect
	// Or else we block ip in the blacklist
	// If the connected ip is both in whitelist and blacklist, we block it
	if (len(ipList.WhiteListIP) != 0 && !MatchIPInList(ipList.WhiteListIP, remoteAddr)) || (len(ipList.BlackListIP) != 0 && MatchIPInList(ipList.BlackListIP, remoteAddr)) {
		if audit.IsAuditLoggerExisted() {
			audit.AuditLogger.WithFields(logrus.Fields{
				"Time":         time.Now().Format(time.RFC850),
				"AuthResult":   "Fail",
				"RemoteAddr":   remoteAddr,
				"ConnectionID": c.ConnectionID,
				"User":         c.User,
			}).Info("Auth")
		}
		return c.writeErrorPacket(ERAccessDeniedError, SSHandshakeError, " %s is disallowed to connect due to get blocked", remoteAddr)
	}
	return nil
}


var ipConfig = flag.String("ip_config", "", "IP config for whitelist or blacklist")

mysql -h172.16.132.31 -P15307 -uvt_app -p123 --enable-cleartext-plugin -A

密码编解码器的密码套件。
hadoop.security.crypto.cipher.suite

kms提供key的加密手段
hadoop.security.key.default.cipher

### Data Encryption on Block data transfer.
dfs.encrypt.data.transfer.cipher.suites


 if (var1 != null && var2 != null) {
      if (var1 == var2) {
        throw new IllegalArgumentException("Input and output buffers must not be the same object, consider using buffer.duplicate()");
      } else if (var2.isReadOnly()) {
        throw new ReadOnlyBufferException();
      } else {
        this.chooseFirstProvider();
        return this.spi.engineDoFinal(var1, var2);
      }
    } else {
      throw new IllegalArgumentException("Buffers must not be null");
    }


hadoop.security.crypto.codec.classes.EXAMPLECIPHERSUITE
hadoop.security.crypto.codec.classes.aes.ctr.nopadding
hadoop.security.crypto.cipher.suite
hadoop.security.crypto.jce.provider
hadoop.security.crypto.buffer.size

// TestMatchIPInList is the unit test for MatchIPInList method
func TestMatchIPInList(t *testing.T) {
	IPlist := []string{"127.0.0.[0-5]", "172.16.1.236"}
	ip := "127.0.0.1"
	match := auth.MatchIPInList(IPlist, ip)
	if !match {
		t.Fatalf("Should match ip in the given list")
	}
	ip = "127.0.0.6"
	match = auth.MatchIPInList(IPlist, ip)
	if match {
		t.Fatalf("Should not match ip in the given list")
	}
}

OBM：A设计，A生产，A品牌，A销售==工厂自己设计自产自销

ODM：B设计，B生产，A品牌，A销售==俗称“贴牌”，就是工厂的产品，别人的品牌

OEM：A设计，B生产，A品牌，A销售==代工，代生产，别人的技术和品牌，工厂只生产

搭一个guardian federation oem出镜像的jenkins job

mpiling 1 source file to /home/jenkins/workspace/build-guardian-federation-oem-image/test/jenkins-test/target/classes

NameNode 和 HDFS 客户端通过 KeyProvider API 操作与 Hadoop KMS (或您配置的替代 KMS) 交互。KMS 负责将加密密钥存储在后备密钥存储中。

[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /home/jenkins/workspace/build-guardian-federation-oem-image/test/jenkins-test/src/main/java/io/transwarp/guardian/federation/test/StressTest.java:[24,1] package org.apache.commons.cli does not exist
[ERROR] /home/jenkins/workspace/build-guardian-federation-oem-image/test/jenkins-test/src/main/java/io/transwarp/guardian/federation/test/StressTest.java:[54,5] cannot find symbol
  symbol:   class Options
  location: class io.transwarp.guardian.federation.test.StressTest
[ERROR] /home/jenkins/workspace/build-guardian-federation-oem-image/test/jenkins-test/src/main/java/io/transwarp/guardian/federation/test/StressTest.java:[54,27] cannot find symbol
  symbol:   class Options
  location: class io.transwarp.guardian.federation.test.StressTest
[ERROR] /home/jenkins/workspace/build-guardian-federation-oem-image/test/jenkins-test/src/main/java/io/transwarp/guardian/federation/test/StressTest.java:[55,23] cannot find symbol
  symbol:   variable Option
  location: class io.transwarp.guardian.federation.test.StressTest
[ERROR] /home/jenkins/workspace/build-guardian-federation-oem-image/test/jenkins-test/src/main/java/io/transwarp/guardian/federation/test/StressTest.java:[56,23] cannot find symbol
  symbol:   variable Option

 protected SecretKey engineGenerateKey() {
    SecretKeySpec var1 = null;
    if (this.random == null) {
      this.random = SunJCE.RANDOM;
    }

    byte[] var2 = new byte[this.keySize];
    this.random.nextBytes(var2);
    var1 = new SecretKeySpec(var2, "AES");
    return var1;
  }
}


/////

export ENABLE_OVERLAY=true 
sudo /usr/bin/startdocker.sh & sleep 60s 


mkdir -p /home/jenkins/.m2/
mkdir -p /home/jenkins/.docker
sudo cp /opt/config.json /home/jenkins/.docker/

    repeat_until_ready() {
      echo "Testing '$1' until ready"
      tmp=$(mktemp)
      for ((i = 0; i < $4; i++)); do
        $1 > ${tmp} && {
          [ `grep "$2" ${tmp} | wc -l` == '0' ] || return 0
        }
        echo "Not ready, wait for $3 seconds ..."
        sleep $3
      done
      return 1
    }

    [ -e "`which zinc`" ] && {
      set +e
      repeat_until_ready "zinc -start" "Zinc compiler" 5 120
      set -e
    }

time=`date "+%Y-%m-%d-%H-%M-%S"`
imageTag="${TAG_NAME}-${time}-${BUILD_ID}"

if [ -f profile.properties ]; then
   rm profile.properties
fi
    
touch profile.properties
    
echo "REVISION=@$SVN_REVISION" > profile.properties
echo "IMAGE_TAG=$imageTag" >> profile.properties

export IMAGE_TAG=${imageTag}
export IMAGE_NAME=${USER}/guardian-federation:latest
export COMPONENT_BASE="federation"
export DEV_ROOT=${WORKSPACE}
export DOCKER_REPO_URL="172.16.1.99"
export BUILDER="postcommit"
export USER=`whoami`
export OSINFO="centos-7"
export releaseStagingId="priv-transwarp-lib"
export releaseRepoName="libs-release-local"
export releaseRepoUrl="http://172.16.1.161:30033/repository/libs-release-local"
export snapStagingId="priv-transwarp-snapshots"
export snapRepoName="libs-snapshot"
export snapRepoUrl="http://172.16.1.161:30033/repository/libs-snapshot-local"

# use jdk 1.8
export JAVA_HOME=/usr/jdk-8u131-linux-x64.tar/jdk1.8.0_131

cd ${DEV_ROOT}


git clone -b master http://wjcaitu:${wj_git}@172.16.1.41:10080/InfraTools/base_project.git base_project


sudo cp base_project/settings_postcommit.xml /home/jenkins/.m2/settings.xml


# add frontend
curl -L -H "PRIVATE-TOKEN: ${FRONTEND_PRIVATE_TOKEN}" \
http://172.16.1.41:10080/api/v4/projects/4531/jobs/artifacts/master/download?job=postcommit -o frontend.zip
unzip frontend.zip

RESOURCE_DIR=$DEV_ROOT/federation-service/src/main/resources
mkdir -p $RESOURCE_DIR/static
mv dist/guardian-federation-frontend/index.html $RESOURCE_DIR/templates/index.html
mv dist/guardian-federation-frontend/* $RESOURCE_DIR/static/
sed -i "s@<html lang=\"en\">@<html xmlns:th=\"http://www.thymeleaf.org\">@g" $RESOURCE_DIR/templates/index.html
sed -i "s@<base href=\"/\">@<base th:href=\"\${basePath}\">@g" $RESOURCE_DIR/templates/index.html

# add frontend
curl -L -H "PRIVATE-TOKEN: ${FRONTEND_PRIVATE_TOKEN}" \
http://172.16.1.41:10080/api/v4/projects/4531/jobs/artifacts/master/download?job=postcommit -o frontend.zip
unzip frontend.zip

RESOURCE_DIR=$DEV_ROOT/federation-service/src/main/resources
mkdir -p $RESOURCE_DIR/static
mv dist/guardian-federation-frontend/index.html $RESOURCE_DIR/templates/index.html
rm -rf $RESOURCE_DIR/static/*
mv dist/guardian-federation-frontend/* $RESOURCE_DIR/static/
sed -i "s@<html lang=\"en\">@<html xmlns:th=\"http://www.thymeleaf.org\">@g" $RESOURCE_DIR/templates/index.html
sed -i "s@<base href=\"/\">@<base th:href=\"\${basePath}\">@g" $RESOURCE_DIR/templates/index.html



# compile & build image
git clone -b master http://wjcaitu:${wj_git}@172.16.1.41:10080/InfraTools/packageRelease.git script
cp build_script/image/build_federation.sh ${DEV_ROOT}/script/build_utils/image/build_federation.sh
cp build_script/deploy/deploy_federation.sh ${DEV_ROOT}/script/build_utils/deploy/deploy_federation.sh
set -e && bash -x script/jenkins_job_build.sh


mvn clean install -DskipTests -Pdocker 


# push image
docker tag ${IMAGE_NAME} ${DOCKER_REPO_URL}/${BUILDER}/guardian-federation:${IMAGE_TAG}
docker push ${DOCKER_REPO_URL}/${BUILDER}/guardian-federation:${IMAGE_TAG}
ps aux | grep dockerd | grep -v "grep" | awk '{print $2}' | xargs kill -9


time="2020-03-27T11:37:41.824432268+08:00" level=warning msg="Running modprobe bridge br_netfilter failed with message: FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory\n, error: exit status 1" 
time="2020-03-27T11:37:41.826151072+08:00" level=warning msg="Running modprobe nf_nat failed with message: `FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory`, error: exit status 1" 
time="2020-03-27T11:37:41.827554678+08:00" level=warning msg="Running modprobe xt_conntrack failed with message: `FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory`, error: exit status 1" 
time="2020-03-27T11:37:41.889363938+08:00" level=warning msg="Could not load necessary modules for IPSEC rules: Running modprobe xfrm_user failed with message: `FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory`, error: exit status 1" v

time="2020-03-27T11:55:28.287104458+08:00" level=warning msg="Running modprobe bridge br_netfilter failed with message: FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory\n, error: exit status 1" 
time="2020-03-27T11:55:28.288422390+08:00" level=warning msg="Running modprobe nf_nat failed with message: `FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory`, error: exit status 1" 
time="2020-03-27T11:55:28.289780032+08:00" level=warning msg="Running modprobe xt_conntrack failed with message: `FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory`, error: exit status 1" 
time="2020-03-27T11:55:28.333805344+08:00" level=warning msg="Could not load necessary modules for IPSEC rules: Running modprobe xfrm_user failed with message: `FATAL: Could not load /lib/modules/4.9.45/modules.dep: No such file or directory`, error: exit status 1" 
time="2020-03-27T11:55:28.334075758+08:00" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address" 



？////
当前版本： KunDB 1.3
整理日期：2020/03/27
一，编写目的
本测试用例文档针对与KunDB安全方面-使用权限认证功能的测试用例覆盖和功能整理。对于每个存储对象不同的权限定义，通过mysql5.7的show privileges语句查看，在本地测试对比持久化在mysql和KunDB的权限数据，形成测试需求。

二，测试环境
KunDB本身支持mysql协议客户端和JDBC等方式的gRPC连接，SQL语句的ACL部分在内部处理和与KunGate的连接方式无关，在此可以不做区别，所以测试环境只选在本地开的mysql客户端做测试。

transwarp@transwarp-Latitude-5480:~$ uname -a
Linux transwarp-Latitude-5480 4.15.0-91-generic #92~16.04.1-Ubuntu SMP Fri Feb 28 14:57:22 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
图1

三，测试用例及执行情况

执行show privileges语句：
图2

这里的权限对象讨论的是普通用户可以使用acl功能的权限，只有admin用户能执行的功能不再讨论范围之内
KunDB ACL对象：database, table, view, index，column, trigger，procedure, function, global index
show privileges 语句提供了账户可执行的操作，实际上通过在mysql的information schema中。mysql并没有按照read write view admin来区分权限，而是细化到定义不同的权限来进行用户操作限制,所以实际权限请按下图为准，这一节的对象权限为自己分类，用户赋权权限通过with grant option拥有赋权的权限
图3
kunDB处理之中的15种：SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, ALTER, INDEX, CREATE ROUTINE, ALTER ROUTINE, EXECUTE, TRIGGER, USAGE, CREATE USER, CREATE VIEW
暂时不能处理以下16种mysql原生支持的权限类型：CREATE TEMPORARY TABLES，Event，File，Grant option，Lock tables，Process，Proxy, References, Reload, Replication client , Replication slave, Show databases, Show view ,Shutdown, Super, Create tablespace

以下为通过kundb可进行的对象操作
kundb没有特定的admin权限，不过可以通过grant语句进行类似admin权限的控制
grant all on *.* to lzb;	//赋予全部权限，相当于global admin
grant all on DBName.* to lzb;		//赋予特定库下的全部权限
grant all on DBName.TableName to lzb;		//赋予用户特定库特定表的全部权限
grant all on TableName to lzb;		//赋予用户一张表的全部权限
3.1 database
用户对database有create, drop, show权限
CREATE DATABASE not_exists_opt table_id
show create database -> 权限表 默认有

3.2 table
用户可以对table有select, delete, insert, update, create, drop, alter, index, trigger权限

3.3 view
用户可以对view有select, drop, CREATE VIEW权限,同时创建完成的view作为一张表存在(不支持赋权？）

3.4 index
index被使用没有权限，在table中有index权限的用户可以创建权限

3.5 column
用户对column有select， insert， update权限
mysql> grant insert(itemid) on item1 to lzb;
Query OK, 0 rows affected (0.03 sec)

mysql> show grants for lzb;
+----------------------------------------------------------------------------------------------------+
| Grants for lzb@%                                                                                   |
+----------------------------------------------------------------------------------------------------+
| GRANT USAGE ON *.* TO 'lzb'@'%' IDENTIFIED BY PASSWORD '*471BD27F313EB01D08E0D9B6CCD6F2236BDB6739' |
| GRANT INSERT (itemid), UPDATE (itemid) ON `db1`.`item1` TO 'lzb'@'%'                               |
| GRANT SELECT ON `db1`.`customer` TO 'lzb'@'%'                                                      |
+----------------------------------------------------------------------------------------------------+
3 rows in set (0.00 sec)


3.6 trigger
trigger被使用没有权限，在table中有TRIGGER权限的用户可以创建权限

3.7 procedure
MySQL的程序（process/routine）
一个全局权限：CREATE ROUTINE，在user,db表中体现
三个对象级权限，主要分为procedure和function两个对象类型。对于程序而言他们的权限种类有
1，EXECUTE #执行权限
2，ALTER ROUTINE #修改权限
3，GRANT  #授予权限

3.8 global index
global index被使用没有权限，用户依赖于在table中index的权限可以创建


四，统计与分析
五，结论

0330
 maven 找不到一个包
 org.apache.commons.cli
maven版本问题 3.0.5

工作周报 - 李镇邦 20200323 ~ 20200327

1. WARP-43034: hdfs透明加密SM4算法支持 完成加密算法添加和密钥使用加密部分 集群验证
2. WARP-42372: 修复JDBC客户端测试case bug
3. 根据show privileges 整理KunDB权限部分测试用例 wiki: http://172.16.1.168:8090/pages/viewpage.action?pageId=23490750

其他: 
搭建guardian federation oem出镜像的jenkins job 

本周：


静态函数和成员函数

export ENABLE_OVERLAY=true 
sudo /usr/bin/startdocker.sh & sleep 45s 


mkdir -p /home/jenkins/.m2/
mkdir -p /home/jenkins/.docker
sudo cp /opt/config.json /home/jenkins/.docker/

    repeat_until_ready() {
      echo "Testing '$1' until ready"
      tmp=$(mktemp)
      for ((i = 0; i < $4; i++)); do
        $1 > ${tmp} && {
          [ `grep "$2" ${tmp} | wc -l` == '0' ] || return 0
        }
        echo "Not ready, wait for $3 seconds ..."
        sleep $3
      done
      return 1
    }

    [ -e "`which zinc`" ] && {
      set +e
      repeat_until_ready "zinc -start" "Zinc compiler" 5 120
      set -e
    }

time=`date "+%Y-%m-%d-%H-%M-%S"`
imageTag="${TAG_NAME}-${time}-${BUILD_ID}"

if [ -f profile.properties ]; then
   rm profile.properties
fi
    
touch profile.properties
    
echo "REVISION=@$SVN_REVISION" > profile.properties
echo "IMAGE_TAG=$imageTag" >> profile.properties

export IMAGE_TAG=${imageTag}
export IMAGE_NAME=${USER}/guardian-federation:latest
export COMPONENT_BASE="federation"
export DEV_ROOT=${WORKSPACE}
export DOCKER_REPO_URL="172.16.1.99"
export BUILDER="postcommit"
export USER=`whoami`
export OSINFO="centos-7"
export releaseStagingId="priv-transwarp-lib"
export releaseRepoName="libs-release-local"
export releaseRepoUrl="http://172.16.1.161:30033/repository/libs-release-local"
export snapStagingId="priv-transwarp-snapshots"
export snapRepoName="libs-snapshot"
export snapRepoUrl="http://172.16.1.161:30033/repository/libs-snapshot-local"

# use jdk 1.8
export JAVA_HOME=/usr/java/jdk1.8.0_151/
mvn -version
# ${LATEST_BRANCH} is from GitLab CI environment
if [ "${CI_COMMIT_REF_NAME}" = "master" ]; then
export BRANCH_NAME="${LATEST_BRANCH}"
else
export BRANCH_NAME="${CI_COMMIT_REF_NAME}"
fi


cd ${DEV_ROOT}


git clone -b master http://wjcaitu:${wj_git}@172.16.1.41:10080/InfraTools/base_project.git base_project
sudo cp base_project/settings_postcommit.xml /home/jenkins/.m2/settings.xml

# add frontend
curl -L -H "PRIVATE-TOKEN: ${FRONTEND_PRIVATE_TOKEN}" \
http://172.16.1.41:10080/api/v4/projects/4531/jobs/artifacts/master/download?job=postcommit -o frontend.zip
unzip frontend.zip

RESOURCE_DIR=$DEV_ROOT/federation-service/src/main/resources
mkdir -p $RESOURCE_DIR/static
mv dist/guardian-federation-frontend/index.html $RESOURCE_DIR/templates/index.html
mv dist/guardian-federation-frontend/* $RESOURCE_DIR/static/
sed -i "s@<html lang=\"en\">@<html xmlns:th=\"http://www.thymeleaf.org\">@g" $RESOURCE_DIR/templates/index.html
sed -i "s@<base href=\"/\">@<base th:href=\"\${basePath}\">@g" $RESOURCE_DIR/templates/index.html

rm -rf /home/jenkins/.m2/repository/*
# compile & build image
mvn clean install -DskipTests -Pdocker -DdistMgmtStagingId=${releaseStagingId} -DdistMgmtStagingName=${releaseRepoName} -DdistMgmtStagingUrl=${releaseRepoUrl} -DdistMgmtSnapshotsId=${snapStagingId} -DdistMgmtSnapshotsName=${snapRepoName} -DdistMgmtSnapshotsUrl=${snapRepoUrl}


# push image
docker tag ${IMAGE_NAME} ${DOCKER_REPO_URL}/${BUILDER}/guardian-federation:${IMAGE_TAG}
docker push ${DOCKER_REPO_URL}/${BUILDER}/guardian-federation:${IMAGE_TAG}
ps aux | grep dockerd | grep -v "grep" | awk '{print $2}' | xargs kill -9

jenkins job那个事
[ERROR] /home/jenkins/workspace/build-guardian-federation-oem-image/test/jenkins-test/src/main/java/io/transwarp/guardian/federation/test/StressTest.java:[24,1] package org.apache.commons.cli does not exist

+ mvn -version
Apache Maven 3.0.5 (r01de14724cdef164cd33c7c8c2fe155faf9602da; 2013-02-19 21:51:28+0800)
Maven home: /root/apache-maven-3.0.5


mvn clean install -pl federation-common,federation-service,federation-utils,federation-client -am -DskipTests

.An image does not exist locally with the tag: 172.16.1.99/postcommit/guardian-federation //tag打错了

http://172.16.1.97:8080 owncloud 123456

http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/INTERNAL/KUNDB/kundb-1.3/IMAGE/centos-7/2020-03-30_00-07-30/KUNDB-Image-Registry-Transwarp-1.3.tar.gz


curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/INTERNAL/GUARDIAN/guardian-3.2/IMAGE/centos-7/2020-03-29_23-48-03/GUARDIAN-Image-Registry-Transwarp-3.2.tar.gz" > /var/lib/docker/guardian.tar.gz

curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/MANAGER/manager-6.0.1907a-final/IMAGE/centos-7/MANAGER-Basic-Component-Transwarp-6.0.1907a-final.tar.gz" > /home/MANAGER-Basic-Component-Transwarp-6.0.1907a-final.tar.gz
http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/MANAGER/manager-6.0.1907a-final/IMAGE/centos-7/MANAGER-Basic-Component-Transwarp-6.0.1907a-final.tar.gz


INSERT INTO item1 (price) VALUES (66);
delimiter go
create procedure sp_hello_world()
begin
select 'hello world';
end go

ALTER  PROCEDURE  sp_hello_world 
MODIFIES SQL DATA
SQL SECURITY INVOKER ; 

SELECT SPECIFIC_NAME,SQL_DATA_ACCESS,SECURITY_TYPE
FROM information_schema.Routines
WHERE ROUTINE_NAME='sp_hello_world' AND ROUTINE_TYPE='PROCEDURE';


初始化case

创建一个数据库db1:

create database db1;

进入db1:

use db1;

创建普通表customer:

create table customer (custid int primary key, custname varchar(20), age int) partition by HASH(custid) using hash;

insert into customer(custid, custname, age) values (1, 'Zhang', 10), (2, 'Li', 20), (3,'Wang', 30), (4,'Zhao', 40);

创建普通表item1:

create table item1 (itemid int primary key, itemname varchar(100), price decimal ) partition by HASH(Itemid) using hash;

insert into item1(itemid, itemname, price) values (1, 'Candy', 5), (2, 'Milk', 10), (3, 'Toy', 20);

创建视图v:

create view v as select age as value from db1.customer;

创建用户test1:

create user test1;


展示MySQL中所有权限:

show privileges;

------------------------------------------------------------------------------------

case1: 赋予普通用户库，表，global级别的所有权限

赋予全部权限，相当于global admin：

grant all on *.* to test1; 

查看test1用户权限：

show grants for test1;

撤销权限：

revoke all on *.* from test1;

查看test1用户权限：

show grants for test1;


赋予特定库下的全部权限：

grant all on db1.* to test1;

查看test1用户权限：

show grants for test1;

撤销权限：

revoke all on db1.* from test1;

查看test1用户权限：

show grants for test1;


赋予用户特定库特定表的全部权限

grant all on db1.item1 to test1;

查看test1用户权限：

show grants for test1;

撤销权限：

revoke all on db1.item1 from test1;

查看test1用户权限：

show grants for test1;


进入库后，赋予用户一张表的全部权限：

grant all on item1 to test1;

查看test1用户权限：

show grants for test1;

撤销权限：

revoke all on item1 from test1;

查看test1用户权限：

show grants for test1;


------------------------------------------------------------------------------------

case2: database权限的赋予和撤回

赋予普通用户针对数据库的create和drop操作权限：

grant create, drop on *.* to test1;

test1用户登陆，测试功能：

create database db2;

drop database db2;

特权用户撤回test1权限：

revoke create, drop on *.* from test1;


------------------------------------------------------------------------------------

case3: table权限的赋予和撤回

赋予普通用户所有表的select, delete, insert, update, create, drop, alter, index, trigger, create view权限：

grant select, delete, insert, update, create, drop, alter, index, trigger, create view on item1 to test1;

test1用户测试功能：

省略，下边有重复的

特权用户撤回test1权限：

revoke select, delete, insert, update, create, drop, alter, index, trigger, create view on item1 from test1;


------------------------------------------------------------------------------------

case4:view， index, trigger权限的赋予和撤回

赋予用户在表item1上的create view和index权限：

grant create view, index, trigger on item1 to test1;

test1用户测试功能：

create view v2 as select price as dollar from db1.item1;  //测试create view

create index id1 on item1(price);   //测试index权限

delimiter $$

CREATE  DEFINER=`test1`@`%` TRIGGER Tri_Item_Insert BEFORE INSERT ON item1 FOR EACH ROW BEGIN         insert into item1 values(6, 'baby', 35); END;$$

delimiter ;   //测试trigger权限

特权用户撤回test1权限：

revoke create view, index, trigger on item1 from test1;


------------------------------------------------------------------------------------


case5: column 权限的赋予和撤回

赋予用户在表item1上列price的权限：

grant select(price),  update(price) on item1 to test1;

切到test1用户测试功能：

select price from item1;

update item1 set price = 5;

特权用户撤回test1权限：

 revoke select(price),  update(price) on item1 from test1;


------------------------------------------------------------------------------------

case6: routine权限的赋予和撤回

 赋予用户CREATE ROUTINE的权限：

grant CREATE ROUTINE on db1.* to test1;

test1测试：

\d go

create procedure sp_hello_world()

begin

select 'hello world';

end go

\d ;

 赋予用户执行和修改的权限：

grant execute, alter routine on sp_hello_world to test1;

test1测试：

call sp_hello_world();

ALTER  PROCEDURE  sp_hello_world

MODIFIES SQL DATA

SQL SECURITY INVOKER ;

验证

SELECT SPECIFIC_NAME,SQL_DATA_ACCESS,SECURITY_TYPE

FROM information_schema.Routines

WHERE ROUTINE_NAME='sp_hello_world' AND ROUTINE_TYPE='PROCEDURE';

收回赋权

 revoke execute, alter routine on sp_hello_world from test1


docker run -it --privileged --rm -v /home/transwarp/Downloads/work/mariadb:/root/mariadb_src 172.16.1.99/kundb/x86_64/mysql-compiler:v1 bash


GuardianSm4CtrCryptoCodec

if(algorithm == "SM4") {
      SM4KeyGenerator sm4KeyGenerator = SM4KeyGenerator.getInstance(algorithm);
      return sm4KeyGenerator.generateKey();
    }

MANAGER-Basic-Component-Transwarp-6.0.1907a-fi

docker run -e CONF_DIR=/etc/guardian/conf -e DUMP_FILE=/etc/guardian/conf/pre_upgrade.dump -e oldVersion=guardian-3.1.0-final --net=host --volume /etc/guardian/conf:/etc/guardian/conf --volume /guardian/data/:/guardian/data/ --volume /transwarp/mounts/guardian:/vdir transwarp/apacheds:guardian-3.1 bash /bin/pre_rollback.sh

 curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/MANAGER/manager-6.0.1907a-final/IMAGE/centos-7/MANAGER-Basic-Component-Transwarp-6.0.1907a-final.tar.gz" > /home/MANAGER-Basic-Component-Transwarp-6.0.1907a-final.tar.gz
 1135  ls -l
 1136  service transwarp-manager restart
 1137  df -h
 1138  docker images
 1139  docker pull 172.16.1.99/gold/txsql:guardian-3.1
 1140  docker images
 1141  docker tag 7f8 tw-node1236:5000/transwarp/txsql:guardian-3.1
 1142  docker push 7f8 tw-node1236:5000/transwarp/txsql:guardian-3.1
 1143  docker push tw-node1236:5000/transwarp/txsql:guardian-3.1
 1144  df -h
 1145  cd /etc/guardian/conf/
 1146  ls
 1147  vi /var/log/transwarp-manager/master/transwarp-manager.log
 1148  cd /guardian/txsql/data/
 1149  ls

{"log":"+ echoWithTimestamp 'Error: failed to resolve LOCAL_IP'\n","stream":"stderr","time":"2020-03-31T10:59:50.205966142Z"}

grep "aabbcc" /var/test -n
pwdInHistoryDuration
grep "pwdInHistoryDuration" ~/tmp/m-oid\=1.3.6.1.4.1.42.2.27.8.2.1.ldif

mkfs.xfs -n ftype=1 /dev/sdb

UUID=048f5b79-fbb7-4594-8c80-6a1d110949db /var/lib/docker xfs defaults 0 0

UUID="048f5b79-fbb7-4594-8c80-6a1d110949db"

tw-node1236:5000/transwarp/workflow              studio-1.3.0-final                                                                    7aea94292aca        5 weeks ago         1.41GB
172.16.1.99/transwarp/workflow                   flyingzoop-studio-1.3.0-final                                                         7aea94292aca        5 weeks ago         1.41GB
transwarp/workflow                               <none>                                                                                6e294012b52a        5 weeks ago         1.38GB
tw-node1236:5000/transwarp/workflow              <none>                                                                                6e294012b52a        5 weeks ago         1.38GB
172.16.1.99/transwarp/inceptor                   flyingzoop-flyingzoop-6.2.1-final                                                     90e0037a2ed8        5 weeks ago         3.99GB
transwarp/inceptor                               <none>                                                                                90e0037a2ed8        5 weeks ago         3.99GB
tw-node1236:5000/transwarp/inceptor              <none>                                                                                90e0037a2ed8        5 weeks ago         3.99GB
172.16.1.99/postcommit/watchman                  oem_flyingzoop_tdh_621-2020-02-20-18-53-55-f0ce9980a8c138d9db051ff9625eba48ebd2e21a   a75f1ce6d41a        5 weeks ago         924MB
172.16.1.99/transwarp/dbaservice                 flyingzoop-flyingzoop-6.2.1-final                                                     a75f1ce6d41a        5 weeks ago         924MB
transwarp/dbaservice                             transwarp-6.2.1-final                                                                 a75f1ce6d41a        5 weeks ago         924MB
tw-node1236:5000/transwarp/dbaservice            transwarp-6.2.1-final                                                                 a75f1ce6d41a        5 weeks ago         924MB
172.16.1.99/transwarp/guardian                   flyingzoop-guardian-3.1.2-final                                                       cfd84ef79271        5 weeks ago         1.38GB
172.16.1.99/transwarp/guardian                   guardian-3.1.2-final                                                                  cfd84ef79271        5 weeks ago         1.38GB
transwarp/guardian                               guardian-3.1.0-final                                                                  cfd84ef79271        5 weeks ago         1.38GB
tw-node1236:5000/transwarp/guardian              guardian-3.1.0-final                                                                  cfd84ef79271        5 weeks ago         1.38GB
172.16.1.99/postcommit/watchman                  oem_flyingzoop_tdh_621                                                                43a5e736ec4b        5 weeks ago         924MB
transwarp/dbaservice                             <none>                                                                                43a5e736ec4b        5 weeks ago         924MB
tw-node1236:5000/transwarp/dbaservice            <none>                                                                                43a5e736ec4b        5 weeks ago         924MB
transwarp/inceptor                               <none>                                                                                d793464f3259        5 weeks ago         3.98GB
172.16.1.99/transwarp/guardian-federation        flyingzoop-guardian-3.1.2-final                                                       92ddd2533013        5 weeks ago         1.11GB
transwarp/guardian-federation                    guardian-3.1.0-final                                                                  92ddd2533013        5 weeks ago         1.11GB
tw-node1236:5000/transwarp/guardian-federation   guardian-3.1.0-final                                                                  92ddd2533013        5 weeks ago         1.11GB
172.16.1.99/transwarp/cas-server                 flyingzoop-guardian-3.1.2-final                                                       f98776656dea        5 weeks ago         1.28GB
transwarp/cas-server                             guardian-3.1.0-final                                                                  f98776656dea        5 weeks ago         1.28GB


var/lib/docker/temp/KUNDB-Image-Registry-Transwarp-1.3.0-X86_64-rc0.tar.gz
/var/lib/docker/STUDIO-Image-Registry-Transwarp-1.3.0-final.tar.gz
/var/lib/docker/TDH-Image-Registry-Transwarp-6.2.1-final.tar.gz

curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/INTERNAL/GUARDIAN/guardian-3.1/IMAGE/centos-7/2020-04-01_16-13-21/GUARDIAN-Image-Registry-Transwarp-3.1.tar.gz" > /var/lib/docker/guardian.tar.gz



Job for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.


pwdInHistoryDuration
pwdMinClasses

if [ `grep -c "pwdInHistoryDuration" ~/tmp/m-oid\=1.3.6.1.4.1.42.2.27.8.2.1.ldif` -eq '0' ]; then

    echo "Found!"
else
    echo "NO"
fi
curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/MANAGER/manager-7.0.1910a-final/IMAGE/centos-7/MANAGER-Basic-Component-Transwarp-7.0.1910a-final.tar.gz" > /var/lib/docker/manager.tar.gz

curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/TDH/transwarp-6.2.1-final/IMAGE/centos-7/TDH-Image-Registry-Transwarp-6.2.1-final.tar.gz" > /var/lib/docker/tdh.tar.gz

http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/INTERNAL/KUNDB/kundb-1.3/IMAGE/centos-7/2020-04-02_00-06-44/KUNDB-Image-Registry-Transwarp-1.3.tar.gz

curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/KUNDB/kundb-1.3.0-X86_64-rc2/IMAGE/centos-7/KUNDB-Image-Registry-Transwarp-1.3.0-X86_64-rc2.tar.gz" > /var/lib/docker/Kundb.tar.gz

装manager
/237 238挂盘 /car/lib/docker
http://172.16.1.168:8090/pages/viewpage.action?pageId=3997860 内部iso文件

m-may: pwdMinClasses
m-may: pwdInHistoryDuration

删
sed '$d' 
删除/etc/passwd所有包含root的行，其他行输出
sed  '/pwdInHistoryDuration/d' new-new-test.txt -i
sed  '/pwdMinClasses/d' new-new-test.txt -i
如果是要增加两行以上，在第二行后面加入两行字，例如 Drink tea or ..... 与 drink beer?
sed -i '$a # This is a test' file
transwarp@transwarp-Latitude-5480:


 sed -i '$a m-may: pwdMinClasses\
m-may: pwdInHistoryDuration' new-new-test.txt

0: jdbc:hive2://172.26.0.38:10000> revoke all on database db_user2 from user crmuser_ht;
Error: EXECUTION FAILED: Task DDL error HiveAuthzPluginException: [Error 40000] ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db_user2], component='inceptor5', grantable='false'} from USER: crmuser_ht (state=08S01,code=40000)


2020-04-01 17:59:00,582 ERROR inceptor.GuardianHiveAccessController: (GuardianHiveAccessController.java:revokePrivileges(173)) [HiveServer2-Handler-Pool: Thread-36547(SessionHandle=9711b3dc-82bf-4fa2-85d1-def9cf9200e4)] - Fail to grant permission: DELETE for hiveObj: [TABLE_OR_VIEW, db_user2] to user: crmuser_ht
io.transwarp.guardian.common.exception.GuardianClientException: ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db_user2], component='inceptor5', grantable='false'} from USER: crmuser_ht
        at io.transwarp.guardian.client.impl.rest.RestClient.processFailure(RestClient.java:389)
        at io.transwarp.guardian.client.impl.rest.RestClient.requestWithHA(RestClient.java:446)
        at io.transwarp.guardian.client.impl.rest.RestClient.requestReturningNothing(RestClient.java:350)
        at io.transwarp.guardian.client.impl.rest.RestClient.put(RestClient.java:179)
        at io.transwarp.guardian.client.impl.rest.RestAdminImpl$10.run(RestAdminImpl.java:209)
        at io.transwarp.guardian.client.impl.rest.RestAdminImpl$10.run(RestAdminImpl.java:206)
        at io.transwarp.guardian.client.impl.rest.AbstractGuardianClient.runWithRelogin(AbstractGuardianClient.java:264)
        at io.transwarp.guardian.client.impl.rest.RestAdminImpl.revoke(RestAdminImpl.java:206)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAccessController.revokePrivileges(GuardianHiveAccessController.java:170)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAccessControllerWrapper.revokePrivileges(GuardianHiveAccessControllerWrapper.java:44)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAuthorizer.revokePrivileges(GuardianHiveAuthorizer.java:32)
        at org.apache.hadoop.hive.ql.exec.DDLTask.grantOrRevokePrivileges(DDLTask.java:1208)
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:604)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:164)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:89)

0: jdbc:hive2://172.26.0.38:10000> revoke all on database db_user2 from user crmuser_ht;


0: jdbc:hive2://172.26.0.38:10000> revoke all on database db_user2 from user a;
Error: EXECUTION FAILED: Task DDL error HiveAuthzPluginException: [Error 40000] ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db_user2], component='inceptor5', grantable='false'} from USER: a (state=08S01,code=40000)

2020-04-01 18:15:50,616 ERROR inceptor.GuardianHiveAccessController: (GuardianHiveAccessController.java:revokePrivileges(173)) [HiveServer2-Handler-Pool: Thread-36547(SessionHandle=9711b3dc-82bf-4fa2-85d1-def9cf9200e4)] - Fail to grant permission: DELETE for hiveObj: [TABLE_OR_VIEW, db_user2] to user: a
io.transwarp.guardian.common.exception.GuardianClientException: ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db_user2], component='inceptor5', grantable='false'} from USER: a
        at io.transwarp.guardian.client.impl.rest.RestClient.processFailure(RestClient.java:389)
        at io.transwarp.guardian.client.impl.rest.RestClient.requestWithHA(RestClient.java:446)
        at io.transwarp.guardian.client.impl.rest.RestClient.requestReturningNothing(RestClient.java:350)
        at io.transwarp.guardian.client.impl.rest.RestClient.put(RestClient.java:179)
        at io.transwarp.guardian.client.impl.rest.RestAdminImpl$10.run(RestAdminImpl.java:209)show
        at io.transwarp.guardian.client.impl.rest.RestAdminImpl$10.run(RestAdminImpl.java:206)
        at io.transwarp.guardian.client.impl.rest.AbstractGuardianClient.runWithRelogin(AbstractGuardianClient.java:264)
        at io.transwarp.guardian.client.impl.rest.RestAdminImpl.revoke(RestAdminImpl.java:206)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAccessController.revokePrivileges(GuardianHiveAccessController.java:170)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAccessControllerWrapper.revokePrivileges(GuardianHiveAccessControllerWrapper.java:44)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAuthorizer.revokePrivileges(GuardianHiveAuthorizer.java:32)
        at org.apache.hadoop.hive.ql.exec.DDLTask.grantOrRevokePrivileges(DDLTask.java:1208)
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:604)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:164)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:89)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2734)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:2451)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1778)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1613)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1580)
        at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:66)
        at org.apache.hive.service.cli.operation.Operation.run(Operation.java:295)
        at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:434)
        at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:401)
        at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:333)
        at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:148)
        at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:542)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1857)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1842)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
2020-04-01 18:15:50,617 ERROR exec.DDLTask: (DDLTask.java:execute(786)) [HiveServer2-Handler-Pool: Thread-36547(SessionHandle=9711b3dc-82bf-4fa2-85d1-def9cf9200e4)] - org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthzPluginException: ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db_user2], component='inceptor5', grantable='false'} from USER: a
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAccessController.revokePrivileges(GuardianHiveAccessController.java:175)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAccessControllerWrapper.revokePrivileges(GuardianHiveAccessControllerWrapper.java:44)
        at io.transwarp.guardian.plugins.inceptor.GuardianHiveAuthorizer.revokePrivileges(GuardianHiveAuthorizer.java:32)
        at org.apache.hadoop.hive.ql.exec.DDLTask.grantOrRevokePrivileges(DDLTask.java:1208)
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:604)

guardian-3.1.2-final
2020-04-01 19:18:18,131 ERROR org.apache.directory.fortress.core.impl.PermUtil: Read permissions failed for permission: Permission{ou='inceptor5', objName='[TABLE_OR_VIEW, db_user3]', opName='CREATE', objId='null'}
org.apache.directory.fortress.core.FinderException: getPerm no entry found dn [ftOpNm=CREATE,ftObjNm=db_user3,ftObjNm=TABLE_OR_VIEW,ou=inceptor5,ou=Permissions,ou=RBAC,dc=tdh]
        at org.apache.directory.fortress.core.impl.PermDAO.getPerm(PermDAO.java:1110)
        at org.apache.directory.fortress.core.impl.PermP.read(PermP.java:358)
        at org.apache.directory.fortress.core.impl.PermUtil.loadPerm(PermUtil.java:158)
        at org.apache.directory.fortress.core.impl.PermUtil.getDetailedPerm(PermUtil.java:146)
        at org.apache.directory.fortress.core.impl.PermUtil.isGrantable(PermUtil.java:42)
        at org.apache.directory.fortress.core.impl.AdminUtil.canRevoke(AdminUtil.java:299)
        at org.apache.directory.fortress.core.impl.AdminMgrImpl.revokePermission(AdminMgrImpl.java:731)
        at io.transwarp.guardian.core.manager.PermManager.revoke(PermManager.java:407)
        at io.transwarp.guardian.server.boot.controller.PermController.revokePermission(PermController.java:378)
        at io.transwarp.guardian.server.boot.controller.PermController$$FastClassBySpringCGLIB$$c4c73116.invoke(<generated>)
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:52)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:174)

2020-04-01 19:57:15,210 INFO io.transwarp.guardian.client.cache.metrics.PeriodCacheMetricsDisplay: Metrics for cache [CheckAccessCache-7b4d87cb-47ba-4e2e-bfe4-ee4ba2d4d292.cache]: { currentRequestCount=0, currentHitCount=0, currentMissCount=0, currentLoadCount=0, currentHitRate=N/A, currentMissRate=N/A, accumulatedRequestCount=0, accumulatedHitCount=0, accumulatedMissCount=0, accumulatedLoadCount=0, accumulatedHitRate=N/A, accumulatedMissRate=N/A, cacheSize=0, }
2020-04-01 20:05:53,229 INFO io.transwarp.guardian.core.manager.QuotaManager: Cannot find the specified quota: QuotaVo{component='inceptor5', dataSource='[GLOBAL]', properties=null}
2020-04-01 20:05:53,268 INFO io.transwarp.guardian.core.manager.QuotaManager: Cannot find the specified quota: QuotaVo{component='inceptor5', dataSource='[TABLE_OR_VIEW, system]', properties=null}
2020-04-01 20:05:53,281 INFO io.transwarp.guardian.core.manager.QuotaManager: Cannot find the specified quota: QuotaVo{component='inceptor5', dataSource='[TABLE_OR_VIEW, db_user2]', properties=null}
2020-04-01 20:05:53,297 INFO io.transwarp.guardian.core.manager.QuotaManager: Cannot find the specified quota: QuotaVo{component='inceptor5', dataSource='[TABLE_OR_VIEW, test1]', properties=null}
2020-04-01 20:05:53,307 INFO io.transwarp.guardian.core.manager.QuotaManager: Cannot find the specified quota: QuotaVo{component='inceptor5', dataSource='[TABLE_OR_VIEW, pctauser]', properties=null}


hive show grants

2020-04-01 20:08:22,904 INFO  ql.Driver: (PerfLogger.java:PerfLogBegin(111)) [HiveServer2-Handler-Pool: Thread-36547(SessionHandle=71dbcdb3-7af9-4e58-942a-60f583e22ca6)] - <PERFLOG method=task.DDL.Stage-0>
2020-04-01 20:08:22,913 ERROR exec.DDLTask: (DDLTask.java:execute(786)) [HiveServer2-Handler-Pool: Thread-36547(SessionHandle=71dbcdb3-7af9-4e58-942a-60f583e22ca6)] - java.lang.NullPointerException
        at org.apache.hadoop.hive.ql.security.authorization.plugin.HivePrincipal.compareTo(HivePrincipal.java:32)
        at org.apache.hadoop.hive.ql.exec.DDLTask$1.compare(DDLTask.java:4256)
        at org.apache.hadoop.hive.ql.exec.DDLTask$1.compare(DDLTask.java:4251)
        at java.util.TimSort.countRunAndMakeAscending(TimSort.java:351)
        at java.util.TimSort.sort(TimSort.java:216)
        at java.util.Arrays.sort(Arrays.java:1512)
        at java.util.ArrayList.sort(ArrayList.java:1454)
        at java.util.Collections.sort(Collections.java:175)
        at org.apache.hadoop.hive.ql.exec.DDLTask.writeGrantInfo(DDLTask.java:4251)
        at org.apache.hadoop.hive.ql.exec.DDLTask.showGrants(DDLTask.java:1182)
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:611)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:164)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:89)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2734)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:2451)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1778)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1613)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1580)
        at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:66)
        at org.apache.hive.service.cli.operation.Operation.run(Operation.java:295)
        at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:434)
        at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:401)
        at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:333)
        at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:148)
        at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:542)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1857)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1842)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)


- name: kundb.log_dir
  recommendExpression: ${"/var/log/" + service['sid']}
  defaultValue: null
  valueType: ABSOLUTE_PATH
  scope: !<ServiceLevel> {}
  onDeps: []
  groups: []
  visibility: READ_WRITE 


#!/bin/bash
#modify template
FILES=$(ls *txt)
NEW="new"
for FILE in $FILES
do
  echo "Renaming $FILE to new-$FILE"
  mv $FILE $NEW-$FILE
done

#modify in pre_upgrade
if [ `grep -c "pwdMinClasses" ~/tmp/m-oid\=1.3.6.1.4.1.42.2.27.8.2.1.ldif` -eq '1' ]; then

    echo "Found!"
else
    echo "Adding config in Apacheds"
    sed -i '$a m-may: pwdMinClasses\' m-oid\=1.3.6.1.4.1.42.2.27.8.2.1.ldif
fi

if [ `grep -c "pwdInHistoryDuration" m-oid\=1.3.6.1.4.1.42.2.27.8.2.1.ldif` -eq '1' ]; then

    echo "Found!"
else
    echo "NO Adding"
    sed -i '$a m-may: pwdInHistoryDuration\' m-oid\=1.3.6.1.4.1.42.2.27.8.2.1.ldif
fi


m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif

创建写入文件：https://blog.csdn.net/wwwlyj123321/article/details/81669342
判断文件是否存在：https://www.cnblogs.com/emanlee/p/3583769.html

2020-04-01T22:07:38.773976-05:00 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.
2020-04-01T22:07:38.781877-05:00 0 [Warning] InnoDB: Using innodb_support_xa is deprecated and the parameter may be removed in future releases. Only innodb_support_xa=ON is allowed.
2020-04-01T22:07:38.781925-05:00 0 [Warning] InnoDB: innodb-page-size has been changed from the default value 16384 to 32768.
2020-04-01T22:07:41.877646-05:00 0 [Warning] InnoDB: New log files created, LSN=74152
2020-04-01T22:07:42.978207-05:00 0 [Warning] InnoDB: Creating foreign key constraint system tables.
2020-04-01T22:07:42.986247-05:00 0 [ERROR] unknown variable 'encryption_algorithm=1'
2020-04-01T22:07:42.986302-05:00 0 [ERROR] Aborting

# -f 参数判断 $file 是否存在
file2=m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif
if [ ! -f "$file2" ]; then
  cat > $file2 <<EOF
version: 1
dn: m-oid=1.3.6.1.4.1.18060.0.4.1.2.940,ou=attributeTypes,cn=adsconfig,ou=schema
m-singlevalue: TRUE
m-oid: 1.3.6.1.4.1.18060.0.4.1.2.940
m-syntax: 1.3.6.1.4.1.1466.115.121.1.27
objectclass: top
objectclass: metaTop
objectclass: metaAttributeType
m-name: ads-pwdInHistoryDuration
creatorsname: uid=admin,ou=system
m-equality: integerMatch
m-length: 0
EOF
fi


mysql -h172.16.1.238 -P15307 -uadmin -padmin --enable-cleartext-plugin --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA

8.1.32
version: 1
dn: m-oid=1.3.6.1.4.1.42.2.27.8.1.32,ou=attributeTypes,cn=pwdpolicy,ou=schema
m-singlevalue: TRUE
m-oid: 1.3.6.1.4.1.42.2.27.8.1.32
m-syntax: 1.3.6.1.4.1.1466.115.121.1.27
objectclass: metaTop
objectclass: metaAttributeType
objectclass: top
m-name: pwdMinClasses
creatorsname: uid=admin,ou=system
m-equality: integerMatch


#Add files
file1=m-oid=1.3.6.1.4.1.18060.0.4.1.2.939.ldif
if [ ! -f "$file1" ]; then
  cat > $file1 <<EOF
version: 1
dn: m-oid=1.3.6.1.4.1.18060.0.4.1.2.939,ou=attributeTypes,cn=adsconfig,ou=schema
m-singlevalue: TRUE
m-oid: 1.3.6.1.4.1.18060.0.4.1.2.939
m-syntax: 1.3.6.1.4.1.1466.115.121.1.27
objectclass: top
objectclass: metaTop
objectclass: metaAttributeType
m-name: ads-pwdMinClasses
creatorsname: uid=admin,ou=system
m-equality: integerMatch
m-length: 0
EOF
fi

file2=m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif
if [ ! -f "$file2" ]; then
  cat > $file2 <<EOF
version: 1
dn: m-oid=1.3.6.1.4.1.18060.0.4.1.2.940,ou=attributeTypes,cn=adsconfig,ou=schema
m-singlevalue: TRUE
m-oid: 1.3.6.1.4.1.18060.0.4.1.2.940
m-syntax: 1.3.6.1.4.1.1466.115.121.1.27
objectclass: top
objectclass: metaTop
objectclass: metaAttributeType
m-name: ads-pwdInHistoryDuration
creatorsname: uid=admin,ou=system
m-equality: integerMatch
m-length: 0
EOF
fi

file3=m-oid=1.3.6.1.4.1.42.2.27.8.1.32.ldif
if [ ! -f "$file3" ]; then
  cat > $file3 <<EOF
version: 1
dn: m-oid=1.3.6.1.4.1.42.2.27.8.1.32,ou=attributeTypes,cn=pwdpolicy,ou=schema
m-singlevalue: TRUE
m-oid: 1.3.6.1.4.1.42.2.27.8.1.32
m-syntax: 1.3.6.1.4.1.1466.115.121.1.27
objectclass: metaTop
objectclass: metaAttributeType
objectclass: top
m-name: pwdMinClasses
creatorsname: uid=admin,ou=system
m-equality: integerMatch
m-length: 0
EOF
fi

file4=m-oid=1.3.6.1.4.1.42.2.27.8.1.33.ldif
if [ -f "$file4" ]; then
 rm $file4
fi


FILES="m-oid=1.3.6.1.4.1.18060.0.4.1.2.939.ldif m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif m-oid=1.3.6.1.4.1.42.2.27.8.1.32.ldif m-oid=1.3.6.1.4.1.42.2.27.8.1.33.ldif"
for FILE in $FILES
do
  if [ -f "$FILE" ]; then
   echo "Deleting abundant files"
  rm $FILE 
fi
  
done

for FILE in "m-oid\=1.3.6.1.4.1.42.2.27.8.2.1.ldif m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif"
do
if [ `grep -c "pwdMinClasses" $FILE` -eq '1' ]; then

    echo "Found!"
else
    echo "No Adding config in Apacheds"
    sed -i '$a m-may: pwdMinClasses\' $FILE
fi

if [ `grep -c "pwdInHistoryDuration" $FILE` -eq '1' ]; then

    echo "Found!"
else
    echo "NO Adding"
    sed -i '$a m-may: pwdInHistoryDuration\' $FILE
fi

done

if [ `grep -c "pwdMinClasses" ~/tmp/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif` -eq '1' ]; then

    echo "Found!"
else
    echo "No Adding config in Apacheds"
    sed -i '$a m-may: pwdMinClasses\' m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif
fi

if [ `grep -c "pwdInHistoryDuration" m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif` -eq '1' ]; then

    echo "Found!"
else
    echo "NO Adding"
    sed -i '$a m-may: pwdInHistoryDuration\' m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif
fi


curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/GUARDIAN/guardian-3.1.1-final/IMAGE/centos-7/GUARDIAN-Image-Registry-Transwarp-3.1.1-final.tar.gz" > /var/lib/docker/guardianold.tar.gz

set -x 是开启 set +x是关闭 set -o是查看 (xtrace)，set去追中一段代码的显示情况。

	if strings.Contains(strings.ToLower(sql), " USER() ") {
		strings.Replace(sql, " USER() ", " CURRENT_USER() ", -1)
	}

	replaceStr := " user()"
	if strings.Contains(strings.ToLower(sql), replaceStr) {
		index := strings.Index(strings.ToLower(sql), replaceStr)
		sql = sql[:index]+" current_user()"+sql[index+len(replaceStr):]
	}
	
	
	
	fmt.Println(sql)

本地登陆kundb
mysql -h172.16.1.236 -P15307 -uadmin -padmin --enable-cleartext-plugin --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA


[root@tw-node1237 ou=objectclasses]# pwd

creatorsname: uid=admin,ou=system


/guardian/data/partitions/schema/ou=schema/cn=pwdpolicy/ou=objectclasses/m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif
/guardian/data/partitions/schema/ou=schema/cn=adsconfig/ou=objectclasses/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif

/guardian/data/partitions/schema/ou=schema/cn=adsconfig/ou=objectclasses/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif /guardian/data/partitions/schema/ou=schema/cn=pwdpolicy/ou=objectclasses/m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif

/guardian/data/partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.33.ldif
/guardian/data/partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.32.ldif
/guardian/data/partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif
/guardian/data/partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.939.ldif

/guardian/data/partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.33.ldif /guardian/data/partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.32.ldif /guardian/data/partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif /guardian/data/partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.939.ldif

ads-pwdid=default,ou=passwordPolicies,ads-interceptorid=authenticationInterceptor,ou=interceptors,ads-directoryserviceid=default,ou=config

docker run -e CONF_DIR=/etc/guardian/conf -e DUMP_FILE=/etc/guardian/conf/pre_upgrade.dump -e oldVersion=guardian-3.1.0-final --net=host --volume /etc/guardian/conf:/etc/guardian/conf --volume /guardian/data/:/guardian/data/ --volume /transwarp/mounts/guardian:/vdir transwarp/apacheds:guardian-3.1 bash /bin/pre_rollback.sh

dn: m-oid=1.3.6.1.4.1.18060.0.4.1.2.938,ou=attributeTypes,cn=adsconfig,ou=schema
objectclass: top
objectclass: metaTop
objectclass: metaAttributeType
m-oid: 1.3.6.1.4.1.18060.0.4.1.2.938
m-name: ads-delegateTlsTrustManager
m-description: FQCN of the TrustManager to use to validate the startTls communication
m-syntax: 1.3.6.1.4.1.1466.115.121.1.15
m-equality: caseExactMatch
m-singlevalue: TRUE
m-length: 0
creatorsname: 0.9.2342.19200300.100.1.1=admin,2.5.4.11=system



 @Override
  public void grantPrivileges(List<HivePrincipal> hivePrincipals, List<HivePrivilege> hivePrivileges, HivePrivilegeObject hivePrivObject, HivePrincipal grantorPrincipal, boolean grantOption) throws HiveAuthzPluginException, HiveAccessControlException {
    List<String> dataSource = InceptorPermUtil.convert(hivePrivObject);

    HivePrivilegeObject.HivePrivilegeObjectType objectType = hivePrivObject.getType();
    if (objectType == null) {
      objectType = HivePrivilegeObject.HivePrivilegeObjectType.GLOBAL;
    }

    hivePrivileges = expandAndValidatePrivileges(hivePrivileges, objectType);

    // authorize the grant
    guardianAuthorizer.authorizeGrant(authenticator.getUserName(), hivePrivileges, hivePrivObject);

    for (HivePrincipal principal : hivePrincipals) {
      for (HivePrivilege privilege : hivePrivileges) {
        PermissionVo permVo = new PermissionVo(component, dataSource, privilege.getName());
        permVo.setGrantable(grantOption);
        if (principal.getType() == null || StringUtils.isEmpty(principal.getType().name())) continue;
        try {
          PrincipalType princType = Enum.valueOf(PrincipalType.class, principal.getType().name());
          EntityPermissionVo entityPermVo = new EntityPermissionVo(principal.getName(), princType, permVo);
          guardianAdmin.grant(entityPermVo);

          // Grant Option as ADMIN permission
          if (grantOptionAsAdmin) {
            if (grantOption && (objectType == HivePrivilegeObject.HivePrivilegeObjectType.GLOBAL
                    || objectType == HivePrivilegeObject.HivePrivilegeObjectType.DATABASE
                    || objectType == HivePrivilegeObject.HivePrivilegeObjectType.TABLE_OR_VIEW)) {
              PermissionVo adminPermVo = new PermissionVo(component, dataSource, "ADMIN");
              EntityPermissionVo entityAdminPermVo = new EntityPermissionVo(principal.getName(), princType, adminPermVo);
              guardianAdmin.grant(entityAdminPermVo);
            }
          }

          // TODO: test Group
        } catch (GuardianClientException e) {
          LOG.error("Fail to grant permission: {} for hiveObj: {} to user: {}", privilege.getName(), dataSource,
                  principal.getName(), e);
          throw new HiveAuthzPluginException(e);
        } catch (IllegalArgumentException e) {
          LOG.warn("Parse hive principal type error", e);
          // ignore
        }
      }
    }
  }

revoke all问题 ：
用户create db的时候 初始化数据库并没有guardian权限的初始化 导致hive执行revoke时 针对于这个库没有任何权限 传到ldap查询的时候报错 当我们执行grant的时候 guardian权限为这个库初始化权限 再执行revoke就没有问题了
show grant问题
hive为了便于展示在showgrant的时候要根据权限的拥有者做排序，

#!/bin/bash

file1=m-oid=1.3.6.1.4.1.18060.0.4.1.2.939.ldif
file2=m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif
file3=m-oid=1.3.6.1.4.1.42.2.27.8.1.32.ldif
file4=m-oid=1.3.6.1.4.1.42.2.27.8.1.33.ldif
UPGRADE="m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif"
#Check modify in pre_upgrade 
for FILE in $UPGRADE
do
if [ `grep -c "pwdMinClasses" $FILE` -eq '1' ]; then

    echo "Found!"
else
    echo "No Adding config in Apacheds"
    sed -i '$i\m-may: pwdMinClasses\' $FILE
fi

if [ `grep -c "pwdInHistoryDuration" $FILE` -eq '1' ]; then

    echo "Found!"
else
    echo "NO Adding"
    sed -i '$i\m-may: pwdInHistoryDuration\' $FILE
fi

done

resourcemanager单测覆盖 test guardian接口有3个可能要添加接口 下周做
docker ps -a 
docker logs 
查看升级脚本日志
inceptor报错: 1. revoke no datasource node会报错
2. grant all on db to user -> show grant -> revoke all on db from user -> show grant

0407

工作周报 - 李镇邦 20200330 ~ 20200403

完成：
1. WARP-43339: guardian密码策略升级回滚脚本并测试

其他：
1. KunDB增加ip限制和空闲时间的使用说明
2. 验证inceptor两个bug：revoke all和show grants报错
3. 1236集群重装

Accesstoken登陆hdfs、inceptor组件时，租户管理员可以增删改该租户下所有用户的AcessToken
本周：
1. 讨论inceptor权限，决定inceptor权限的解决方案
2. WARP-43659： guardian resource-manager 单测覆盖率提升



                                <resource>
                                    <targetPath>rootfs/usr/bin</targetPath>
                                    <directory>docker-build/scripts/env</directory>
                                    <exclude>this_is_a_dummy_value</exclude>
                                </resource>

jar xf genesys_data_etl-0.0.1-SNAPSHOT.jar BOOT-INF/classes/realtime/t_ivr_data_bj.json
jar xf 内部jar包.jar conf/hbase.conf       # 解出内部jar包子路径下的指定文件

Mon Apr 06 22:15:11 EDT 2020 [Manager] Starting task local part ...
start to execute docker run -e CONF_DIR=/etc/guardian/conf -e DUMP_FILE=/etc/guardian/conf/pre_upgrade.dump -e oldVersion=guardian-3.1.2-final --net=host --volume /etc/guardian/conf:/etc/guardian/conf --volume /guardian/data/:/guardian/data/ --volume /transwarp/mounts/guardian:/vdir transwarp/apacheds:guardian-3.1 bash /bin/pre_upgrade.sh on tw-node1237
Starting Upgrade for password policy
Added ads-pwdMinClasses ldif file
Added ads-pwdInHistoryDuration ldif file
Added pwdMinClasses ldif file
Added pwdInHistoryDuration ldif file
No pwdMinClasses line, adding config in Apacheds
NO pwdInHistoryDuration line, adding config in Apacheds
No pwdMinClasses line, adding config in Apacheds
NO pwdInHistoryDuration line, adding config in Apacheds
Finishing Upgrade for password policy
 + echo 'Starting Upgrade for password policy'
+ cd /guardian/data/
+ LDIF_DIR=partitions/schema/ou=schema
+ file1=partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.939.ldif
+ file2=partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif
+ file3=partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.32.ldif
+ file4=partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.33.ldif
+ file5=partitions/schema/ou=schema/cn=pwdpolicy/ou=objectclasses/m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif
+ file6=partitions/schema/ou=schema/cn=adsconfig/ou=objectclasses/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif
+ '[' '!' -f partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.939.ldif ']'
+ cat
+ echo 'Added ads-pwdMinClasses ldif file'
+ '[' '!' -f partitions/schema/ou=schema/cn=adsconfig/ou=attributetypes/m-oid=1.3.6.1.4.1.18060.0.4.1.2.940.ldif ']'
+ cat
+ echo 'Added ads-pwdInHistoryDuration ldif file'
+ '[' '!' -f partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.32.ldif ']'
+ cat
+ echo 'Added pwdMinClasses ldif file'
+ '[' '!' -f partitions/schema/ou=schema/cn=pwdpolicy/ou=attributetypes/m-oid=1.3.6.1.4.1.42.2.27.8.1.33.ldif ']'
+ cat
+ echo 'Added pwdInHistoryDuration ldif file'
++ grep -c pwdMinClasses partitions/schema/ou=schema/cn=pwdpolicy/ou=objectclasses/m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif
+ '[' 0 -eq 1 ']'
+ echo 'No pwdMinClasses line, adding config in Apacheds'
+ sed -i '$a m-may: pwdMinClasses\' partitions/schema/ou=schema/cn=pwdpolicy/ou=objectclasses/m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif
++ grep -c pwdInHistoryDuration partitions/schema/ou=schema/cn=pwdpolicy/ou=objectclasses/m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif
+ '[' 0 -eq 1 ']'
+ echo 'NO pwdInHistoryDuration line, adding config in Apacheds'
+ sed -i '$a m-may: pwdInHistoryDuration\' partitions/schema/ou=schema/cn=pwdpolicy/ou=objectclasses/m-oid=1.3.6.1.4.1.42.2.27.8.2.1.ldif
++ grep -c pwdMinClasses partitions/schema/ou=schema/cn=adsconfig/ou=objectclasses/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif
+ '[' 0 -eq 1 ']'
+ echo 'No pwdMinClasses line, adding config in Apacheds'
+ sed -i '$i\m-may: ads-pwdMinClasses\' partitions/schema/ou=schema/cn=adsconfig/ou=objectclasses/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif
++ grep -c pwdInHistoryDuration partitions/schema/ou=schema/cn=adsconfig/ou=objectclasses/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif
+ '[' 0 -eq 1 ']'
+ echo 'NO pwdInHistoryDuration line, adding config in Apacheds'
+ sed -i '$i\m-may: ads-pwdInHistoryDuration\' partitions/schema/ou=schema/cn=adsconfig/ou=objectclasses/m-oid=1.3.6.1.4.1.18060.0.4.1.3.900.ldif
+ echo 'Finishing Upgrade for password policy'
execute docker run -e CONF_DIR=/etc/guardian/conf -e DUMP_FILE=/etc/guardian/conf/pre_upgrade.dump -e oldVersion=guardian-3.1.2-final --net=host --volume /etc/guardian/conf:/etc/guardian/conf --volume /guardian/data/:/guardian/data/ --volume /transwarp/mounts/guardian:/vdir transwarp/apacheds:guardian-3.1 bash /bin/pre_upgrade.sh on tw-node1237 successfully
Mon Apr 06 22:15:12 EDT 2020 [Manager] Task local part ended


curl -X GET -u zhenbang.li:123456 "http://172.16.1.97:8080/remote.php/webdav/TRANSWARP_RELEASES/OFFICIAL/TDH/transwarp-6.2.1-final/IMAGE/centos-7/TDH-Image-Registry-Transwarp-6.2.1-final.tar.gz" > /var/lib/docker/TDH.tar.gz

DDLTask
writeGrantInfo

revokePrivileges



beeline -u "jdbc:hive2://localhost:10000/default;principal=hive/tw-node1238@TDH"

Java HotSpot(TM) 64-Bit Server VM warning: Using the ParNew young collector with the Serial old collector is deprecated and will likely be removed in a future release
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/inceptor/lib/graphsearch-hive-2.0.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/inceptor/lib/shiva-client-shade-1.3.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/inceptor/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
scan complete in 5ms
Connecting to jdbc:hive2://localhost:10000/default;principal=hive/tw-node1238@TDH
2020-04-07 14:10:34,487 INFO  [main] jdbc.Utils (Utils.java:parseURL(304)) - Supplied authorities: localhost:10000
2020-04-07 14:10:34,494 INFO  [main] jdbc.Utils (Utils.java:parseURL(391)) - Resolved authority: localhost:10000
2020-04-07 14:10:35,099 INFO  [Thread-1] util.KerberosUtil (KerberosUtil.java:getDefaultPrincipalPattern(81)) - Using principal pattern: HTTP/_HOST
Connected to: Apache Hive (version 8.0.2)
Driver: Inceptor JDBC (version 8.0.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 8.0.2 by Apache Hive
0: jdbc:hive2://localhost:10000/default> 

DDLTask 
hive/HivePrincipal-->compareTo
plugin/HivePrivilegeObject--->compareTo


 if (compare == 0) {
      compare = dbname != null ?
          (o.dbname != null ? dbname.compareTo(o.dbname) : 1) :
          (o.dbname != null ? -1 : 0);
    }


TABLE_OR_VIEW
db2


EXECUTION FAILED: Task DDL error HiveAuthzPluginException: [Error 40000] ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db333], component='inceptor5', grantable='false'} from USER: a
2020-04-08 11:04:01,212 INFO  ql.Driver: (PerfLogger.java:PerfLogEnd(138)) [HiveServer2-Handler-Pool: Thread-36547(SessionHandle=937109ed-3537-4f5b-8066-6a8b73d724bb)] - </PERFLOG method=Driver.execute start=1586315041087 end=1586315041212 duration=125>
2020-04-08 11:04:01,212 INFO  exec.TransactionManagerHeartbeaterThread: (TransactionManagerHeartbeaterThread.java:stopHeartBeat(70)) [HiveServer2-Handler-Pool: Thread-36547()] - Unregister heart beat for session: 937109ed-3537-4f5b-8066-6a8b73d724bb
2020-04-08 11:04:01,213 WARN  thrift.ThriftCLIService: (ThriftCLIService.java:ExecuteStatement(553)) [HiveServer2-Handler-Pool: Thread-36547()] - Error executing statement:
org.apache.hive.service.cli.HiveSQLException: EXECUTION FAILED: Task DDL error HiveAuthzPluginException: [Error 40000] ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db333], component='inceptor5', grantable='false'} from USER: a
        at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:90)
        at org.apache.hive.service.cli.operation.Operation.run(Operation.java:295)
        at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:434)
        at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:401)
        at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:333)
        at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:148)
        at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:542)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1857)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1842)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

172.26.0.37
root/Aiops!123
beeline -u jdbc:hive2://172.26.0.38:10000 -n hive -p 123456

{action: "ADMIN", component: "inceptor5", dataSource: ["TABLE_OR_VIEW", "db3"]}

一般都是直接grant，如果发现permission没创建的话，会自动创建

2020-04-08 15:09:27,027 field=PERMISSION, requestClass=RevokePermRequest, user=hive, serverIp=172.26.0.38, clientIp=172.26.0.38, level=UPDATE, operation=revoke permission, entity [EntityPermissionVo{name='a', principalType=USER, permissionVo=PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db36666], component='inceptor5', grantable='false'}}], statusCode=500, errorCode=3007
2020-04-08 15:09:27,027 field=PERMISSION, requestClass=RevokePermRequest, user=hive, serverIp=172.26.0.38, clientIp=172.26.0.38, level=UPDATE, operation=revoke permission, entity [EntityPermissionVo{name='a', principalType=USER, permissionVo=PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db36666], component='inceptor5', grantable='false'}}], statusCode=500, errorCode=3007


compare = dbname != null ?
          (o.dbname != null ? dbname.compareTo(o.dbname) : 1) :
          (o.dbname != null ? -1 : 0);

    int compare = o.name != null ? name.compareTo(o.name) : 0;


git log --author="lishinho" --pretty=tformat: --numstat | awk '{ add += $1; subs += $2; loc += $1 - $2 } END { printf "added lines: %s, removed lines: %s, total lines: %s\n", add, subs, loc }' -


if *enablePlanCache {
		if result, ok := e.plans.Get(key); ok {
			servenv.AccumPlanCacheHit.Add(1)
			return result.(*engine.Plan), nil
		}
	}


{
  "name": "a",
  "permissionVo": {
    "action": "SELECT",
    "administrative": false,
    "component": "inceptor5",
    "dataSource": [
      "TABLE_OR_VIEW", 
      "db342345222222"
    ],
    "grantable": false,
    "heritable": false
  },
  "principalType": "USER"
}


2020-04-08 15:12:53,219 WARN io.transwarp.guardian.common.util.ResourceUtil: Can not find string by key 3007 in resource guardian-error
io.transwarp.guardian.common.exception.GuardianException: ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db36666], component='inceptor5', grantable='false'} from USER: a
        at io.transwarp.guardian.core.manager.PermManager.revoke(PermManager.java:454)
        at io.transwarp.guardian.server.boot.controller.PermController.revokePermission(PermController.java:378)
        at io.transwarp.guardian.server.boot.controller.PermController$$FastClassBySpringCGLIB$$c4c73116.invoke(<generated>)
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:52)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:174)
        at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:62)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:174)

2020-04-08 15:09:27,488 ERROR org.apache.directory.fortress.core.impl.PermUtil: Read permissions failed for permission: Permission{ou='inceptor5', objName='[TABLE_OR_VIEW, db36666]', opName='DELETE', objId='null'}
org.apache.directory.fortress.core.FinderException: getPerm no entry found dn [ftOpNm=DELETE,ftObjNm=db36666,ftObjNm=TABLE_OR_VIEW,ou=inceptor5,ou=Permissions,ou=RBAC,dc=tdh]
        at org.apache.directory.fortress.core.impl.PermDAO.getPerm(PermDAO.java:1110)
        at org.apache.directory.fortress.core.impl.PermP.read(PermP.java:358)
        at org.apache.directory.fortress.core.impl.PermUtil.loadPerm(PermUtil.java:158)
        at org.apache.directory.fortress.core.impl.PermUtil.getDetailedPerm(PermUtil.java:146)
        at org.apache.directory.fortress.core.impl.PermUtil.isGrantable(PermUtil.java:42)
        at org.apache.directory.fortress.core.impl.AdminUtil.canRevoke(AdminUtil.java:299)
        at org.apache.directory.fortress.core.impl.AdminMgrImpl.revokePermission(AdminMgrImpl.java:731)
        at io.transwarp.guardian.core.manager.PermManager.revoke(PermManager.java:407)
        at io.transwarp.guardian.server.boot.controller.PermController.revokePermission(PermController.java:378)
        at io.transwarp.guardian.server.boot.controller.PermController$$FastClassBySpringCGLIB$$c4c73116.invoke(<generated>)

旧版本admin可以revoke不存在的权限 hive不能


    Permission getPerm( Permission permission )
        throws FinderException
    {
        Permission entity = null;
        LdapConnection ld = null;
        String dn = getDn( permission, permission.getContextId() );

        try
        {
            ld = getAdminConnection( true );
            Entry findEntry = read( ld, dn, PERMISSION_OP_ATRS );
            if ( findEntry == null )
            {
                String warning = "getPerm no entry found dn [" + dn + "]";
                throw new FinderException( GlobalErrIds.PERM_OP_NOT_FOUND, warning );
            }
            entity = unloadPopLdapEntry( findEntry, 0, permission.isAdmin() );
        }
        catch ( LdapNoSuchObjectException e )
        {
            String warning = "getPerm Op COULD NOT FIND ENTRY for dn [" + dn + "]";
            throw new FinderException( GlobalErrIds.PERM_OP_NOT_FOUND, warning );
        }
        catch ( LdapException e )
        {
            String error = "getUser [" + dn + "] caught LdapException=" + e.getMessage();
            throw new FinderException( GlobalErrIds.PERM_READ_OP_FAILED, error, e );
        }
        finally
        {
            closeAdminConnection( ld );
        }
        return entity;
    }
{
  "name": "a",
  "permissionVo": {
    "action": "SELECT",
    "administrative": false,
    "component": "inceptor5",
    "dataSource": [
      "TABLE_OR_VIEW", 
      "db342345222222"
    ],
    "grantable": false,
    "heritable": false
  },
  "principalType": "USER"
}


2020-04-08 15:12:53,219 WARN io.transwarp.guardian.common.util.ResourceUtil: Can not find string by key 3007 in resource guardian-error
io.transwarp.guardian.common.exception.GuardianException: ErrorCode: 3007, ErrorMessage: Failed to revoke permission PermissionVo{action='DELETE', dataSource=[TABLE_OR_VIEW, db36666], component='inceptor5', grantable='false'} from USER: a
        at io.transwarp.guardian.core.manager.PermManager.revoke(PermManager.java:454)
        at io.transwarp.guardian.server.boot.controller.PermController.revokePermission(PermController.java:378)
        at io.transwarp.guardian.server.boot.controller.PermController$$FastClassBySpringCGLIB$$c4c73116.invoke(<generated>)
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:52)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:174)
        at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:62)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:174)

2020-04-08 15:09:27,488 ERROR org.apache.directory.fortress.core.impl.PermUtil: Read permissions failed for permission: Permission{ou='inceptor5', objName='[TABLE_OR_VIEW, db36666]', opName='DELETE', objId='null'}
org.apache.directory.fortress.core.FinderException: getPerm no entry found dn [ftOpNm=DELETE,ftObjNm=db36666,ftObjNm=TABLE_OR_VIEW,ou=inceptor5,ou=Permissions,ou=RBAC,dc=tdh]
        at org.apache.directory.fortress.core.impl.PermDAO.getPerm(PermDAO.java:1110)
        at org.apache.directory.fortress.core.impl.PermP.read(PermP.java:358)
        at org.apache.directory.fortress.core.impl.PermUtil.loadPerm(PermUtil.java:158)
        at org.apache.directory.fortress.core.impl.PermUtil.getDetailedPerm(PermUtil.java:146)
        at org.apache.directory.fortress.core.impl.PermUtil.isGrantable(PermUtil.java:42)
        at org.apache.directory.fortress.core.impl.AdminUtil.canRevoke(AdminUtil.java:299)
        at org.apache.directory.fortress.core.impl.AdminMgrImpl.revokePermission(AdminMgrImpl.java:731)
        at io.transwarp.guardian.core.manager.PermManager.revoke(PermManager.java:407)
        at io.transwarp.guardian.server.boot.controller.PermController.revokePermission(PermController.java:378)
        at io.transwarp.guardian.server.boot.controller.PermController$$FastClassBySpringCGLIB$$c4c73116.invoke(<generated>)

旧版本admin可以revoke不存在的权限 hive不能


    Permission getPerm( Permission permission )
        throws FinderException
    {
        Permission entity = null;
        LdapConnection ld = null;
        String dn = getDn( permission, permission.getContextId() );

        try
        {
            ld = getAdminConnection( true );
            Entry findEntry = read( ld, dn, PERMISSION_OP_ATRS );
            if ( findEntry == null )
            {
                String warning = "getPerm no entry found dn [" + dn + "]";
                throw new FinderException( GlobalErrIds.PERM_OP_NOT_FOUND, warning );
            }
            entity = unloadPopLdapEntry( findEntry, 0, permission.isAdmin() );
        }
        catch ( LdapNoSuchObjectException e )
        {
            String warning = "getPerm Op COULD NOT FIND ENTRY for dn [" + dn + "]";
            throw new FinderException( GlobalErrIds.PERM_OP_NOT_FOUND, warning );
        }
        catch ( LdapException e )
        {
            String error = "getUser [" + dn + "] caught LdapException=" + e.getMessage();
            throw new FinderException( GlobalErrIds.PERM_READ_OP_FAILED, error, e );
        }
        finally
        {
            closeAdminConnection( ld );
        }
        return entity;
    }


	//check cache if yes, right; else go on
	if result, ok := cache.Get(authData.Username); ok {
		
	}
	getter, err := c.config.AuthService.Authenticate(authData.Username, authData.Password)
	if err != nil {
		field := logrus.Fields{
			"Time":       time.Now().Format(time.RFC850),
			"AuthResult": "Fail",
			"RemoteAddr": tlsConn.RemoteAddr().String(),
			"User":       authData.Username,
		}
		audit.Log(field, "Auth")
		authRespBuf[0] = authFailByte
	} else {
		field := logrus.Fields{
			"Time":       time.Now().Format(time.RFC850),
			"AuthResult": "Success",
			"RemoteAddr": tlsConn.RemoteAddr().String(),
			"User":       authData.Username,
		}
		//record in cache using SetIfAbsent

		audit.Log(field, "Auth")
	}

func (pln *Plan) Size() int {
	return 1
}

// Get returns wrapped username and LDAP groups and possibly updates the cache
func (lud *LdapUserData) Get() *querypb.VTGateCallerID {
	if time.Since(lud.lastUpdated) > lud.asl.RefreshTimeout*time.Second {
		go lud.update()
	}
	return &querypb.VTGateCallerID{Username: lud.username, Groups: lud.groups}
}

enablePlanCache     = flag.Bool("enable_plan_cache", true, "whether to use plan cache or not")



	//check cache if yes, right; else go on
	result, ok := servenv.LdapCache.Get(authData.Username)
	if ok {
		field := logrus.Fields{
			"Time":       time.Now().Format(time.RFC850),
			"AuthResult": "Success",
			"RemoteAddr": tlsConn.RemoteAddr().String(),
			"User":       authData.Username,
		}
		audit.Log(field, "Auth")

		err := c.sendAll(tlsConn, authRespBuf)
		if err != nil {
			return nil, nil, err
		}
		return tlsConn, TLSWithPasswordAuthInfo{State: getTLSConnectionState(tlsAuthInfo), CallerID: result.(*servenv.CacheValue)}, nil
	}

servenv.LoginCache.Get(user)
/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-keystore.jks
/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-truststore.jks

mysql -h127.0.0.1 -P15307 -uvt_app -p123 --enable-cleartext-plugin --ssl-ca=/etc/kundb1/conf/ca-cert.pem --ssl-cert=/etc/kundb1/conf/kungate-client-cert.pem --ssl-key=/etc/kundb1/conf/kungate-client-key.pem --ssl-mode=VERIFY_CA

mysql -h127.0.0.1 -P15307 -uvt_app -p123 --enable-cleartext-plugin --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA


login_cache_conns

runtime error: invalid memory address or nil pointer dereference

services
{"serviceName":"hdfs1","serviceType":"HDFS","description":"description","serviceHosts":["tw-node1237","tw-node1238"],"timestamp":1586427963065}]
serviceMapping
{"hdfs1":"hdfs1","inceptor1":"inceptor1","yarn1":"yarn1"}
searchPrincipals?component=hdfs1&dataSource=GLOBAL&action=ADMIN
{"users":["admin","hdfs"],"groups":[],"roles":[]}

resourceLookupVo
{
  "resources": {
"name": ["123","124"]},
  "serviceName": "hdfs1",
  "serviceType": "HDFS",
  "userInput": "aaa"
}
QuotaManager

golang gocache
awk指令

public class HdfsResourceSvcTest {
  private HdfsResourceSvc hdfsResourceSvc;

  @Test
  public void connectionTest() throws GuardianException {
    Assert.assertFalse(hdfsResourceSvc.connectionTest());
  }

  @Test
  public void lookupResource() throws GuardianException {
    HdfsResourceMgrTest mgrTest = new HdfsResourceMgrTest();
    mgrTest.getHdfsResources();
  }
}

new ResourceEntry(
      new NodeVo(ResourceTypes.CLUSTER, CLUSTER_RESOURCE_NAME));
new ResourceVo.Builder().serviceName(component).dataSource(SEARCH_CLUSTER).build()

ResourceVo resourceVo = new ResourceVo("HDFS", "service", Arrays.asList(new NodeVo("DIR", "/"),
            new NodeVo("DIR", "secret")));


 // [] -> [<scheduler *>]
  // [<pool root.default.sub_queue>] -> [<scheduler *>, <queue root>, <queue default>, <queue sub_queue>]

工作周报 - 李镇邦 20200407 ~ 20200410

完成：
1. WARP-43781: 解决Inceptor 权限show grant 和revoke all报错
2. WARP-43853: 用户登陆处增加缓存logincache 增加manager界面参数限定cache容量
3. 解决WARP-41406,WARP-41627 MR冲突

进行中：
WARP-43659： guardian resource-manager 单测覆盖率提升

编辑
备注
分配更多
Start Test
导出





[WARNING] /security/guardian-backend/guardian/resource-manager/src/test/java/io/transwarp/guardian/resource/ResourceServiceInitializerTest.java: /security/guardian-backend/guardian/resource-manager/src/test/java/io/transwarp/guardian/resource/ResourceServiceInitializerTest.java uses or overrides a deprecated API.
[WARNING] /security/guardian-backend/guardian/resource-manager/src/test/java/io/transwarp/guardian/resource/ResourceServiceInitializerTest.java: Recompile with -Xlint:deprecation for details.
[WARNING] /security/guardian-backend/guardian/resource-manager/src/test/java/io/transwarp/guardian/resource/hdfs/HdfsResourceMgrTest.java: Some input files use unchecked or unsafe operations.
[WARNING] /security/guardian-backend/guardian/resource-manager/src/test/java/io/transwarp/guardian/resource/hdfs/HdfsResourceMgrTest.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /security/guardian-backend/guardian/resource-manager/src/test/java/io/transwarp/guardian/resource/tcc/TccResourceSvcTest.java:[29,35] cannot find symbol
  symbol:   method initialize()
  location: variable resourceServiceInitializerTest of type io.transwarp.guardian.resource.ResourceServiceInitializerTest
[INFO] 1 error

getInheritDataNodes
getAuthorizedDataNodes


Running io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest
2020-04-13 10:33:56,282 DEBUG conf.GuardianConfiguration: parsing URL file:/security/guardian-backend/guardian/resource-manager/target/test-classes/guardian-site.xml
2020-04-13 10:33:56,282 DEBUG conf.GuardianConfiguration: parsing input stream java.io.BufferedInputStream@6d4dac56
2020-04-13 10:33:56,286 DEBUG conf.GuardianConfiguration: parsing URL file:/security/guardian-backend/guardian/resource-manager/target/test-classes/guardian-site.xml
2020-04-13 10:33:56,287 DEBUG conf.GuardianConfiguration: parsing input stream java.io.BufferedInputStream@1ca55d5
2020-04-13 10:33:56,296 DEBUG conf.GuardianConfiguration: parsing URL file:/security/guardian-backend/guardian/resource-manager/target/test-classes/guardian-site.xml
2020-04-13 10:33:56,297 DEBUG conf.GuardianConfiguration: parsing input stream java.io.BufferedInputStream@6fc9c0cc
Tests run: 3, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 0.021 sec <<< FAILURE! - in io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest
lookupResource(io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest)  Time elapsed: 0.001 sec  <<< ERROR!
java.lang.NullPointerException: null
	at io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest.getInceptorResources(InceptorResourceMgrTest.java:43)
	at io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest.lookupResource(InceptorResourceSvcTest.java:20)

getSchedulerType(io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest)  Time elapsed: 0.008 sec  <<< ERROR!
java.lang.ClassCastException: io.transwarp.guardian.common.conf.GuardianConfiguration cannot be cast to java.util.Map
	at io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest.getSchedulerType(InceptorResourceMgrTest.java:26)
	at io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest.getSchedulerType(InceptorResourceSvcTest.java:25)

connectionTest(io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest)  Time elapsed: 0 sec  <<< ERROR!
java.lang.NullPointerException: null
	at io.transwarp.guardian.resource.inceptor.InceptorResourceSvcTest.connectionTest(InceptorResourceSvcTest.java:15)

Running io.transwarp.guardian.resource.inceptor.InceptorSchedulerResponseTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec - in io.transwarp.guardian.resource.inceptor.InceptorSchedulerResponseTest
Running io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest
2020-04-13 10:33:56,300 DEBUG conf.GuardianConfiguration: parsing URL file:/security/guardian-backend/guardian/resource-manager/target/test-classes/guardian-site.xml
2020-04-13 10:33:56,300 DEBUG conf.GuardianConfiguration: parsing input stream java.io.BufferedInputStream@7011eee0
2020-04-13 10:33:56,304 DEBUG conf.GuardianConfiguration: parsing URL file:/security/guardian-backend/guardian/resource-manager/target/test-classes/guardian-site.xml
2020-04-13 10:33:56,304 DEBUG conf.GuardianConfiguration: parsing input stream java.io.BufferedInputStream@5beda06e
2020-04-13 10:33:56,307 DEBUG conf.GuardianConfiguration: parsing URL file:/security/guardian-backend/guardian/resource-manager/target/test-classes/guardian-site.xml
2020-04-13 10:33:56,307 DEBUG conf.GuardianConfiguration: parsing input stream java.io.BufferedInputStream@24eb71f6
Tests run: 3, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.007 sec <<< FAILURE! - in io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest
getSchedulerType(io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest)  Time elapsed: 0.001 sec  <<< ERROR!
java.lang.ClassCastException: io.transwarp.guardian.common.conf.GuardianConfiguration cannot be cast to java.util.Map
	at io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest.getSchedulerType(InceptorResourceMgrTest.java:26)

getInceptorResources(io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest)  Time elapsed: 0 sec  <<< ERROR!
java.lang.NullPointerException: null
	at io.transwarp.guardian.resource.inceptor.InceptorResourceMgrTest.getInceptorResources(InceptorResourceMgrTest.java:43)

Running io.transwarp.guardian.resource.inceptor.hms.sync.PathUtilsTest
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.027 sec <<< FAILURE! - in io.transwarp.guardian.resource.inceptor.hms.sync.PathUtilsTest
splitPath(io.transwarp.guardian.resource.inceptor.hms.sync.PathUtilsTest)  Time elapsed: 0.005 sec  <<< FAILURE!
java.lang.AssertionError: array lengths differed, expected.length=0 actual.length=1
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.internal.ComparisonCriteria.assertArraysAreSameLength(ComparisonCriteria.java:76)
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:37)
	at org.junit.Assert.internalArrayEquals(Assert.java:532)
	at org.junit.Assert.assertArrayEquals(Assert.java:283)
	at org.junit.Assert.assertArrayEquals(Assert.java:298)
	at io.transwarp.guardian.resource.inceptor.hms.sync.PathUtilsTest.splitPath(PathUtilsTest.java:13)

Running io.transwarp.guardian.resource.inceptor.hms.sync.NotificationProcessorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 sec - in io.transwarp.guardian.resource.inceptor.hms.sync.NotificationProcessorTest
Running io.transwarp.guardian.resource.ResourceEntryTest
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.004 sec <<< FAILURE! - in io.transwarp.guardian.resource.ResourceEntryTest
ofTest(io.transwarp.guardian.resource.ResourceEntryTest)  Time elapsed: 0.003 sec  <<< ERROR!
java.lang.NullPointerException: null
	at io.transwarp.guardian.resource.ResourceEntry.of(ResourceEntry.java:113)
	at io.transwarp.guardian.resource.ResourceEntryTest.ofTest(ResourceEntryTest.java:12)


Results :

Failed tests: 
  ResourceEntryTest.differenceTest:29 expected null, but was:<[]>
  PathUtilsTest.splitPath:13 array lengths differed, expected.length=0 actual.length=1

 private static final Map<String, Class<? extends ResourceBaseService>> RES_CLASS_MAP =
      ImmutableMap.<String, Class<? extends ResourceBaseService>>builder()
          .put("HDFS", HdfsResourceSvc.class)
          .put("YARN", YarnResourceSvc.class)
          .put("HYPERBASE", HyperbaseResourceSvc.class)
          .put("INCEPTOR", InceptorResourceSvc.class)
          .put("SLIPSTREAM", InceptorResourceSvc.class)
          .put("ZOOKEEPER", ZookeeperResourceSvc.class)
          .put("SOPHON", SophonResourceSvc.class)
          .put("WORKFLOW", WorkflowResourceSvc.class)
          .put("RUBIK", RubikResourceSvc.class)
          .put("PILOT", PilotResourceSvc.class)
          .put("DISCOVER", DiscoverResourceSvc.class)
          .put("NOTEBOOK", DiscoverResourceSvc.class)
          .put("TRANSPORTER", TransporterResourceSvc.class)
          .put("KAFKA", KafkaResourceSvc.class)
          .put("ELASTICSEARCH", SearchResourceSvc.class)
          .put("SLIPSTREAMSTUDIO", SlipstreamStudioResourceSvc.class)
          .put("TCC", TccResourceSvc.class).build();


Results :

Failed tests: 
  RubikResourceMgrTest.isResourceTypeMatchTest:16 null

Tests in error: 
  ResourceEntryTest.ofTest:12 » NullPointer
  KerberosUtilsTest.loginTest:24 NullPointer
  StudioCommonResourceMgrTest.getResourcesTest:28 » NullPointer
  WorkflowResourceSvcTest.<init>:9 » NullPointer
  WorkflowResourceSvcTest.<init>:9 » NullPointer
  RubikResourceSvcTest.lookupResourceTest:19 » NullPointer
  HyperbaseResourceSvcTest.<init>:8 » NullPointer
  HyperbaseResourceSvcTest.<init>:8 » NullPointer
  HyperbaseResourceMgrTest.getHyperbaseResourcesTest:18 » NullPointer
  ResourceServiceInitializerTest.addServiceSuperuserTest:32 » NullPointer
  KafkaResourceSvcTest.<init>:9 » NullPointer
  KafkaResourceSvcTest.<init>:9 » NullPointer
  KafkaResourceMgrTest.<init>:20 ClassCast io.transwarp.guardian.common.conf.Gua...
  SearchResourceSvcTest.<init>:8 » NullPointer
  SearchResourceSvcTest.<init>:8 » NullPointer
  SearchResourceMgrTest.<init>:18 ClassCast io.transwarp.guardian.common.conf.Gu...
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnSiteProviderTest.overrideSchedulerConfAndReturnXmlTest:17 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  InceptorResourceSvcTest.lookupResource:20 » NullPointer
  InceptorResourceSvcTest.getSchedulerType:25 » ClassCast io.transwarp.guardian....
  InceptorResourceSvcTest.connectionTest:15 NullPointer
  InceptorResourceMgrTest.getSchedulerType:26 ClassCast io.transwarp.guardian.co...
  InceptorResourceMgrTest.getInceptorResources:43 NullPointer
  ServiceQuotaInterpreterTest.supplementRelatedHdfsQuotaTest:45 NullPointer
  HdfsResourceSvcTest.lookupResourceTest:17 » ClassCast io.transwarp.guardian.co...
  HdfsResourceSvcTest.connectionTest:12 NullPointer
  HdfsResourceMgrTest.<init>:15 ClassCast io.transwarp.guardian.common.conf.Guar...

Tests run: 67, Failures: 1, Errors: 38, Skipped: 0

@Test
  public void testLookupResource() throws Exception {
    System.setProperty("java.security.krb5.conf", "/home/qimeng/configuration/krb5.conf");
    ResourceServiceManager rsMgr = ResourceServiceManager.getInstance();
    Configuration conf = new Configuration();
    conf.addResource(new Path("/home/qimeng/configuration/core-site.xml"));
    conf.addResource(new Path("/home/qimeng/configuration/hdfs-site.xml"));
    Iterator<Map.Entry<String, String>> it = conf.iterator();
    Map<String, String> dummyConfigs = new HashMap<>();
    while(it.hasNext()) {
      Map.Entry<String, String> entry = it.next();
      dummyConfigs.put(entry.getKey(), entry.getValue());
    }
    rsMgr.register(null, "hdfs", "hdfs1", "hdfs service", dummyConfigs);
    ResourceLookupContext context = new ResourceLookupContext();
    context.setUser("hdfs");
    context.setResourceName("path");

  }

 public ResourceServiceManager(ApplicationContext context, ServiceManager serviceManager, ResourceManager resourceManager,
                                ResourceServiceInitializer initializer) {

  ApplicationContext context = new AnnotationConfigApplicationContext(TestConfiguration.class);
  ResourceServiceInitializer resInit = new ResourceServiceInitializer(userManager, permManager);
  ResourceServiceManager rsMgr = new ResourceServiceManager(context, serviceManager, resourceManager, resInit);


@RunWith(SpringRunner.class)
@ContextConfiguration(classes = TestConfiguration.class)

  @Autowired
  private ServiceManager serviceManager;
  @Autowired
  private ResourceManager resourceManager;
  @Autowired
  private UserManager userManager;
  @Autowired
  private PermManager permManager;

  @Before
  public void setUp() throws Exception {
    serviceManager.deleteAllClusters(null);
    serviceManager.deleteAllServices(null);
  }

        System.setProperty("java.security.krb5.conf", "/home/qimeng/inceptor1/krb5.conf");
        /*
        ResourceServiceManager rsMgr = ResourceServiceManager.getInstance();
        Configuration conf = new Configuration();
        conf.addResource(new Path("/home/qimeng/inceptor1/core-site.xml"));
        conf.addResource(new Path("/home/qimeng/inceptor1/hive-site.xml"));
        Iterator<Map.Entry<String, String>> it = conf.iterator();
        Map<String, String> dummyConfigs = new HashMap<>();
        while(it.hasNext()) {
            Map.Entry<String, String> entry = it.next();
            dummyConfigs.put(entry.getKey(), entry.getValue());
        }
        dummyConfigs.put("hive.server2.hostname", "tw-node1194");
        dummyConfigs.put("hive.server2.thrift.port", "10000");
        dummyConfigs.put("hive.server2.authentication.kerberos.principal", "hive/tw-node1194@TDH");
        rsMgr.register("inceptor", "inceptor1", "inceptor service", dummyConfigs);

        ResourceLookupContext context = new ResourceLookupContext();
        context.setResourceName("database");
        context.setUserInput("*");
        context.setUser("");
        List<String> list1 = rsMgr.lookupResource("INCEPTOR", "inceptor1", context);
        for(String result : list1)
            System.out.println(result);*/

        try {
            Class.forName("org.apache.hive.jdbc.HiveDriver");
        } catch (ClassNotFoundException e) {
        }

        Configuration conf = new Configuration();
        conf.set("hadoop.security.authentication", "kerberos");
        UserGroupInformation.setConfiguration(conf);
        // login user via KDC
        UserGroupInformation ugi1 = UserGroupInformation.loginUserFromKeytabAndReturnUGI("hive@TDH", "/home/qimeng/hdfs1/hive.keytab");
        Connection con1 = null;
        try {
            con1 = ugi1.doAs(new PrivilegedExceptionAction<Connection>() {
                public Connection run() throws Exception {
                    return DriverManager.getConnection("jdbc:hive2://tw-node1194:10000/default;principal=hive/tw-node1194@TDH");
                }
            });
            System.out.println("Connection hive@TDH: " + ugi1);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        if(con1 != null)
        {

            String tokenStrHive = ((HiveConnection) con1).getDelegationToken("hive", "hive@TDH");
            String tokenStrAdmin = ((HiveConnection) con1).getDelegationToken("admin", "hive@TDH");
            con1.close();

            Token<DelegationTokenIdentifier> hive2TokenAdmin = new Token<>(), hive2TokenHive = new Token<>();
            hive2TokenHive.decodeFromUrlString(tokenStrHive);
            hive2TokenAdmin.decodeFromUrlString(tokenStrAdmin);


            UserGroupInformation ugiHive = UserGroupInformation.createRemoteUser("hive");
            ugiHive.addToken(new Text("hive2Token"), hive2TokenHive);
            UserGroupInformation ugiAdmin = UserGroupInformation.createRemoteUser("admin");
            ugiAdmin.addToken(new Text("hive2Token"), hive2TokenAdmin);

            String sql = "show databases like \"*\"";

            try {
                Connection conHive = ugiHive.doAs(new PrivilegedExceptionAction<Connection>() {
                    public Connection run() throws Exception {
                        return DriverManager.getConnection("jdbc:hive2://tw-node1194:10000/default;auth=delegationToken");
                    }
                });
                Statement statement = conHive.createStatement();
                long start = System.currentTimeMillis();
                ResultSet rs = statement.executeQuery(sql);
                long end = System.currentTimeMillis();
                System.out.println("Connection hive: " + ugiHive);
                System.out.println("Time consumed: " + (end - start));
                while(rs.next())
                    System.out.println(rs.getString(1));
                statement.close();
                conHive.close();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

            try {
                Connection conAdmin = ugiAdmin.doAs(new PrivilegedExceptionAction<Connection>() {
                    public Connection run() throws Exception {
                        return DriverManager.getConnection("jdbc:hive2://tw-node1194:10000/default;auth=delegationToken");
                    }
                });
                Statement statement = conAdmin.createStatement();

                long start = System.currentTimeMillis();
                ResultSet rs = statement.executeQuery(sql);
                long end = System.currentTimeMillis();
                System.out.println("Connection admin: " + ugiAdmin);
                System.out.println("Time consumed: " + (end - start));
                while(rs.next())
                    System.out.println(rs.getString(1));
                statement.close();
                conAdmin.close();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

        }

Results :

Failed tests: 
  InceptorResourceMgrTest.getSchedulerType:29 expected null, but was:<ResourceEntry{entry=NodeVo{type='scheduler-type', value=''}, fullPath=[NodeVo{type='scheduler-type', value=''}], status=normal}>
  
ServiceQuotaInterpreterTest.supplementRelatedHdfsQuotaTest:48 expected:<[QuotaVo{resourceVo=ResourceVo{id=0, dataSource=[NodeVo{type='dir', value='/'}], serviceType='HDFS', serviceName='service', externalId=0}, properties={key=value}}, QuotaVo{resourceVo=ResourceVo{id=0, dataSource=[NodeVo{type='dir', value='/'}], serviceType='null', serviceName='service', externalId=0}, properties={key=value}}]> 
but was:<[QuotaVo{resourceVo=ResourceVo{id=0, dataSource=[NodeVo{type='dir', value='/'}], serviceType='HDFS', serviceName='service', externalId=0}, properties={key=value}}]>
  
HdfsResourceMgrTest.getHdfsResourcesTest:24 expected:<NodeVo{type='dir', value='/'}> but was:<[]>
  ResourceEntryTest.ofTest:12 expected null, but was:<ResourceEntry{fullName='/', name='/', type=, status=NORMAL}>

Tests in error: 
  InceptorResourceMgrTest.getInceptorResources:45 NullPointer
  InceptorResourceSvcTest.<init>:21 » NoSuchBeanDefinition No qualifying bean of...
  InceptorResourceSvcTest.<init>:21 » NoSuchBeanDefinition No qualifying bean of...
  InceptorResourceSvcTest.<init>:21 » NoSuchBeanDefinition No qualifying bean of...
  SearchResourceSvcTest.<init>:14 » NullPointer
  SearchResourceSvcTest.<init>:14 » NullPointer
  SearchResourceMgrTest.getSearchResourcesTest:27 » NullPointer
  KerberosUtilsTest.loginTest:22 » NullPointer
  HdfsResourceSvcTest.<init>:21 » NoSuchBeanDefinition No qualifying bean of typ...
  HdfsResourceSvcTest.<init>:21 » NoSuchBeanDefinition No qualifying bean of typ...
  KafkaResourceMgrTest.<init>:20 ClassCast io.transwarp.guardian.common.conf.Gua...
  KafkaResourceSvcTest.<init>:14 » NullPointer
  KafkaResourceSvcTest.<init>:14 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnResourceSvcTest.<init>:8 » NullPointer
  YarnSiteProviderTest.overrideSchedulerConfAndReturnXmlTest:17 » NullPointer
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnResourceMgrTest.<init>:19 ClassCast io.transwarp.guardian.common.conf.Guar...
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  HyperbaseResourceSvcTest.<init>:8 » NullPointer
  HyperbaseResourceSvcTest.<init>:8 » NullPointer
  HyperbaseResourceMgrTest.getHyperbaseResourcesTest:22 » Guardian ErrorCode: 56...
  StudioCommonResourceMgrTest.getResourcesTest:27 » NullPointer
  RubikResourceSvcTest.lookupResourceTest:19 » NullPointer
  WorkflowResourceSvcTest.<init>:22 » NoSuchBeanDefinition No qualifying bean of...
  WorkflowResourceSvcTest.<init>:22 » NoSuchBeanDefinition No qualifying bean of...
  ResourceServiceInitializerTest.addServiceSuperuserTest:32 » NullPointer

Tests run: 67, Failures: 4, Errors: 34, Skipped: 0

0414 10:00
Results :

Failed tests: 
  HdfsResourceMgrTest.getHdfsResourcesTest:24 expected:<NodeVo{type='dir', value='/'}> but was:<[ResourceEntry{entry=NodeVo{type='dir', value='/'}, fullPath=[NodeVo{type='dir', value='/'}], status=normal}]>
  KafkaResourceMgrTest.getKafkaResourcesTest:35 
expected:<ResourceEntry{entry=NodeVo{type='cluster', value='kafka-cluster'}, fullPath=[NodeVo{type='cluster', value='kafka-cluster'}], status=normal}> 
but was:<[ResourceEntry{entry=NodeVo{type='cluster', value='kafka-cluster'}, fullPath=[NodeVo{type='cluster', value='kafka-cluster'}], status=normal}]>
  ResourceEntryTest.ofTest:12 expected:<ResourceEntry{fullName='null', name='null', type=, status=NORMAL}> but was:<ResourceEntry{fullName='/', name='/', type=, status=NORMAL}>

Tests in error: 
  InceptorResourceMgrTest.getInceptorResources:49 NullPointer
  InceptorResourceSvcTest.<init>:19 » NoSuchBeanDefinition No qualifying bean of...
  InceptorResourceSvcTest.<init>:19 » NoSuchBeanDefinition No qualifying bean of...
  InceptorResourceSvcTest.<init>:19 » NoSuchBeanDefinition No qualifying bean of...
  SearchResourceSvcTest.<init>:12 » NoSuchBeanDefinition No qualifying bean of t...
  SearchResourceSvcTest.<init>:12 » NoSuchBeanDefinition No qualifying bean of t...
  SearchResourceMgrTest.getSearchResourcesTest:24 » NullPointer
  KerberosUtilsTest.loginTest:22 » Guardian ErrorCode: 56003, ErrorMessage: Guar...
  HdfsResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean of typ...
  HdfsResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean of typ...
  KafkaResourceSvcTest.<init>:12 » NoSuchBeanDefinition No qualifying bean of ty...
  KafkaResourceSvcTest.<init>:12 » NoSuchBeanDefinition No qualifying bean of ty...
  YarnResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean of typ..
  YarnResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean of typ...
  YarnResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean of typ...
  YarnResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean of typ...
  YarnResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean of typ...
  YarnResourceMgrTest.genXmlConfTest:47 NullPointer
  YarnResourceMgrTest.getInactiveQueuesTest:40 NullPointer
  YarnResourceMgrTest.getYarnResourcesTest:30 » NullPointer
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  YarnQueueProviderTest.<init>:18 » GuardianClient ErrorCode: 50107, ErrorMessag...
  HyperbaseResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean o...
  HyperbaseResourceSvcTest.<init>:16 » NoSuchBeanDefinition No qualifying bean o...
  HyperbaseResourceMgrTest.getHyperbaseResourcesTest:22 » Guardian ErrorCode: 56...
  StudioCommonResourceMgrTest.getResourcesTest:27 » NullPointer
  RubikResourceSvcTest.lookupResourceTest:19 » NullPointer
  WorkflowResourceSvcTest.<init>:17 » NoSuchBeanDefinition No qualifying bean of...
  WorkflowResourceSvcTest.<init>:17 » NoSuchBeanDefinition No qualifying bean of...
  ResourceServiceInitializerTest.addServiceSuperuserTest:28 » NullPointer

Tests run: 64, Failures: 3, Errors: 31, Skipped: 0

 private List<ResourceEntry> getResourcesFromParentDataSource(SessionVo sessionVo, String user, List<NodeVo> parentDataSource,
                                                               String resourceType, String prefix) throws GuardianException {

@RunWith(SpringRunner.class)
@EnableAutoConfiguration


  public YarnResourceSvcTest(ApplicationContext context) {
    this.yarnResourceSvc = context.getBean(YarnResourceSvc.class, context, "YARN",
        "yarn1", "yarn service", dummyConfigs);
  }


Results :

Failed tests: 
  ResourceEntryTest.ofTest:16 expected: io.transwarp.guardian.resource.ResourceEntry<ResourceEntry{fullName='/', name='/', type=TEST_TEST1, status=NORMAL}> but was: io.transwarp.guardian.resource.ResourceEntry<ResourceEntry{fullName='/', name='/', type=TEST_TEST1, status=NORMAL}>

Tests in error: 
  InceptorResourceMgrTest.getInactivePools:33 NullPointer
  InceptorResourceMgrTest.getInceptorResources:45 NullPointer
  InceptorResourceSvcTest.<init>:22 » NullPointer
  InceptorResourceSvcTest.<init>:22 » NullPointer
  InceptorResourceSvcTest.<init>:22 » NullPointer
  SearchResourceSvcTest.<init>:18 » NullPointer
  SearchResourceSvcTest.<init>:18 » NullPointer
  SearchResourceMgrTest.getSearchResourcesTest:21 » NullPointer
  KerberosUtilsTest.loginTest » UnsatisfiedDependency Error creating bean with n...
  ServiceQuotaInterpreterTest.supplementRelatedHdfsQuotaTest » UnsatisfiedDependency
  ServiceQuotaInterpreterTest.decorateQuotaResourceTest » UnsatisfiedDependency ...
  HdfsResourceMgrTest.getHdfsResourcesTest:29 » NullPointer
  HdfsResourceSvcTest.<init>:16 » NullPointer
  HdfsResourceSvcTest.<init>:16 » NullPointer
  KafkaResourceMgrTest.getKafkaResourcesTest:37 » NullPointer
  KafkaResourceSvcTest.<init>:10 » NullPointer
  KafkaResourceSvcTest.<init>:10 » NullPointer
  YarnResourceSvcTest.<init>:21 » NullPointer
  YarnResourceSvcTest.<init>:21 » NullPointer
  YarnResourceSvcTest.<init>:21 » NullPointer
  YarnResourceSvcTest.<init>:21 » NullPointer
  YarnResourceSvcTest.<init>:21 » NullPointer
  YarnResourceMgrTest.genXmlConfTest:51 » NullPointer
  YarnResourceMgrTest.getInactiveQueuesTest:44 » NullPointer
  YarnResourceMgrTest.getYarnResourcesTest:32 » NullPointer
  YarnQueueProviderTest.genFSXmlTest » UnsatisfiedDependency Error creating bean...
  YarnQueueProviderTest.genCSXmlTest » UnsatisfiedDependency Error creating bean...
  HyperbaseResourceSvcTest.<init>:21 » NullPointer
  HyperbaseResourceSvcTest.<init>:21 » NullPointer
  HyperbaseResourceMgrTest.getHyperbaseResourcesTest:22 » Guardian ErrorCode: 56...
  StudioCommonResourceMgrTest.getResourcesTest:28 » NullPointer
  RubikResourceSvcTest.<init>:23 » NullPointer
  RubikResourceSvcTest.<init>:23 » NullPointer
  WorkflowResourceSvcTest.<init>:22 » NullPointer
  WorkflowResourceSvcTest.<init>:22 » NullPointer
  ResourceServiceInitializerTest.addServiceSuperuserTest » UnsatisfiedDependency


Tests in error: 
  StudioCommonResourceMgrTest.getResourcesTest:28 » NullPointer
  HyperbaseResourceMgrTest.getHyperbaseResourcesTest:22 » Guardian ErrorCode: 56...
  ServiceQuotaInterpreterTest.supplementRelatedHdfsQuotaTest » UnsatisfiedDependency
  ServiceQuotaInterpreterTest.decorateQuotaResourceTest » UnsatisfiedDependency ...
  ResourceServiceInitializerTest.addServiceSuperuserTest » UnsatisfiedDependency
  SearchResourceMgrTest.getSearchResourcesTest:40 » NullPointer
  KerberosUtilsTest.loginTest » UnsatisfiedDependency Error creating bean with n...
  YarnResourceMgrTest.genXmlConfTest:51 » NullPointer
  YarnResourceMgrTest.getInactiveQueuesTest:44 » NullPointer
  YarnResourceMgrTest.getYarnResourcesTest:32 » NullPointer
  YarnQueueProviderTest.genFSXmlTest » UnsatisfiedDependency Error creating bean...
  YarnQueueProviderTest.genCSXmlTest » UnsatisfiedDependency Error creating bean...
  InceptorResourceMgrTest.getInactivePools:46 NullPointer
  InceptorResourceMgrTest.getInceptorResources:56 NullPointer

Tests run: 63, Failures: 0, Errors: 34, Skipped: 0

1. sessionVo报空：kafka,search（getchildnode），yarn(getDescendantResources), studioCommon

2. 所有的svc getbean初始化

3. configuration初始化 取出用 guardian-plugin和guardian不同

4. 扩充所有用例

/home/transwarp/Downloads/work/guardian-backend/guardian/resource-manager/src/test/resources

context.setSession(null);

{"component":"yarn1",
"dataSource":["CAPACITY_SCHEDULER","root","default"],
"properties"{"maxAMResource":0.1,"userLimitFactor":1.0,
"maximumCapacity":100.0,"state":"RUNNING","userLimit":100,
"capacity":100.0,"maxApplications":10000}}

1.租户管理员怎么定义
2.版本
3.需要做controller-

  @RequireAdminPriv(AdminPriv.ADD_USER)

AdminManager adminManager = AdminManager.getInstance();
      if (adminManager.hasRole(session, null, Collections.singletonList(GuardianConstants.TOKEN_ADMIN_ROLE))) {
        return true;
      }

 if (!skipCheckAccessWithService
            && !AuthUtil.checkAuthorized(sessionVo, AdminPriv.READ_SERVICE)
            && !AuthUtil.checkGlobalAdmin(sessionVo, serviceName)) {
      throw new GuardianException(ErrorCodes.AUTHORIZED_FAILURE, AdminPriv.READ_SERVICE);
    }


[{"roleName":"grantors","roleDescription":"predefined role: use which can grant the permission with grant option","users":[],"osPSet":[],"osUSet":[]},{"roleName":"role-viewer","roleDescription":"Role Viewer","users":[],"osPSet":[],"osUSet":[]},{"roleName":"perm-viewer","roleDescription":"Perm Viewer","users":[],"osPSet":[],"osUSet":[]},{"roleName":"tenant-owners","roleDescription":"predefined role: tenant-owners","users":[],"osPSet":[],"osUSet":[]},{"roleName":"role-admin","roleDescription":"Role Admin","users":["guardian/guardian","lzb"],"osPSet":[],"osUSet":[]},{"roleName":"perm-admin","roleDescription":"Perm Admin","users":["guardian/guardian"],"osPSet":[],"osUSet":[]},{"roleName":"service-admin","roleDescription":"Service Admin","users":[],"osPSet":[],"osUSet":[]},{"roleName":"super-admin","roleDescription":"Guardian Super User","users":["admin"],"osPSet":[],"osUSet":[]},{"roleName":"user-viewer","roleDescription":"User Viewer","users":[],"osPSet":[],"osUSet":[]},{"roleName":"user-admin","roleDescription":"User Admin","users":[],"osPSet":[],"osUSet":[]},{"roleName":"group-viewer","roleDescription":"Group Viewer","users":[],"osPSet":[],"osUSet":[]},{"roleName":"group-admin","roleDescription":"Group Admin","users":["guardian/guardian"],"osPSet":[],"osUSet":[]}]

	// LoginCacheConns manages the cache capacity to login
	LoginCacheConns = flag.Int64("login_cache_conns", 0, "Cache capacity to login"


// GetWithExpiration returns an item and its expiration time from the cache.
// It returns the item or nil, the expiration time if one is set (if the item
// never expires a zero value for time.Time is returned), and a bool indicating
// whether the key was found.
func (c *cache) GetWithExpiration(k string) (interface{}, time.Time, bool) {
	c.mu.RLock()
	// "Inlining" of get and Expired
	item, found := c.items[k]
	if !found {
		c.mu.RUnlock()
		return nil, time.Time{}, false
	}

	if item.Expiration > 0 {
		if time.Now().UnixNano() > item.Expiration {
			c.mu.RUnlock()
			return nil, time.Time{}, false
		}

		// Return the item and the expiration time
		c.mu.RUnlock()
		return item.Object, time.Unix(0, item.Expiration), true
	}

	// If expiration <= 0 (i.e. no expiration time set) then return the item
	// and a zeroed time.Time
	c.mu.RUnlock()
	return item.Object, time.Time{}, true
}


			l, s, c, o := ldapCache.Stats()
			log.Infof("cache msg:%v, %v, %v, %v", l, s, c, o)


strings.LastIndex(remoteAddr, ":")

func (lru *LRUCache) checkExpired(expireTime time.Duration) (ok bool) {
	// Partially duplicated from Delete
	lru.mu.Lock()
	defer lru.mu.Unlock()

	for e := lru.list.Back(); e != nil; e = e.Prev() {
		oldest := e.Value.(*entry).timeAccessed
		if oldest.Add(expireTime).Before(time.Now()) {
			lru.list.Remove(e)
			delete(lru.table, e.Value.(*entry).key)
			lru.size -= e.Value.(*entry).size
		} else {
			return true
		}
	}
	return false
}

 mysql -h127.0.0.1 -P15307 -uvt_app -p123 --enable-cleartext-plugin --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA


 AdminManager adminManager = AdminManager.getInstance();
    if (!(enableTokenAdminAccess && AuthUtil.checkAuthorized(sessionVo, AdminPriv.ADD_TOKEN))) {
      
    }
    if (session != null && tokenVo != null && (!session.getUserId().equals(tokenVo.getOwner())) ||
        adminManager.hasAnyRole(session, null, Arrays.asList(GuardianConstants.TOKEN_ADMIN_ROLE, GuardianConstants.TOKEN_VIEWER_ROLE))) {
      throw new GuardianException(ErrorCodes.AUTHORIZED_FAILURE,
              "User " + session.getUserId() + " has no the permission to get access token of id " + id);
    }


dn: ftOpNm=createToken,ftObjNm=org.apache.directory.fortress.core.impl.AdminMgrImpl,ou=AdminPerms,ou=ARBAC,${guardian_ds_domain}
objectClass: top
objectClass: organizationalRole
objectClass: ftOperation
objectClass: ftProperties
objectClass: ftMods
cn: org.apache.directory.fortress.core.impl.AdminMgrImpl.createToken
ftId: 9573a986-8543-5724-ac80-9496f7dee140
ftObjNm: org.apache.directory.fortress.core.impl.AdminMgrImpl
ftOpNm: createToken
ftPermName: org.apache.directory.fortress.core.impl.AdminMgrImpl.createToken
ftRoles: super-admin
ftRoles: token-admin

dn: ftOpNm=updateToken,ftObjNm=org.apache.directory.fortress.core.impl.AdminMgrImpl,ou=AdminPerms,ou=ARBAC,${guardian_ds_domain}
objectClass: top
objectClass: organizationalRole
objectClass: ftOperation
objectClass: ftProperties
objectClass: ftMods
cn: org.apache.directory.fortress.core.impl.AdminMgrImpl.updateToken
ftId: 2a777deb-6922-4222-ae9f-d760c39331be
ftObjNm: org.apache.directory.fortress.core.impl.AdminMgrImpl
ftOpNm: updateToken
ftPermName: org.apache.directory.fortress.core.impl.AdminMgrImpl.updateToken
ftRoles: super-admin
ftRoles: token-admin

dn: ftOpNm=deleteToken,ftObjNm=org.apache.directory.fortress.core.impl.AdminMgrImpl,ou=AdminPerms,ou=ARBAC,${guardian_ds_domain}
objectClass: top
objectClass: organizationalRole
objectClass: ftOperation
objectClass: ftProperties
objectClass: ftMods
cn: org.apache.directory.fortress.core.impl.AdminMgrImpl.deleteToken
ftId: b61cfa24-0cc0-4383-bb51-fc322f423a0d
ftObjNm: org.apache.directory.fortress.core.impl.AdminMgrImpl
ftOpNm: deleteToken
ftPermName: org.apache.directory.fortress.core.impl.AdminMgrImpl.deleteToken
ftRoles: super-admin
ftRoles: token-admin

  public static final String ADD_TOKEN_PERM = "createToken";
  public static final String UPDATE_TOKEN_PERM = "updateToken";
  public static final String DELETE_TOKEN_PERM = "deleteToken";
  public static final String READ_TOKEN_PERM = "readToken";

checkAccess

<?xml version="1.0" encoding="UTF-8"?>

<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.springframework.org/schema/beans
    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">

   <bean id="WorkflowResourceSvc" class="com.tutorialspoint.HelloWorld" 
      scope="singleton">
   </bean>

</beans>

WARP-7349

<property>
        <name>guardian.txsql.connection.url</name>
        <value>jdbc:mysql://localhost:3306/guardian?characterEncoding=UTF-8&amp;allowMultiQueries=true</value>
    </property>
mysql -h127.0.0.1 -P3306 -uroot -p123456

Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.

2020-04-17 15:01:05,263 INFO org.flywaydb.core.internal.util.VersionPrinter: Flyway Community Edition 5.0.7 by Boxfuse
2020-04-17 15:01:05,746 ERROR io.transwarp.guardian.persistence.flyway.SchemaMigrator: Exception occurred when migrating from location classpath:flyway
org.flywaydb.core.internal.exception.FlywaySqlException: 
Unable to obtain connection from database (jdbc:mysql://127.0.0.1:3306/guardian?characterEncoding=UTF-8&allowMultiQueries=true) for user 'root': Could not create connection to database server.
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL State  : 08001
Error Code : 0
Message    : Could not create connection to database server.


jdbc:mysql://127.0.0.1:3306/mysql
root@172.17.0.1


  <property>
        <name>guardian.txsql.connection.url</name>
        <value>jdbc:mysql://localhost:3307/guardian?characterEncoding=UTF-8&amp;allowMultiQueries=true</value>
    </property>

java.lang.ClassNotFoundException: io.transwarp.guardian.apacheds.synchronization.GuardianAuthenticationInterceptor
        at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:419)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:352)
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:264)
        at io.transwarp.guardian.apacheds.ApacheDsServer.createInterceptors(ApacheDsServer.java:558)
        at io.transwarp.guardian.apacheds.ApacheDsServer.initConfigPartition(ApacheDsServer.java:435)
        at io.transwarp.guardian.apacheds.ApacheDsServer.initDirectoryService(ApacheDsServer.java:312)
        at io.transwarp.guardian.apacheds.ApacheDsServer.initialize(ApacheDsServer.java:254)
        at io.transwarp.guardian.examples.StandaloneEnv.main(StandaloneEnv.java:13)
Exception in thread "main" org.apache.directory.server.config.ConfigurationException: Cannot initialize the io.transwarp.guardian.apacheds.synchronization.GuardianAuthenticationInterceptor, error : java.lang.ClassNotFoundException: io.transwarp.guardian.apacheds.synchronization.GuardianAuthenticationInterceptor
        at io.transwarp.guardian.apacheds.ApacheDsServer.createInterceptors(ApacheDsServer.java:610)
        at io.transwarp.guardian.apacheds.ApacheDsServer.initConfigPartition(ApacheDsServer.java:435)
        at io.transwarp.guardian.apacheds.ApacheDsServer.initDirectoryService(ApacheDsServer.java:312)
        at io.transwarp.guardian.apacheds.ApacheDsServer.initialize(ApacheDsServer.java:254)
        at io.transwarp.guardian.examples.StandaloneEnv.main(StandaloneEnv.java:13)
transwarp@transwarp-Latitude-5480:~/Downloads/work/guardian-backend/guardian/test$ 

 mysql -uroot -pTranswarp! -P17100 -h127.0.0.1

getVSchema


func (e *Executor) getVSchema(ctx context.Context, ksName string) (*vschemapb.Keyspace, error) {
	keyspaceVSchema, err1 := e.topServ.GetVSchema(ctx, ksName)
	if err1 == topo.ErrNoNode {

mysql> show databases;
Empty set (0.00 sec)

mysql> create database kundb1;
Query OK, 1 row affected (0.13 sec)

mysql> use kundb1;
Database changed
mysql> 
mysql> CREATE TABLE t1 (   id int(11),   name varchar(20),   PRIMARY KEY (`id`) ) ENGINE=InnoDB;
Query OK, 0 rows affected (0.16 sec)

mysql> show tables;
+------------------+
| Tables_in_kundb1 |
+------------------+
| t1               |
+------------------+
1 row in set (0.00 sec)

mysql> 
mysql> insert into t1(id, name) values (1, 'Zhang'), (2, 'Li');
Query OK, 2 rows affected (0.01 sec)

mysql> select * from t1;
+----+-------+
| id | name  |
+----+-------+
|  1 | Zhang |
|  2 | Li    |
+----+-------+
2 rows in set (0.00 sec)

mysql> create user lzb;
Query OK, 0 rows affected (0.01 sec)

mysql> grant select on t1 to lzb;
Query OK, 0 rows affected (0.01 sec)

case1
show databases;
create database kundb1;
use kundb1;
CREATE TABLE t1 (   id int(11),   name varchar(20),   PRIMARY KEY (`id`) ) ENGINE=InnoDB;
show tables;
insert into t1(id, name) values (1, 'Zhang'), (2, 'Li');
select * from t1;
create user lzb;
grant select on t1 to lzb;

case2
CREATE TABLE t2 (   id int(11),   name varchar(20),   PRIMARY KEY (`id`) ) ENGINE=InnoDB;
show tables;
insert into t2(id, name) values (1, 'Zhang'), (2, 'Li');
select * from t2;
grant select(id) on t2 to lzb;

case3
create table customer (custid int primary key, custname varchar(20), age int) partition by HASH(custid) using hash;
insert into customer(custid, custname, age) values (1, 'Zhang', 10), (2, 'Li', 20), (3,'Wang', 30), (4,'Zhao', 40);
grant select(id) on customer to lzb;

if grant.GrantIdent.Schema.IsEmpty() {
			return nil, fmt.Errorf("sql[%s] is should be executed here", sql)
		}
		originalSchema := grant.GrantIdent.Schema.String()
		allKs, err := getAllKeyspaces(ctx, e.serv, e.cell)
		if err != nil {
			return nil, err
		}
		ksSQL := make(map[string]string)
		for _, ks := range allKs {
			shardSQL := sql
			if ks != "_mfed" {
				internalDb := schemautil.GenerateInternalDBName(ks, originalSchema)
				shardSQL = strings.Replace(shardSQL, originalSchema, internalDb, 1)
			}
			ksSQL[ks] = shardSQL
		}
		grant.GrantIdent.Schema = sqlparser.NewTableIdent(originalSchema)
		if err := e.execOnSchema2(ctx, session, ksSQL, bindVars); err != nil {
			return nil, err
		}
	dclResult, err = e.execOnTarget(ctx, session, shardSQL, bindVars, querypb.Target{Keyspace: ks.String(), TabletType: topodatapb.TabletType_MASTER})
			
	if err := e.execOnSchema(ctx, session, sql, bindVars); err != nil {
			return nil, err
		}
	dclResult, err = e.execOnTarget(ctx, session, sql, bindVars, querypb.Target{Keyspace: ksName, TabletType: topodatapb.TabletType_MASTER})


	allKs, err := getAllKeyspaces(ctx, e.serv, e.cell)
	if err != nil {
		return err
	}
	// if map(failed) is not empty when exists for, this operation is failed
	// tell user which keyspace of schema is failed, then user should repair it or revert it
	for _, ks := range allKs {
		if _, err := e.execOnTarget(ctx, session, sql, bindVars, querypb.Target{Keyspace: ks, TabletType: topodatapb.TabletType_MASTER}); err != nil {
			log.Warningf("failed to execute sql[%s] in keyspace[%s]. err is %s", sql, ks, err.Error())
			lastErr = err
			failed = append(failed, ks)
		}
	}


		originalSchema := grant.GrantIdent.Schema.String()
		allKs, err := getAllKeyspaces(ctx, e.serv, e.cell)
		if err != nil {
			return nil, err
		}
	ksSQL := make(map[string]string)
		for _, ks := range allKs {
			shardSQL := sql
			internalDb := schemautil.GenerateInternalDBName(ks, originalSchema)
			shardSQL = strings.Replace(shardSQL, originalSchema, internalDb, 1)
			ksSQL[ks] = shardSQL
		}
		grant.GrantIdent.Schema = sqlparser.NewTableIdent(originalSchema)
		if err := e.execOnSchema2(ctx, session, ksSQL, bindVars); err != nil {
			return nil, err
		}



		if table, ok := tableOrView.(*vindexes.Table); ok {
					if !table.Sharded {
						target.Keyspace, target.Shard, _ = getFirstShard(ctx, e.serv, e.cell, target.Keyspace, topodatapb.TabletType_MASTER)
						defer func() {
							target.Shard = ""
						}()
					}
				}
			

if strings.ToLower(keyspace) == "_mfed" || strings.ToLower(dbName) == "information_schema" || strings.ToLower(dbName) == "mysql" {
		return strings.ToLower(keyspace), dbName, nil
	}

case sqlparser.ShowSchemasStr, sqlparser.ShowDatabasesStr, sqlparser.ShowKeyspacesStr:
		schemas, err := getAllSchemas(ctx, e.serv, e.cell)
		if err != nil {
			return nil, err
		}

		rows := make([][]sqltypes.Value, len(schemas))
		for i, v := range schemas {
			rows[i] = buildVarCharRow(v)
		}

		return &sqltypes.Result{
			Fields:       buildVarCharFields("Databases"),
			Rows:         rows,
			RowsAffected: uint64(len(rows)),
		}, nil

work25
1.并发
合理运用锁，什么时候加锁什么时候解锁，防止脏数据；又要防止死锁活锁资源占用
2.内存限制 ( 限制最大的可使用空间 )
涉及到golang gc，缓存要对内存实际使用量做限制，内存激增同样会导致资源竞争问题
Go 请求内存很容易，但释放给操作系统却很难。当碎片被清空的同时，goroutines 去访问 key 的时候，会开始分配内存空间，此时之前的内存空间并没有被完全释放，这导致内存的激增，甚至会出发 OOM 错误。
我们没有意识到，访问的模式还受 Zipf 定律的束缚。最常访问的几个 key 仍然存在几个锁，因此产生 Goroutines 的竞争问题。这种方式不满足多核之间的扩展的需求。
3.在多核和多 Goroutines 之间更好的扩展
单机使用，或者只有一个请求者连续请求的情况下，缓存做到资源管理。多核多goroutine就会涉及到缓存动态扩展问题，业务量上来了怎么去迁移数据保证请求的资源最大限度发挥效用，往往会用到缓存分片
4.在非随机密钥的情况下，很好地扩展 (eg. Zipf)
齐夫定律可以表述为：在自然语言的语料库里，一个单词出现的频率与它在频率表里的排名成反比。所以，频率最高的单词出现的频率大约是出现频率第二位的单词的2倍，而出现频率第二位的单词则是出现频率第四位的单词的2倍。这个定律被作为任何与幂定律概率分布有关的事物的参考。搜索引擎经常用到这个定律。缓存这里可以想为zipf定律下如何合理分配缓存的key使得频率访问次数科学地使用缓存
5.更高的缓存命中率
由于内存速度比磁盘读写速度快很多，我们当然希望所有的请求热点数据都打到缓存上，充分利用内存以及CPU资源做到效益最大化
涉及到gc处理


go-cache
安装方法：go get github.com/patrickmn/go-cache
是一个运行在单机上的k/v缓存，相当于memcached，实现线程安全，可以带有过期时间访问清理。里面有cach0e和sharded cache两种，今年加入了单测可以看怎么去使用，value支持有限的数据类型不过可扩展，是一个比较老的实现，当成一个简单可用的demo是可以好的。

FreeCache - A cache library for Go with zero GC overhead and high concurrent performance.
https://github.com/coocood/freecache.git
0gc过剩，支持高并发，支持lru，支持过期清理get，严格限制内存使用量，同时具有审计平均access时间，hitcount等功能，现在仍有活跃开发

FreeCache 将缓存分成了 256 段，每段包括 256 个槽和一个 ring buffer 存储数据。set数据使用 hash 值下 8 位作为标识 id，通过使用 LSB 9-16 的值作为槽 ID。将数据分配到多个槽里面，有助于优化查询的时间 ( 分治策略 )。

数据被存储在 每个槽的ring buffer 中，相当于一个排序的数组里面。如果 ring buffer 内存不足，则会利用 LRU 的策略在 ring buffer 逐个扫描，如果缓存的最后访问时间小于平均访问的时间，就会被删掉。要找到一个缓存内容，在槽中是通过二分查找法对一个已经排好的数据进行查询。

sync包实现了两种锁Mutex （互斥锁）和RWMutex（读写锁）

BIGCache
https://github.com/allegro/bigcache.git
参数如下，支持分片支持时间控制，支持最大cache空间限制，支持verbose开关 使用读写锁RWMUTEX读锁无消耗
https://blog.csdn.net/chenbaoke/article/details/41957725
Shards
CleanWindow
MaxEntriesInWindow
MaxEntrySize
Verbose
HardMaxCacheSize
OnRemove
OnRemoveWithReason
BigCache 会通过 Hash 的方式进行分片。 每个分片都包含一个 map 和一个 ring buffer。无论如何添加元素，都会将它放置在对应的 ring buffer 中，并将位置保存在 map 中。如果多次设置相同的元素，则 ring buffer 中的旧值则会被标记为无效，如果 ring buffer 太小，则会进行扩容。

每个 map 的 key 都是一个 uint32 的 hash 值，每个值对应一个存储着元数据的 ring buffer。如果 hash 值碰撞了，BigCache 会忽略旧 key，然后把新的值存储到 map 中。预先分配更少，更大的 ring buffer，使用 map [uint32] uint32 是避免支付 GC 扫描成本的好方法

BigCache 不能有效地利用缓冲区，并且可能会在缓冲区中为同一个键存储多个条目。
BigCache 不更新访问 ( 读 ) 条目，因此会导致最近访问的键被删除

GroupCache
https://github.com/golang/groupcache.git
星标最多的cache 支持shardByKey，P2P形式形成一个分布式缓存，更好的cachefilling，得益于p2p，cache不命中时只需要在其中的某个cache添加data即可，同时抛弃版本号的概念并支持把super-hot key备份到所有节点

GroupCache 使用链表和 Map 实现了一个精准的 LRU 删除策略的缓存。为了进行公平的比较，我们在 GroupCache 的基础上，实现了一个包括 256 个分片的切片结构。

for _, value := range result.Rows {
			schema := value[0].ToString()
			if strings.ToLower(schema) != "_vt" && strings.ToLower(schema) != "information_schema" && strings.ToLower(schema) != "mysql" &&
				strings.ToLower(schema) != "vt__mfed" && strings.ToLower(schema) != "performance_schema" {
				schemas = append(schemas, schema)
			}
		}

mysql -h127.0.0.1 -P15307 -uvt_appdebug -pvtappdebug_password

工作周报 - 李镇邦 20200413 ~ 20200417

完成：
1. WARP-43659: [guardian] ResourceManager单测提升 提升中需要一段时间夯实
2. WARP-43107: [guardian] AccessToken添加admin权限 guardian3.1和3.2版本 本地已测过3.2
3. WARP-43853: [kundb] ldap接口缓存优化，增加过期处理
4. WARP-44290: [kundb]grant在schema不分片创建表时时报错表不存在
5. WARP-41378: [kundb]schema处理后show database未赋权可见


本周：
1. 对kundb权限修改的部分进行审核 添加单测
2. WARP-43659有些resource不存在的情况下更好的方法实现测试，启动配置
3. 继续跟进guardian accesstoken权限完成后的测试 以及这个功能滚动升级可能存在的问题


 ps aux | grep mariadb
 mysql -h127.0.0.1 -P17800 -uroot -pTranswarp!

https://dev.mysql.com/doc/refman/5.7/en/privileges-provided.html#priv_alter
http://172.16.1.168:8090/pages/viewpage.action?pageId=23490750


db1: vt_insert_test

testTb1
testTb2
v
nightly test
docker run -it --rm --network host 172.16.1.99/kundb-ci/x86_64/bootstrap-ci:go1.14
git clone http://172.16.1.41:10080/lishinho/kundb.git --depth=1 -b WARP-44346
mv kundb vitess
cd vitess && source dev.env
GO111MODULE=off make build
python privileges_test.py -v --skip-teardown --keep-logs --skip-build
python mysqlalias_test.py -v --skip-teardown --keep-logs --skip-build

[1]+  Stopped                 python privileges_test.py -v --skip-teardown --keep-logs --skip-build
kundb@transwarp-Latitude-5480:/vt/src/github.com/youtube/vitess/test$ python privileges_test.py -v --skip-teardown --keep-logs --skip-build
-- 2020-04-20 12:49:05,065 mysql_flavor:212 DEBUG Using MySQL flavor: MySQL56, setting MYSQL_FLAVOR=MySQL56 (<class 'mysql_flavor.MySQL56'>)
-- 2020-04-20 12:49:05,094 environment:237 DEBUG Using protocols flavor 'grpc'
-- 2020-04-20 12:49:05,095 server:66 DEBUG Using topo server flavor 'zk2'
-- 2020-04-20 12:49:05,095 gateway:69 DEBUG Using VTGate gateway flavor 'discoverygateway'
-- 2020-04-20 12:49:05,095 environment:145 DEBUG run: ['/vt/bin/zkctl', '-log_dir', '/vt/vtdataroot/tmp', '-zk.cfg', '1@transwarp-Latitude-5480:15012:15013:15014', 'init'] 
-- 2020-04-20 12:49:05,125 utils:80 INFO ===== ERROR
-- 2020-04-20 12:49:05,126 utils:80 INFO ===== ======================================================================
-- 2020-04-20 12:49:05,126 utils:80 INFO ===== ERROR: setUpModule (__main__)
-- 2020-04-20 12:49:05,127 utils:80 INFO ===== ----------------------------------------------------------------------
-- 2020-04-20 12:49:05,127 utils:80 INFO ===== Traceback (most recent call last):
  File "privileges_test.py", line 29, in setUpModule
    environment.topo_server().setup()
  File "/vt/src/github.com/youtube/vitess/test/topo_flavor/zk2.py", line 51, in setup
    'init'])
  File "/vt/src/github.com/youtube/vitess/test/environment.py", line 157, in run
    stderr)
Exception: Command failed: /vt/bin/zkctl -log_dir /vt/vtdataroot/tmp -zk.cfg 1@transwarp-Latitude-5480:15012:15013:15014 init:
E0420 12:49:05.101458    9698 zkctl.go:89] failed init: zk already inited


-- 2020-04-20 12:49:05,128 utils:80 INFO ===== ----------------------------------------------------------------------
-- 2020-04-20 12:49:05,128 utils:80 INFO ===== Ran 0 tests in 0.031s
-- 2020-04-20 12:49:05,128 utils:80 INFO ===== FAILED
-- 2020-04-20 12:49:05,129 utils:80 INFO ===== FAILED (errors=1)
-- 2020-04-20 12:49:05,129 utils:187 WARNING Leaving temporary files behind (--keep-logs), please clean up before next run: /vt/vtdataroot
kundb@transwarp-Latitude-5480:/vt/src/github.com/youtube/vitess/test$ 

guardian admin-assign接口有问题
 {
    "dataSource": [
      "org.apache.directory.fortress.core.impl.AdminMgrImpl"
    ],
    "action": "addUser",
    "heritable": false,
    "grantable": false,
    "administrative": true
  },

 jdbc:kundb://dft:111@168.66.136.100:15991/abc?useSSL=true&trustAllCA=true&nullCatalogMeansCurrent=true&defaultIdleTimeout=36000000

I0421 02:23:36.476831    4062 vtgate.go:426] SQLLog: Session Info: 74be1298-478d-4d60-a856-e66a03645b81 , Executed sql: rollback, BindVariables: map[], Cost: 14.619µs
W0421 02:23:36.512210    4062 vtgate.go:459] unexpected error when executing sql[create database db2], err is target: _mfed.0.master, used tablet: test_nj-62346 (localhost), vttablet: rpc error: code = Unknown desc = Access denied; you need (at least one of) the SUPER privilege(s) for this operation (errno 1227) (sqlstate 42000) during query: DROP SERVER IF EXISTS `db2`, CallerID: u1

mysql -h127.0.0.1 -P15307 -uvt_app -p123 --enable-cleartext-plugin --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA

本地登陆kundb
mysql -h172.16.1.236 -P15307 -uadmin -padmin --enable-cleartext-plugin --ssl-ca=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/ca-cert.pem --ssl-cert=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-cert.pem --ssl-key=/home/transwarp/go/src/github.com/youtube/vitess/examples/local_mfed/sub_scripts/kungate-client-key.pem --ssl-mode=VERIFY_CA


   # test create/drop privileges on database
    params['user'] = 'u1'
    params['passwd'] = 'u1'
    conn = MySQLdb.Connect(**params)
    try:
        cursor = conn.cursor()
        cursor.execute('create database db2', {})
        self.fail('Execute went through')
    except MySQLdb.OperationalError, e:
        s = str(e)
        self.assertIn('denied', s)
    conn.close()

    params['user'] = 'vt_app'
    params['passwd'] = 'vt_app'
    conn = MySQLdb.Connect(**params)
    cursor = conn.cursor()
    cursor.execute('grant create, drop on *.* to u1', {})
    conn.close()

    params['user'] = 'u1'
    params['passwd'] = 'u1'
    conn = MySQLdb.Connect(**params)
    cursor = conn.cursor()
    cursor.execute('create database db2')
    cursor.execute('drop database db2')
    conn.close()


create table customer (custid int primary key, custname varchar(20), age int) partition by HASH(custid) using hash;
insert into customer(custid, custname, age) values (1, 'Zhang', 10), (2, 'Li', 20), (3,'Wang', 30), (4,'Zhao', 40);


create table item1 (itemid int primary key, itemname varchar(100), price decimal ) partition by HASH(Itemid) using hash;
insert into item1(itemid, itemname, price) values (1, 'Candy', 5), (2, 'Milk', 10), (3, 'Toy', 20);

// CheckDbName returns a error if the given name contains underline
func CheckDbName(dbName string) error {
	if strings.ContainsAny(dbName, underline) {
		return fmt.Errorf("not support '_' in the name of database, while the database's name is %s", dbName)
	}
	if dbName == "mysql" {
		return fmt.Errorf("not support 'mysql' as the name of database")
	}
	return nil
}
Q1 db1 exists
Q2 

WARP-41378->review
WARP-44290->review
WARP-44415->修改case，支持oracle暂不支持select procedure
WARP-44406->ing cyj
WARP-44389->ing cyj
WARP-44350->ing lgy


先整理case 然后测一遍
把WARP-43107 guardian3.1完成 联通项目出包

\d //
create procedure proc1 ()
begin
update FROM item1 WHERE itemid=3;
end //
\d ;
show procedure status;

call proc0();

ERROR 1142 (42000): vtgate: http://tw-node1236:15001/: target: _mfed.80-.master, used tablet: transwarp-810 (tw-node1237), vttablet: TRIGGER command denied to user 'wangbin'@'%' for table 'item1' (errno 1142) (sqlstate 42000) during query: insert into item1 values (3, 'Toy', 20), CallerID: vt_app


DELIMITER //  
CREATE PROCEDURE demo_in_parameter(IN p_in int)  
BEGIN   
SELECT p_in;   
SET p_in=2;   
SELECT p_in;   
END;   
//  
DELIMITER ;




    if (!skipCheckAccessWithService &&
        !AuthUtil.checkAdminAccess(session, serviceVo.getServiceName()) &&
        !AuthUtil.checkPermission(session, AdminManager.ADMIN_MGR, ADD)) {
      throw new GuardianException(ErrorCodes.AUTHORIZED_FAILURE, ADD);
    }

      if (!(enableTokenAdminAccess && (AuthUtil.checkPermission(session, AdminManager.ADMIN_MGR, ADD_TOKEN_PERM)))) {



create_testTb2 = '''create table testTb2 (
custid bigint,
custname varchar(64),
age int,
primary key (custid)
) partition by HASH(custid) using hash'''

\d //
create procedure proc1 ()
begin
insert into testtb2 values(1, 'Kun', 33) ;
update testtb2 set custid=2;
end //
\d ;

  543  sudo rm -rf TDH-Client/
  544  rm -rf tdh-client.tar 
  545  ls
  546  sudo tar -xvf tdh-client.tar
  547  ls
  548  cd TDH-Client/
  549  ls
  550  source init.sh 
  551  cd ~/tmp
  552  ls
  553  cd TDH-Client/
  554  ls
  555  cat init.sh 
  556  ps -aux
  557  ps -aux | grep init
  558  ps -aux | grep kerberos
  559  ls
  560  source init.sh 
  561  cd ~/tmp
  562  ls
  563  cd TDH-Client/
  564  ls
  565  source init.sh 
  566  ls
  567  cd -
  568  cd ~/tmp
  569  ls
  570  cd TDH-Client/
  571  ls
  572  cat init.sh 
  573  cat init.sh  | grep exit
  574  cat init.sh  | grep -a2 exit
  575  ls
  576  vi init.sh 
  577  ls
  578  ls -al
  579  ls
  580  cd ../
  581  ls
  582  sudo chown -R transwarp:transwarp TDH-Client/
  583  cd TDH-Client/
  584  ls
  585  vi init.sh 
  586  ls
  587  source init.sh 
  588  ls
  589  klist
  590  hadoop fs -ls /
  591  history 20
  592  history 50

http://172.26.5.46:8180/#/dashboard/status

lzb/123


  627  vi hosts 
  628  hadoop fs -ls /
  629  vi hosts 
  630  cd ..
  631  rm -rf TDH-Client/
  632  ls
  633  rm -rf tdh-client.tar 
  634  ls
  635  ps -ef |grep mysql
  636  vim /vt/vtdataroot/vt_793535492/vt_0000062346/my.cnf
  637  docker ps 
  638  docker exec -it 6c35e09e4724 bash
  639  exit
  640  docker ps -ef |grep mysql
  641  docker ps
  642  docker rm 6c35e09e4724       
  643  docker ps -a
  644  ps -ef |grep mysql
  645  cd /home/transwarp/go/src/github.com/youtube/vitess/
  646  source dev.env 
  647  cd test/
  648  python
  649  python privileges_test.py  -v --skip-teardown --keep-logs --skip-build
  650  sudo apt-get install python-mysqldb
  651  pip install mysql-python
  652  python privileges_test.py  -v --skip-teardown --keep-logs --skip-build
  653  ps -ef 
  654  ps -ef |grep mysql
  655  vi /home/transwarp/go/vtdataroot/vt_0000062344/my.cnf
  656  vim ~/go/config/mycnf/master_mysql56.cnf 
  657  vim ~/go/config/mycnf/master_mysql80.cnf 
  658  vim ~/go/config/mycnf/master_mariadb.cnf 
  659  vim ~/go/config/mycnf/mfed.cnf 
  660  vim ~/go/config/mycnf/binlog_statement.cnf 
  661  vim privileges_test.py 
  662  vim st.py 
  663  history 40

if !ok {
						return "", vterrors.Errorf(vtrpcpb.Code_NOT_FOUND, "keyspace %s not found in vschema", ksName)
					}


create_trigger = '''drop trigger if exists "Tri_Item_Insert"
delimiter $$
CREATE TRIGGER Tri_Item_Insert BEFORE INSERT ON testTb1 FOR EACH ROW
BEGIN
insert into testTb1 values(6, 'paper', 35);
END;$$
delimiter ;'''

create_routines = '''
\d //
create procedure proc1 ()
begin
DELETE FROM testTb1 WHERE itemid=3;
end //
\d ;'''

E0423 11:58:28.548425   27760 vtgate.go:429] SQLLog: Session Info: 4cfbd124-745a-45a0-9370-82a8446e788d db1, Executed sql: call proc1() , BindVariables: map[], Cost: 4.415642ms, Error: vtgate: http://transwarp-Latitude-5480:15015/: target: _mfed.0.master, used tablet: test_nj-62346 (localhost), vttablet: SELECT command denied to user 'u1'@'localhost' for column 'itemid' in table 'testtb1' (errno 1143) (sqlstate 42000) during query: call proc1() , CallerID: u1


create_testTb1 = '''create table testTb1 (
itemid bigint auto_increment,
itemname varchar(64),
price int,
primary key (itemid)
) Engine=InnoDB'''

create_testTb2 = '''create table testTb2 (
custid bigint,
custname varchar(64),
age int,
primary key (custid)
) partition by HASH(custid) using hash'''


hadoop fs -mkdir /inceptor1-encrypt

transwarp@transwarp-Latitude-5480:~/tmp/TDH-Client$ hadoop fs -mkdir /inceptor1-encrypt
2020-04-23 14:17:53,178 INFO  [main] util.KerberosUtil (KerberosUtil.java:getDefaultPrincipalPattern(81)) - Using principal pattern: HTTP/_HOST
-mkdir: Fatal internal error
io.transwarp.guardian.federation.utils.oauth2.configuration.InvalidOAuth2ConfigurationException: Failed to extract client credential from file /etc/hdfs1/conf/client-credential.jks
	at io.transwarp.guardian.federation.utils.oauth2.configuration.ClientCredentialExtractingTransformer.transform(ClientCredentialExtractingTransformer.java:41)
	at io.transwarp.guardian.federation.utils.oauth2.configuration.ClientCredentialExtractingTransformer.transform(ClientCredentialExtractingTransformer.java:9)
	at io.transwarp.guardian.federation.utils.oauth2.configuration.OAuth2Configuration.transform(OAuth2Configuration.java:61)
	at io.transwarp.guardian.federation.utils.oauth2.configuration.OAuth2ConfigurationFactory.getConf(OAuth2ConfigurationFactory.java:21)
	at org.apache.hadoop.security.SecurityUtil.getOAuth2Conf(SecurityUtil.java:674)
	at org.apache.hadoop.security.SaslRpcServer.init(SaslRpcServer.java:202)
	at org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:575)
	at org.apache.hadoop.hdfs.NameNodeProxies.createNNProxyWithClientProtocol(NameNodeProxies.java:428)
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.getProxy(ConfiguredFailoverProxyProvider.java:138)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.<init>(RetryInvocationHandler.java:73)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.<init>(RetryInvocationHandler.java:64)
	at org.apache.hadoop.io.retry.RetryProxy.create(RetryProxy.java:58)
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:181)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:687)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:628)
/////////||////////////////////////////////////////////////////////////////////////////////////////////////////
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:93)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2718)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2700)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:171)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:356)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)
	at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:325)
	at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:235)
	at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:218)
	at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:201)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:165)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:287)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:340)

在使用HDFS的API进行读写操作前都会对FileSystem进行初始化。并且让客户端创建namenode的通信代理代理用于进行RPC通信。
HADOOP_SECURITY_AUTHENTICATION_OAUTH2_ENABLED -》false

      for (EntityPermissionVo epVo : perms2EntityPermissionVo(perms)) {
        if (StringUtils.isNotEmpty(epVo.getName())) {
          epVos.add(epVo);
        }
      }

curl -X POST --header 'Content-Type: application/json' --header 'Accept: application/json' -d '{ \ 
   "isSystem": false, \ 
   "password": "admin", \ 
   "username": "admin" \ 
 }' 'https://172.26.0.38:8380/api/v1/login'

curl -X GET --header 'Accept: application/json' 'http://172.26.5.46:8380/api/v1/perms/component/inceptor1/dataSource/**?subtree=true&pageSize=-1&sorting=false'


    List<Permission> findPermissionsByFilters( String contextId, String user, String role, String group,
        PermFilterParams filter)
        throws FinderException
    {
        List<Permission> permList = new ArrayList<>();
        LdapConnection ld = null;
        PermObj permObj = new PermObj( filter.getDataSource(), filter.getComponent() );
        String permObjDn = getDn( permObj, contextId );

        try
        {
            String _user = Rdn.escapeValue( user );
            String _group = Rdn.escapeValue( group );
            String _role = Rdn.escapeValue( role );
            String _prefix = Rdn.escapeValue( filter.getPrefix() );
            StringBuilder filterbuf = new StringBuilder();
            filterbuf.append( GlobalIds.FILTER_PREFIX );
            filterbuf.append( PERM_OP_OBJECT_CLASS_NAME );
            filterbuf.append( ")" );

            filterbuf.append(")");
            ld = getAdminConnection( true );

            SearchCursor searchResults;
            if ( filter.getPageSize() >= 0 ) {
                // Search paged result
                searchResults = search( ld, permObjDn, filter.getScope(),
                    filterbuf.toString(), PERMISSION_OP_ATRS, false, filter.getPagingCookie(), filter.getPageSize());
            } else {
                searchResults = search( ld, permObjDn,
                    filter.getScope(), filterbuf.toString(), PERMISSION_OP_ATRS, false, 0 );
            }

            long sequence = 0;

            while ( searchResults.next() )
            {
                permList.add( unloadPopLdapEntry( searchResults.getEntry(), sequence++, false ) );
            }

            pagedSearchDone( searchResults, filter );
        }
        catch ( LdapException e )
        {
            String error = "findAnyPermissions caught LdapException=" + e.getMessage();
            throw new FinderException( GlobalErrIds.PERM_SEARCH_FAILED, error, e );
        }
        catch ( CursorException e )
        {
            String error = "findAnyPermissions caught CursorException=" + e.getMessage();
            throw new FinderException( GlobalErrIds.PERM_SEARCH_FAILED, error, e );
        }
        finally
        {
            closeAdminConnection( ld );
        }
        return permList;
    }

mysql binlog rbr sbr

 if (session == null) {
        throw new GuardianException(ErrorCodes.PARAMETERS_ERROR, "parameter owner is needed");
      } else if (enableTokenAdminAccess && AuthUtil.checkPermission(session, AdminManager.ADMIN_MGR, FIND_TOKENS_PERM)) {
        return tokenDao.getAccessTokenByOwner(owner);
      }


 database.  Cause: org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'owner' in 'class java.lang.String'\n### Cause: org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'owner' in 'class java.lang.String'",
  "detailMessage": "org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'owner' in 'class java.lang.String'\n\tat org.apache.ibatis.reflection.Reflector.getGetInvoker(Reflector.java:422)\n\tat org.apache.ibatis.reflection.MetaClass.getGetInvoker(MetaClass.java:164)\n\tat org.apache.ibatis.reflection.wrapper.BeanWrapper.getBeanProperty(BeanWrapper.java:162)\n\tat org.apache.ibatis.reflection.wrapper.BeanWrapper.


// Original user get owner from session if input owner is empty
      if (session == null) {
        throw new GuardianException(ErrorCodes.PARAMETERS_ERROR, "parameter owner is needed");
      }
      owner = session.getUserId();

Client的通过RPC的Proxy与NameNode交互。在client端会有两个代理同时存在，分别代表与Active和Standby的NameNode的连接。由于Client端有Retry机制，当与Active NameNode正常通信的client proxy收到RPC返回的StandbyException时，说明这个Active NameNode已经变成了Standby模式，所以触发dfs.client.failover.proxy.provider.[nameservice ID]这个参数指定的类来做failover，目前唯一的实现是ConfiguredFailoverProxyProvider，实现方法就是下次开始把RPC发向另外一个NameNode。此后的RPC都是发往另外一个NameNode，也就是NameNode发生了主从切换。

